{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os, sys, json, datetime  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def classify_response(j):\n",
    "    \n",
    "    if isinstance(j, (int, float)):\n",
    "        if isinstance(j, float) and str(j) == 'nan':\n",
    "            return 'missing'         \n",
    "        elif isinstance(j, (int, float)):\n",
    "            # print(j)\n",
    "            return 'quantitative'\n",
    "    elif re.search(r'^yes|^no', str(j).lower().strip()):\n",
    "        return \"bool\"\n",
    "    else:        \n",
    "        return 'qualitative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for ECLS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ecls_survey_data = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up\\edited\\ECLS_evaluation_2024.xlsx\"\n",
    "ecls_df = pd.read_excel(ecls_survey_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q8_share 78.0%\n",
      "\n",
      "\n",
      "q8_identify 44.0%\n",
      "\n",
      "\n",
      "q8_committee 35.0%\n",
      "\n",
      "\n",
      "q8_build 56.00000000000001%\n",
      "\n",
      "\n",
      "q8_propose 43.0%\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#what actions are you prepared to take\n",
    "sel_col = ecls_df.columns[8]\n",
    "\n",
    "all_resp = len(ecls_df)\n",
    "\n",
    "q8 = ecls_df[~ecls_df[sel_col].isna()]\n",
    "q8_resp = len(q8)\n",
    "\n",
    "response_rate = q8_resp/all_resp\n",
    "\n",
    "q8_share = ecls_df[ecls_df[sel_col].str.contains('Sharing ideas', na=False)]\n",
    "q8_identify = ecls_df[ecls_df[sel_col].str.contains('Identify clear', na=False)]\n",
    "q8_committee = ecls_df[ecls_df[sel_col].str.contains('Create a ', na=False)]\n",
    "q8_build = ecls_df[ecls_df[sel_col].str.contains('Build consensus', na=False)]\n",
    "q8_propose = ecls_df[ecls_df[sel_col].str.contains('Propose policy actions', na=False)]\n",
    "\n",
    "counts = {\"q8_share\": q8_share, \"q8_identify\": q8_identify, \"q8_committee\": q8_committee, \"q8_build\":q8_build, \"q8_propose\": q8_propose}\n",
    "\n",
    "q8_dict = {}\n",
    "for k,c in counts.items():\n",
    "    n = len(c)\n",
    "    q8_dict[k] = f'{round((n/all_resp), 2) * 100}%'\n",
    "\n",
    "\n",
    "\n",
    "for k,v in q8_dict.items():\n",
    "    print(k,v)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.74% of respondents found ECLS to be useful\n",
      "The Summit increased my understanding of key early education policy issues in my state and the country\n",
      "positive response: 92.59%\n",
      "average response: 4.43\n",
      "The Summit facilitated an environment supportive of nonpartisan discussion\n",
      "positive response: 94.44%\n",
      "average response: 4.63\n",
      "Adequate time was given to creating realistic, attainable SMART goals for my state team\n",
      "positive response: 79.63%\n",
      "average response: 3.88\n",
      "I felt prepared to create SMART goals with support from The Hunt Institute staff\n",
      "positive response: 87.04%\n",
      "average response: 4.15\n",
      "The Fireside Chat on Wednesday evening gave me valuable insight into how governors and business leaders view the promise and challenges facing early childhood policy.\n",
      "positive response: 92.59%\n",
      "average response: 4.38\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "q1 = ecls_df.columns[0]\n",
    "q2 = ecls_df.columns[1]\n",
    "q3 = ecls_df.columns[2]\n",
    "q4 = ecls_df.columns[3]\n",
    "q5 = ecls_df.columns[4]\n",
    "q6 = ecls_df.columns[5]\n",
    "q7 = ecls_df.columns[6]\n",
    "\n",
    "\n",
    "#likert q's\n",
    "for ic, col in enumerate(ecls_df.columns):\n",
    "    # for i,j in enumerate(ecls_df[col]):\n",
    "    #     print(type(j))\n",
    "    num_resp = len(ecls_df)\n",
    "    if ic == 0: \n",
    "        continue\n",
    "    elif ic == 1:\n",
    "        yes = ecls_df[ecls_df[col].str.contains(\"Yes\", na=False)]\n",
    "        yes_num = len(yes)\n",
    "        yes_rr = round((yes_num/num_resp)*100, 2)\n",
    "        print(f'{yes_rr}% of respondents found ECLS to be useful')\n",
    "    elif ic > 6:\n",
    "        # print(col)\n",
    "        continue\n",
    "    else:\n",
    "        new_col = pd.to_numeric(ecls_df[col], errors = \"coerce\")\n",
    "        positive = len(new_col[new_col >= 3])\n",
    "        percent_pos = round((positive/num_resp)*100, 2)\n",
    "        # print(new_col)\n",
    "        avg = round(new_col.mean(skipna=True), 2)\n",
    "        # print(col)\n",
    "\n",
    "        print(col)\n",
    "        print(f'positive response: {percent_pos}%')\n",
    "        print(f'average response: {avg}')\n",
    "    \n",
    "\n",
    "\n",
    "# for ic, col in enumerate(ecls_df.columns):\n",
    "#     # for i,j in enumerate(ecls_df[col]):\n",
    "#     #     print(type(j))\n",
    "#     if ic ==2:\n",
    "#         yes = ecls_df[ecls_df[col].str.contains(\"Yes\")]\n",
    "#         yes_num = len(yes)\n",
    "#         yes_rr = round((yes_num/len(ecls_df)), 2)\n",
    "#         print(f'{yes_rr} found ECLS to be useful')\n",
    "    \n",
    "#     if ic >= 7:\n",
    "#         print(col)\n",
    "        \n",
    "#     else:\n",
    "#         continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#grab files from edited folder\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up\\edited')\n",
    "edited_files = glob.glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 21.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#survey formatter\n",
    "all_surveys = {}\n",
    "for file in tqdm(edited_files):\n",
    "    \n",
    "    # file = edited_files[0]\n",
    "    df = pd.read_excel(file)\n",
    "    # print(\"##################\")\n",
    "    # print(file)\n",
    "    # print(df.columns[0])\n",
    "    # print(\"\\n\")\n",
    "    dfs = []\n",
    "    for name, data in df.items():\n",
    "        if str(name) == 'respondent' or str(name).lower().strip() == 'name':\n",
    "            index_col = str(name)\n",
    "            continue\n",
    "        \n",
    "        n = len(data)\n",
    "        \n",
    "        respondents = df[index_col].to_list()\n",
    "        # print(respondents)\n",
    "        quest = [str(name)]*n\n",
    "        response = data.to_list()\n",
    "        df_app = pd.DataFrame({'respondent':respondents, 'question': quest, 'response': response})\n",
    "        dfs.append(df_app)\n",
    "    survey_data = pd.concat(dfs)\n",
    "    all_surveys[file] = survey_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull all survey data together\n",
    "modified_dfs = []\n",
    "for file, df in all_surveys.items():\n",
    "    print('##########')\n",
    "    print(file)\n",
    "    event_name = re.sub(r'\\s{2}', \" \", re.sub(r'evaluation|eval|results', '', str(file).split(\".\", 1)[0].replace(\"_\", \" \"), flags=re.IGNORECASE).strip(),flags=re.IGNORECASE)\n",
    "    print(event_name)\n",
    "    df['event'] = event_name\n",
    "    modified_dfs.append(df)    # Append modified DataFrame to the list\n",
    "combined_df = pd.concat(modified_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avansa 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>ECLS 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>ElevateNC C4 M2</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>Elevate NC C4 M3</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Elevate NC C4 M4</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>HFK FL Regional Site Visit</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>HKF C10 S1</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>HKF C10 S2</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>HLR 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>HSPF C4 M1</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>HSPF C4 M2</td>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>IN PPC M5</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>MO SLR 2023</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>MO SLR 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>NCCCS M2</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>NCCCS M3</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>NCCCS M4</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>ND SLR 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>OH SLR</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>OK SLR 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>WSELR 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>WSSU M2 reuslts</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7232</th>\n",
       "      <td>WSSU M3</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7277</th>\n",
       "      <td>WSSU M4</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7327</th>\n",
       "      <td>WV SLR 2024</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           event event_type\n",
       "0                    Avansa 2024     annual\n",
       "731                    ECLS 2024     annual\n",
       "1379             ElevateNC C4 M2     cohort\n",
       "1651            Elevate NC C4 M3     cohort\n",
       "2025            Elevate NC C4 M4     cohort\n",
       "2329  HFK FL Regional Site Visit      other\n",
       "2446                  HKF C10 S1     cohort\n",
       "2782                  HKF C10 S2     cohort\n",
       "3132                    HLR 2024     annual\n",
       "3672                  HSPF C4 M1     cohort\n",
       "3966                  HSPF C4 M2     cohort\n",
       "4380                   IN PPC M5      other\n",
       "4515                 MO SLR 2023     annual\n",
       "4965                 MO SLR 2024     annual\n",
       "5285                    NCCCS M2      other\n",
       "5675                    NCCCS M3      other\n",
       "5775                    NCCCS M4      other\n",
       "5838                 ND SLR 2024     annual\n",
       "6458                      OH SLR      other\n",
       "6598                 OK SLR 2024     annual\n",
       "6920                  WSELR 2024     annual\n",
       "7112             WSSU M2 reuslts      other\n",
       "7232                     WSSU M3      other\n",
       "7277                     WSSU M4      other\n",
       "7327                 WV SLR 2024     annual"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_df.loc[:,'event_type'] = np.nan\n",
    "for i,j in enumerate(combined_df['event']):\n",
    "    \n",
    "    if re.search(r'\\d{4}', str(j)):\n",
    "        event_type = \"annual\"\n",
    "    elif re.search(r'C\\d{1,2}\\s?(M\\d{1,2})?', str(j)):\n",
    "        event_type = \"cohort\"\n",
    "    else:\n",
    "        event_type = \"other\"\n",
    "    combined_df.loc[i,'event_type'] = event_type\n",
    "\n",
    "event_review = combined_df.loc[:,['event','event_type']]\n",
    "event_review = event_review.drop_duplicates()\n",
    "event_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use classify response\n",
    "combined_df['data_type'] = combined_df['response'].apply(classify_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>event</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robin McConnell (Cnetral Piedmont)</td>\n",
       "      <td>Avanza Convening 2</td>\n",
       "      <td>5</td>\n",
       "      <td>Avansa 2024</td>\n",
       "      <td>quantitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheena Ashley (Central Piedmont)</td>\n",
       "      <td>Avanza Convening 2</td>\n",
       "      <td>4</td>\n",
       "      <td>Avansa 2024</td>\n",
       "      <td>quantitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Joevanne Estrada (Central Piedmont)</td>\n",
       "      <td>Avanza Convening 2</td>\n",
       "      <td>5</td>\n",
       "      <td>Avansa 2024</td>\n",
       "      <td>quantitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tracie Clark (Central Piedmont)</td>\n",
       "      <td>Avanza Convening 2</td>\n",
       "      <td>5</td>\n",
       "      <td>Avansa 2024</td>\n",
       "      <td>quantitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jennifer Recendez (Randolph CC)</td>\n",
       "      <td>Avanza Convening 2</td>\n",
       "      <td>5</td>\n",
       "      <td>Avansa 2024</td>\n",
       "      <td>quantitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7910</th>\n",
       "      <td>Anon</td>\n",
       "      <td>Please share any other comments and/or feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "      <td>qualitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>Anon</td>\n",
       "      <td>Please share any other comments and/or feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "      <td>qualitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>Anon</td>\n",
       "      <td>Please share any other comments and/or feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "      <td>qualitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>Anon</td>\n",
       "      <td>Please share any other comments and/or feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "      <td>qualitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>Anon</td>\n",
       "      <td>Please share any other comments and/or feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "      <td>qualitative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7915 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   respondent  \\\n",
       "0          Robin McConnell (Cnetral Piedmont)   \n",
       "1            Sheena Ashley (Central Piedmont)   \n",
       "2     Dr. Joevanne Estrada (Central Piedmont)   \n",
       "3             Tracie Clark (Central Piedmont)   \n",
       "4             Jennifer Recendez (Randolph CC)   \n",
       "...                                       ...   \n",
       "7910                                     Anon   \n",
       "7911                                     Anon   \n",
       "7912                                     Anon   \n",
       "7913                                     Anon   \n",
       "7914                                     Anon   \n",
       "\n",
       "                                               question response  \\\n",
       "0                                    Avanza Convening 2        5   \n",
       "1                                    Avanza Convening 2        4   \n",
       "2                                    Avanza Convening 2        5   \n",
       "3                                    Avanza Convening 2        5   \n",
       "4                                    Avanza Convening 2        5   \n",
       "...                                                 ...      ...   \n",
       "7910  Please share any other comments and/or feedbac...      NaN   \n",
       "7911  Please share any other comments and/or feedbac...      NaN   \n",
       "7912  Please share any other comments and/or feedbac...      NaN   \n",
       "7913  Please share any other comments and/or feedbac...      NaN   \n",
       "7914  Please share any other comments and/or feedbac...      NaN   \n",
       "\n",
       "              event     data_type  \n",
       "0     Avansa 2024    quantitative  \n",
       "1     Avansa 2024    quantitative  \n",
       "2     Avansa 2024    quantitative  \n",
       "3     Avansa 2024    quantitative  \n",
       "4     Avansa 2024    quantitative  \n",
       "...             ...           ...  \n",
       "7910  WV SLR 2024     qualitative  \n",
       "7911  WV SLR 2024     qualitative  \n",
       "7912  WV SLR 2024     qualitative  \n",
       "7913  WV SLR 2024     qualitative  \n",
       "7914  WV SLR 2024     qualitative  \n",
       "\n",
       "[7915 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning\n",
    "lookup = combined_df.loc[:,['question', 'data_type']]\n",
    "lookup = lookup.drop_duplicates()\n",
    "lookup = lookup[~lookup['data_type'].str.contains(\"missing\", regex=False)]\n",
    "mapping = lookup.set_index('question')['data_type'].to_dict()\n",
    "combined_df['data_type'] =  combined_df['data_type'].replace('missing', np.nan)\n",
    "combined_df['data_type'] = combined_df['data_type'].fillna(combined_df['question'].map(mapping))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ooking for Net Promoter Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#looking for net promoter questions\n",
    "combined_df.loc[combined_df['question'].str.contains('recommend ', regex=True), 'data_type'] = 'nps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export all data \n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\tableau\\survey view\\data sources')\n",
    "combined_df.to_excel('master_survey_sheet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split qualitative and quantitative data\n",
    "survey_data_qual = combined_df[combined_df['data_type'] == 'qualitative']\n",
    "survey_data_quant = combined_df[~(combined_df['data_type'] == 'qualitative')]\n",
    "survey_data_bool = combined_df[(combined_df['data_type'] == 'bool')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#export split files\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\tableau\\survey view\\data sources')\n",
    "survey_data_bool.to_excel('survey_data_bool.xlsx', index=False)\n",
    "survey_data_qual.to_excel('survey_data_qual.xlsx', index=False)\n",
    "survey_data_quant.to_excel('survey_data_quant.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest of this is Defunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all else qualitative\n",
    "survey_data['data_type'] = survey_data['response'].apply(\n",
    "    lambda x: 'quantitative' if isinstance(x, (int, float)) and str(x) != 'nan' else 'qualitative'\n",
    ")\n",
    "# survey_data.loc[isinstance(survey_data['response'], (int, float)), 'data_type'] = 'quantitative'\n",
    "# survey_data.loc[isinstance(survey_data['response'], str), 'data_type'] = 'qualitative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data['data_type'] = ''\n",
    "for i,j in enumerate(survey_data['response']):\n",
    "    # print(str(j))\n",
    "    # if isinstance(j, float):\n",
    "    #     try:\n",
    "    #         survey_data.loc[i, \"response\"] = str(j).astype(int)\n",
    "            \n",
    "    \n",
    "    #     except:\n",
    "    #         print(survey_data.loc[i,:])\n",
    "    #         print('not working')\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    survey_data.loc[isinstance(survey_data['response'], (int, float)), 'data_type'] = 'quantitative'\n",
    "    survey_data.loc[isinstance(survey_data['response'], str), 'data_type'] = 'qualitative'\n",
    "    # if isinstance(j,str):\n",
    "    #     survey_data.loc[i, \"data_type\"] = 'qualitative'\n",
    "    # elif isinstance(j, (int, float)):\n",
    "    #     survey_data.loc[i, \"data_type\"] = 'quantative'\n",
    "    # else:\n",
    "    #     print(str(j) + \" isn't either str or int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up')\n",
    "survey_data.to_excel('survey_data_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey data\\survey_data_monday_export_9_16.xlsx\"\n",
    "survey_update = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_surveys = survey_update['file_path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_files = []\n",
    "path_error = []\n",
    "files_list = {}\n",
    "for i,f in enumerate(file_paths_surveys):\n",
    "    # path = survey_update['file_path'].iloc[1]\n",
    "    # print(path)\n",
    "    path = f\n",
    "    \n",
    "    # print('###############')\n",
    "    # print(survey_update['event'].iloc[i])\n",
    "    # print(path)\n",
    "    try:\n",
    "        os.chdir(path)\n",
    "    except:\n",
    "        print('no')\n",
    "        path_error.append(path)\n",
    "        continue\n",
    "    files = glob.glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    if len(files) == 0:\n",
    "        zero_files.append(path)\n",
    "    elif len(files) == 2:\n",
    "        for option in files:\n",
    "            if 'data' in str(option):\n",
    "                files_list[path] = option\n",
    "    else:\n",
    "        files_list[path] = files[0]\n",
    "    # data = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination folder where you want to copy the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the destination folder if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(destination_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "didnt_work = []\n",
    "# Loop through each file path\n",
    "for k,v in files_list.items():\n",
    "    \n",
    "    file_path = os.path.join(k,v)\n",
    "    print(file_path)\n",
    "    try:\n",
    "        # Copy the file to the destination folder\n",
    "        shutil.copy(file_path, destination_folder)\n",
    "        print(f'Copied: {file_path} to {destination_folder}')\n",
    "    except Exception as e:\n",
    "        print(f'Error copying {file_path}: {e}')\n",
    "        didnt_work.append(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up\\edited\\HLR_2024_eval_results.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for col_name,col_data in df.items():\n",
    "    \n",
    "    res_list = []\n",
    "    quest_list = []\n",
    "    response_list = []\n",
    "    if col_name == df.columns[0]:\n",
    "        continue\n",
    "    n = len(df[df.columns[0]])\n",
    "    res_list.extend(df[df.columns[0]])\n",
    "    quest_list.extend([str(col_name)]*n)\n",
    "    response_list.extend(col_data.to_list())\n",
    "    df_to_append = pd.DataFrame({\"responder\":res_list, \"question\": quest_list , \"response\": response_list})\n",
    "    dfs.append(df_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('################')\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in multiple_files:\n",
    "    os.chdir(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_name(value):\n",
    "    try:\n",
    "        name = HumanName(value)\n",
    "        # If name parsing did not fail, it might be a name\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files = []\n",
    "dfs = []\n",
    "for i,f in enumerate(survey_update['file_path']):\n",
    "    # path = survey_update['file_path'].iloc[1]\n",
    "    # print(path)\n",
    "    path = f\n",
    "    break_main_loop = False\n",
    "    print('###############')\n",
    "    print(survey_update['event'].iloc[i])\n",
    "    print(path)\n",
    "    try:\n",
    "        os.chdir(path)\n",
    "    except:\n",
    "        print('no')\n",
    "        continue\n",
    "    files = glob.glob('*.xlsx')\n",
    "    if len(files) != 1:\n",
    "        # print(files)\n",
    "        # for file in files:\n",
    "        #     file_df = pd.read_excel(file)\n",
    "        #     print(file_df)\n",
    "        print(\"%%%%%\")\n",
    "        print(\"multiple files\")\n",
    "        print(\"%%%%%\")\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        multiple_files.append(path)\n",
    "        continue\n",
    "    else:\n",
    "        file = files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = pd.read_excel(file)\n",
    "    data_cl = data.dropna(how = 'all', axis = 1)\n",
    "    \n",
    "\n",
    "    ##THIS DOESNT WORK###\n",
    "    # # Find columns where the substring is found in the column names\n",
    "    # for name, col_values in data.cl.items():\n",
    "    #     check_list = col_values.to_list()\n",
    "    #     name_found = False\n",
    "    #     for check in check_list:\n",
    "    #         if is_name(str(check)):\n",
    "    #             name_column = name\n",
    "    #             name_found = True\n",
    "    #             break\n",
    "    #     if name_found == True:\n",
    "    #         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Looking for Committee member column to get respondents names as first column\n",
    "    matching_columns = [col for col in data_cl.columns if re.search(r'^[Cc]ommittee [Mm]ember', col)]\n",
    "    try:\n",
    "        first_col = matching_columns[0]\n",
    "    except:\n",
    "        print(\"col match method #2\")\n",
    "        # try:\n",
    "        summary_found = False\n",
    "        for col_name, col_data in data_cl.items():\n",
    "            print('***************************************')\n",
    "            print(col_name)\n",
    "            print(col_data)\n",
    "            print('***************************************')\n",
    "            print(summary_found)\n",
    "            if summary_found == True:\n",
    "                first_col = col_name\n",
    "                print(\"first column:\")\n",
    "                print(col_name)\n",
    "                print(\"______________________________________________________________________________\")\n",
    "                print(col_data)\n",
    "                print(\"______________________________________________________________________________\")\n",
    "                break\n",
    "            col_to_list = col_data.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            for col_val in col_to_list:\n",
    "                # print(col_val)\n",
    "                # if summary_found == True:\n",
    "                #     name_col = col_name\n",
    "                #     print(\"[\" + str(name_col) + \"]\"+ \" is what is being matched\")\n",
    "                #     print(col_data)\n",
    "                #     break\n",
    "                    \n",
    "                \n",
    "                if re.search(r'number of attendees|response rate', str(col_val).lower()):\n",
    "                    # print(str(col_val))\n",
    "                    summary_found = True\n",
    "                    print('col value that matches: ' + str(col_val).lower())\n",
    "                    # print(col_data)\n",
    "                    break\n",
    "            print(data_cl.columns[(len(data_cl.columns)-1)])\n",
    "            if col == data_cl.columns[(len(data_cl.columns)-1)] and summary_found ==  False:\n",
    "                print(\"no summary found\")\n",
    "                break_main_loop = True\n",
    "    \n",
    "        for ik, k in enumerate(data_cl[first_col]):\n",
    "            if 'attendees' in str(k) or 'response rate' in str(k).lower():\n",
    "                print('THIS ISNT RIGHT') \n",
    "                break_main_loop = True\n",
    "    if break_main_loop == True:\n",
    "        break\n",
    "\n",
    "            # print(\"first column: \" + str(start))\n",
    "            # print(data_cl.loc[:,name_col])\n",
    "        # except:\n",
    "        #     print('no matching columns')\n",
    "        #     # print(data.columns)\n",
    "        #     # print(data.iloc[:,0])\n",
    "        #     # print(data.iloc[:,1])\n",
    "        #     # print(data_cl)\n",
    "        #     break\n",
    "    \n",
    "    if first_col:\n",
    "        print('CONTINUE')\n",
    "        print(first_col)\n",
    "    else:\n",
    "        print('STOP')\n",
    "        # break\n",
    "    data_cl = data_cl.loc[:,first_col:]\n",
    "    \n",
    "    #     data_cl = data_cl.loc[:,first_col:]\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    #     print('new data frame')\n",
    "    #     print(data_cl)\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    # except:\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    #     print(\"something wrong, df below for reference\")\n",
    "    #     print(data_cl)\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    for ix,j in enumerate(data_cl[data_cl.columns[0]]):\n",
    "        # print(j)\n",
    "        if 'average' in str(j).lower():\n",
    "            stop = ix-1\n",
    "            break\n",
    "    data_cl = data_cl.iloc[:stop,:]\n",
    "    \n",
    "    data_cl = data_cl[~data_cl.iloc[:,3].astype(str).str.contains(\"sessions\", case = False, na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # data_cl[data_cl.columns[1]] = data_cl[data_cl.columns[1]].astype(int)\n",
    "    for col, data in data_cl.items():\n",
    "        # print(col)\n",
    "        # data  = data_cl[\"The Financial Reality of NC Community College Students\"]\n",
    "        data_int = data.dropna()\n",
    "        # print(data)\n",
    "        # data_int = data_int.astype(int)\n",
    "        # pd.api.types.is_integer_dtype(data)\n",
    "        try:\n",
    "            # Try to convert to int, if successful update the DataFrame\n",
    "            data_int = data_int.astype(int)\n",
    "        except ValueError:\n",
    "            # If conversion fails, convert to string\n",
    "            data_int = data_int.astype(str)\n",
    "        data_cl[col] = data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #gathering data to for export file\n",
    "    \n",
    "    for col, data in data_cl.items():\n",
    "        if col == data_cl.columns[0]:\n",
    "            # print(\"this worked\")\n",
    "            # print(col)\n",
    "            # print(data)\n",
    "            continue\n",
    "        # if str(col).strip() == \"Committee Member\":\n",
    "        #     continue\n",
    "\n",
    "        # print(data)\n",
    "        if pd.api.types.is_integer_dtype(data_cl[col]):\n",
    "            n = len(data)\n",
    "            data_type = ['quantitative']*n\n",
    "            event_name = [str(survey_update['event'].iloc[i])]*n\n",
    "            respondents = data_cl.iloc[0,:].to_list()\n",
    "            quest = [str(col)]*n\n",
    "            response = data.to_list()\n",
    "            \n",
    "        else:\n",
    "            n = len(data)\n",
    "            data_type = ['qualitative']*n\n",
    "            event_name = [str(survey_update['event'].iloc[i])]*n\n",
    "            respondents = data_cl.iloc[:,0].to_list()\n",
    "            quest = [str(col)]*n\n",
    "            response = data.to_list()\n",
    "        list_list = [data_type,event_name,respondents,quest,response]\n",
    "        if all(len(v) == n for v in list_list):\n",
    "            print('making df')\n",
    "            df = pd.DataFrame({'event': event_name, \n",
    "            'data_type': data_type, \n",
    "            'responder_name': respondents,\n",
    "            'question': quest,\n",
    "            'response': response})\n",
    "            dfs.append(df)\n",
    "            \n",
    "            # print('%%%%%%%')\n",
    "            # print('issue with: ' + str(survey_update['event'].iloc[i]))\n",
    "            # print(path)\n",
    "            # print('%%%%%%%')\n",
    "            # print(\"_______questions________\")\n",
    "            # print(quest)\n",
    "            # print(\"_______respondents_______\")\n",
    "            # print(respondents)\n",
    "            # break_main_loop = True\n",
    "            # break\n",
    "        else:\n",
    "            print('lengths dont match')\n",
    "            break\n",
    "        \n",
    "        \n",
    "        # event_list.extend(event_name)\n",
    "        # data_type_list.extend(data_type)\n",
    "        # responder_list.extend(respondents)\n",
    "        # question_list.extend(quest)\n",
    "        # response_list.extend(response)\n",
    "\n",
    "        # try:\n",
    "        #     df = pd.DataFrame({'event': event_list, \n",
    "        #     'data_type': data_type_list, \n",
    "        #     'responder_name': response,\n",
    "        #     'question': question_list,\n",
    "        #     'response': response_list})\n",
    "        # except:\n",
    "        #     print(\"event_list\" + \": \" +str(len(event_list)))\n",
    "        #     print(\"data_type_list\" + \": \" +str(len(data_type_list)))\n",
    "        #     print(\"responder_list\" + \": \" +str(len(responder_list)))\n",
    "        #     print(\"question_list\" + \": \" +str(len(question_list)))\n",
    "        #     print(\"response_list\" + \": \" +str(len(response_list)))\n",
    "\n",
    "        #     break\n",
    "        \n",
    "    if break_main_loop == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "   \n",
    "        \n",
    "# %%\n",
    "    for i,j in enumerate(data_cl['Commitee Member']):\n",
    "        list = [0,i]\n",
    "    \n",
    "    # data_cl.iloc[:,0].to_list()\n",
    "    print(data_cl.dtypes)\n",
    "    print(data_cl)\n",
    "    print('\\n')\n",
    "# print(\"Columns with missing values:\")\n",
    "# print(data.isnull().sum())\n",
    "# %%\n",
    "for d in data.columns:\n",
    "    print(d)\n",
    "    \n",
    "# %%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
