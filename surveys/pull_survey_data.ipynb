{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os, sys, json, datetime  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_response(j):\n",
    "    \n",
    "    if isinstance(j, (int, float)):\n",
    "        if isinstance(j, float) and str(j) == 'nan':\n",
    "            return 'missing'         \n",
    "        elif isinstance(j, (int, float)):\n",
    "            print(j)\n",
    "            return 'quantitative'\n",
    "    elif re.search(r'^yes|^no', str(j).lower().strip()):\n",
    "        return \"bool\"\n",
    "    else:        \n",
    "        return 'qualitative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab files from edited folder\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up\\edited')\n",
    "edited_files = glob.glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey formatter\n",
    "all_surveys = {}\n",
    "for file in tqdm(edited_files):\n",
    "    \n",
    "    # file = edited_files[0]\n",
    "    df = pd.read_excel(file)\n",
    "    print(\"##################\")\n",
    "    print(file)\n",
    "    print(df.columns[0])\n",
    "    print(\"\\n\")\n",
    "    dfs = []\n",
    "    for name, data in df.items():\n",
    "        if str(name) == 'respondent' or str(name).lower().strip() == 'name':\n",
    "            index_col = str(name)\n",
    "            continue\n",
    "        \n",
    "        n = len(data)\n",
    "        \n",
    "        respondents = df[index_col].to_list()\n",
    "        # print(respondents)\n",
    "        quest = [str(name)]*n\n",
    "        response = data.to_list()\n",
    "        df_app = pd.DataFrame({'respondent':respondents, 'question': quest, 'response': response})\n",
    "        dfs.append(df_app)\n",
    "    survey_data = pd.concat(dfs)\n",
    "    all_surveys[file] = survey_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull all survey data together\n",
    "modified_dfs = []\n",
    "for file, df in all_surveys.items():\n",
    "    df['event'] = str(file).split(\".\",1)[0].replace(\"_\", \" \").replace('eval', \"\").replace(r'results', '')  # Add new column with the filename\n",
    "    modified_dfs.append(df)    # Append modified DataFrame to the list\n",
    "combined_df = pd.concat(modified_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use classify response\n",
    "combined_df['data_type'] = combined_df['response'].apply(classify_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning\n",
    "lookup = combined_df.loc[:,['question', 'data_type']]\n",
    "lookup = lookup.drop_duplicates()\n",
    "lookup = lookup[~lookup['data_type'].str.contains(\"missing\", regex=False)]\n",
    "mapping = lookup.set_index('question')['data_type'].to_dict()\n",
    "combined_df['data_type'] =  combined_df['data_type'].replace('missing', np.nan)\n",
    "combined_df['data_type'] = combined_df['data_type'].fillna(combined_df['question'].map(mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ooking for Net Promoter Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for net promoter questions\n",
    "combined_df.loc[combined_df['question'].str.contains('recommend ', regex=True), 'data_type'] = 'nps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export all data \n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\tableau\\survey view\\data sources')\n",
    "combined_df.to_csv('master_survey_sheet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split qualitative and quantitative data\n",
    "survey_data_qual = combined_df[combined_df['data_type'] == 'qualitative']\n",
    "survey_data_quant = combined_df[~(combined_df['data_type'] == 'qualitative')]\n",
    "\n",
    "#export split files\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\tableau\\survey view\\data sources')\n",
    "survey_data_qual.to_excel('survey_data_qual.xlsx', index=False)\n",
    "survey_data_quant.to_excel('survey_data_quant.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest of this is Defunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all else qualitative\n",
    "survey_data['data_type'] = survey_data['response'].apply(\n",
    "    lambda x: 'quantitative' if isinstance(x, (int, float)) and str(x) != 'nan' else 'qualitative'\n",
    ")\n",
    "# survey_data.loc[isinstance(survey_data['response'], (int, float)), 'data_type'] = 'quantitative'\n",
    "# survey_data.loc[isinstance(survey_data['response'], str), 'data_type'] = 'qualitative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data['data_type'] = ''\n",
    "for i,j in enumerate(survey_data['response']):\n",
    "    # print(str(j))\n",
    "    # if isinstance(j, float):\n",
    "    #     try:\n",
    "    #         survey_data.loc[i, \"response\"] = str(j).astype(int)\n",
    "            \n",
    "    \n",
    "    #     except:\n",
    "    #         print(survey_data.loc[i,:])\n",
    "    #         print('not working')\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    survey_data.loc[isinstance(survey_data['response'], (int, float)), 'data_type'] = 'quantitative'\n",
    "    survey_data.loc[isinstance(survey_data['response'], str), 'data_type'] = 'qualitative'\n",
    "    # if isinstance(j,str):\n",
    "    #     survey_data.loc[i, \"data_type\"] = 'qualitative'\n",
    "    # elif isinstance(j, (int, float)):\n",
    "    #     survey_data.loc[i, \"data_type\"] = 'quantative'\n",
    "    # else:\n",
    "    #     print(str(j) + \" isn't either str or int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up')\n",
    "survey_data.to_excel('survey_data_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey data\\survey_data_monday_export_9_16.xlsx\"\n",
    "survey_update = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_surveys = survey_update['file_path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_files = []\n",
    "path_error = []\n",
    "files_list = {}\n",
    "for i,f in enumerate(file_paths_surveys):\n",
    "    # path = survey_update['file_path'].iloc[1]\n",
    "    # print(path)\n",
    "    path = f\n",
    "    \n",
    "    # print('###############')\n",
    "    # print(survey_update['event'].iloc[i])\n",
    "    # print(path)\n",
    "    try:\n",
    "        os.chdir(path)\n",
    "    except:\n",
    "        print('no')\n",
    "        path_error.append(path)\n",
    "        continue\n",
    "    files = glob.glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    if len(files) == 0:\n",
    "        zero_files.append(path)\n",
    "    elif len(files) == 2:\n",
    "        for option in files:\n",
    "            if 'data' in str(option):\n",
    "                files_list[path] = option\n",
    "    else:\n",
    "        files_list[path] = files[0]\n",
    "    # data = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination folder where you want to copy the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the destination folder if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(destination_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "didnt_work = []\n",
    "# Loop through each file path\n",
    "for k,v in files_list.items():\n",
    "    \n",
    "    file_path = os.path.join(k,v)\n",
    "    print(file_path)\n",
    "    try:\n",
    "        # Copy the file to the destination folder\n",
    "        shutil.copy(file_path, destination_folder)\n",
    "        print(f'Copied: {file_path} to {destination_folder}')\n",
    "    except Exception as e:\n",
    "        print(f'Error copying {file_path}: {e}')\n",
    "        didnt_work.append(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\surveys\\survey files to clean up\\edited\\HLR_2024_eval_results.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for col_name,col_data in df.items():\n",
    "    \n",
    "    res_list = []\n",
    "    quest_list = []\n",
    "    response_list = []\n",
    "    if col_name == df.columns[0]:\n",
    "        continue\n",
    "    n = len(df[df.columns[0]])\n",
    "    res_list.extend(df[df.columns[0]])\n",
    "    quest_list.extend([str(col_name)]*n)\n",
    "    response_list.extend(col_data.to_list())\n",
    "    df_to_append = pd.DataFrame({\"responder\":res_list, \"question\": quest_list , \"response\": response_list})\n",
    "    dfs.append(df_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('################')\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in multiple_files:\n",
    "    os.chdir(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_name(value):\n",
    "    try:\n",
    "        name = HumanName(value)\n",
    "        # If name parsing did not fail, it might be a name\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files = []\n",
    "dfs = []\n",
    "for i,f in enumerate(survey_update['file_path']):\n",
    "    # path = survey_update['file_path'].iloc[1]\n",
    "    # print(path)\n",
    "    path = f\n",
    "    break_main_loop = False\n",
    "    print('###############')\n",
    "    print(survey_update['event'].iloc[i])\n",
    "    print(path)\n",
    "    try:\n",
    "        os.chdir(path)\n",
    "    except:\n",
    "        print('no')\n",
    "        continue\n",
    "    files = glob.glob('*.xlsx')\n",
    "    if len(files) != 1:\n",
    "        # print(files)\n",
    "        # for file in files:\n",
    "        #     file_df = pd.read_excel(file)\n",
    "        #     print(file_df)\n",
    "        print(\"%%%%%\")\n",
    "        print(\"multiple files\")\n",
    "        print(\"%%%%%\")\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        multiple_files.append(path)\n",
    "        continue\n",
    "    else:\n",
    "        file = files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = pd.read_excel(file)\n",
    "    data_cl = data.dropna(how = 'all', axis = 1)\n",
    "    \n",
    "\n",
    "    ##THIS DOESNT WORK###\n",
    "    # # Find columns where the substring is found in the column names\n",
    "    # for name, col_values in data.cl.items():\n",
    "    #     check_list = col_values.to_list()\n",
    "    #     name_found = False\n",
    "    #     for check in check_list:\n",
    "    #         if is_name(str(check)):\n",
    "    #             name_column = name\n",
    "    #             name_found = True\n",
    "    #             break\n",
    "    #     if name_found == True:\n",
    "    #         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Looking for Committee member column to get respondents names as first column\n",
    "    matching_columns = [col for col in data_cl.columns if re.search(r'^[Cc]ommittee [Mm]ember', col)]\n",
    "    try:\n",
    "        first_col = matching_columns[0]\n",
    "    except:\n",
    "        print(\"col match method #2\")\n",
    "        # try:\n",
    "        summary_found = False\n",
    "        for col_name, col_data in data_cl.items():\n",
    "            print('***************************************')\n",
    "            print(col_name)\n",
    "            print(col_data)\n",
    "            print('***************************************')\n",
    "            print(summary_found)\n",
    "            if summary_found == True:\n",
    "                first_col = col_name\n",
    "                print(\"first column:\")\n",
    "                print(col_name)\n",
    "                print(\"______________________________________________________________________________\")\n",
    "                print(col_data)\n",
    "                print(\"______________________________________________________________________________\")\n",
    "                break\n",
    "            col_to_list = col_data.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            for col_val in col_to_list:\n",
    "                # print(col_val)\n",
    "                # if summary_found == True:\n",
    "                #     name_col = col_name\n",
    "                #     print(\"[\" + str(name_col) + \"]\"+ \" is what is being matched\")\n",
    "                #     print(col_data)\n",
    "                #     break\n",
    "                    \n",
    "                \n",
    "                if re.search(r'number of attendees|response rate', str(col_val).lower()):\n",
    "                    # print(str(col_val))\n",
    "                    summary_found = True\n",
    "                    print('col value that matches: ' + str(col_val).lower())\n",
    "                    # print(col_data)\n",
    "                    break\n",
    "            print(data_cl.columns[(len(data_cl.columns)-1)])\n",
    "            if col == data_cl.columns[(len(data_cl.columns)-1)] and summary_found ==  False:\n",
    "                print(\"no summary found\")\n",
    "                break_main_loop = True\n",
    "    \n",
    "        for ik, k in enumerate(data_cl[first_col]):\n",
    "            if 'attendees' in str(k) or 'response rate' in str(k).lower():\n",
    "                print('THIS ISNT RIGHT') \n",
    "                break_main_loop = True\n",
    "    if break_main_loop == True:\n",
    "        break\n",
    "\n",
    "            # print(\"first column: \" + str(start))\n",
    "            # print(data_cl.loc[:,name_col])\n",
    "        # except:\n",
    "        #     print('no matching columns')\n",
    "        #     # print(data.columns)\n",
    "        #     # print(data.iloc[:,0])\n",
    "        #     # print(data.iloc[:,1])\n",
    "        #     # print(data_cl)\n",
    "        #     break\n",
    "    \n",
    "    if first_col:\n",
    "        print('CONTINUE')\n",
    "        print(first_col)\n",
    "    else:\n",
    "        print('STOP')\n",
    "        # break\n",
    "    data_cl = data_cl.loc[:,first_col:]\n",
    "    \n",
    "    #     data_cl = data_cl.loc[:,first_col:]\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    #     print('new data frame')\n",
    "    #     print(data_cl)\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    # except:\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    #     print(\"something wrong, df below for reference\")\n",
    "    #     print(data_cl)\n",
    "    #     print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    for ix,j in enumerate(data_cl[data_cl.columns[0]]):\n",
    "        # print(j)\n",
    "        if 'average' in str(j).lower():\n",
    "            stop = ix-1\n",
    "            break\n",
    "    data_cl = data_cl.iloc[:stop,:]\n",
    "    \n",
    "    data_cl = data_cl[~data_cl.iloc[:,3].astype(str).str.contains(\"sessions\", case = False, na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # data_cl[data_cl.columns[1]] = data_cl[data_cl.columns[1]].astype(int)\n",
    "    for col, data in data_cl.items():\n",
    "        # print(col)\n",
    "        # data  = data_cl[\"The Financial Reality of NC Community College Students\"]\n",
    "        data_int = data.dropna()\n",
    "        # print(data)\n",
    "        # data_int = data_int.astype(int)\n",
    "        # pd.api.types.is_integer_dtype(data)\n",
    "        try:\n",
    "            # Try to convert to int, if successful update the DataFrame\n",
    "            data_int = data_int.astype(int)\n",
    "        except ValueError:\n",
    "            # If conversion fails, convert to string\n",
    "            data_int = data_int.astype(str)\n",
    "        data_cl[col] = data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #gathering data to for export file\n",
    "    \n",
    "    for col, data in data_cl.items():\n",
    "        if col == data_cl.columns[0]:\n",
    "            # print(\"this worked\")\n",
    "            # print(col)\n",
    "            # print(data)\n",
    "            continue\n",
    "        # if str(col).strip() == \"Committee Member\":\n",
    "        #     continue\n",
    "\n",
    "        # print(data)\n",
    "        if pd.api.types.is_integer_dtype(data_cl[col]):\n",
    "            n = len(data)\n",
    "            data_type = ['quantitative']*n\n",
    "            event_name = [str(survey_update['event'].iloc[i])]*n\n",
    "            respondents = data_cl.iloc[0,:].to_list()\n",
    "            quest = [str(col)]*n\n",
    "            response = data.to_list()\n",
    "            \n",
    "        else:\n",
    "            n = len(data)\n",
    "            data_type = ['qualitative']*n\n",
    "            event_name = [str(survey_update['event'].iloc[i])]*n\n",
    "            respondents = data_cl.iloc[:,0].to_list()\n",
    "            quest = [str(col)]*n\n",
    "            response = data.to_list()\n",
    "        list_list = [data_type,event_name,respondents,quest,response]\n",
    "        if all(len(v) == n for v in list_list):\n",
    "            print('making df')\n",
    "            df = pd.DataFrame({'event': event_name, \n",
    "            'data_type': data_type, \n",
    "            'responder_name': respondents,\n",
    "            'question': quest,\n",
    "            'response': response})\n",
    "            dfs.append(df)\n",
    "            \n",
    "            # print('%%%%%%%')\n",
    "            # print('issue with: ' + str(survey_update['event'].iloc[i]))\n",
    "            # print(path)\n",
    "            # print('%%%%%%%')\n",
    "            # print(\"_______questions________\")\n",
    "            # print(quest)\n",
    "            # print(\"_______respondents_______\")\n",
    "            # print(respondents)\n",
    "            # break_main_loop = True\n",
    "            # break\n",
    "        else:\n",
    "            print('lengths dont match')\n",
    "            break\n",
    "        \n",
    "        \n",
    "        # event_list.extend(event_name)\n",
    "        # data_type_list.extend(data_type)\n",
    "        # responder_list.extend(respondents)\n",
    "        # question_list.extend(quest)\n",
    "        # response_list.extend(response)\n",
    "\n",
    "        # try:\n",
    "        #     df = pd.DataFrame({'event': event_list, \n",
    "        #     'data_type': data_type_list, \n",
    "        #     'responder_name': response,\n",
    "        #     'question': question_list,\n",
    "        #     'response': response_list})\n",
    "        # except:\n",
    "        #     print(\"event_list\" + \": \" +str(len(event_list)))\n",
    "        #     print(\"data_type_list\" + \": \" +str(len(data_type_list)))\n",
    "        #     print(\"responder_list\" + \": \" +str(len(responder_list)))\n",
    "        #     print(\"question_list\" + \": \" +str(len(question_list)))\n",
    "        #     print(\"response_list\" + \": \" +str(len(response_list)))\n",
    "\n",
    "        #     break\n",
    "        \n",
    "    if break_main_loop == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "   \n",
    "        \n",
    "# %%\n",
    "    for i,j in enumerate(data_cl['Commitee Member']):\n",
    "        list = [0,i]\n",
    "    \n",
    "    # data_cl.iloc[:,0].to_list()\n",
    "    print(data_cl.dtypes)\n",
    "    print(data_cl)\n",
    "    print('\\n')\n",
    "# print(\"Columns with missing values:\")\n",
    "# print(data.isnull().sum())\n",
    "# %%\n",
    "for d in data.columns:\n",
    "    print(d)\n",
    "    \n",
    "# %%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
