{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, re  # Provides OS-dependent functionality, system-specific parameters, JSON handling\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import time\n",
    "import glob\n",
    "import xlsxwriter\n",
    "from tqdm import tqdm\n",
    "from datetime import date #date/time manipulation\n",
    "import lxml\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "from cprl_functions.state_capture import thi_states,state_ref, state_coding, state_coding_r, state_pat, state_abv_pat, state_abbreviations\n",
    "from cprl_functions.text_printing import bordered\n",
    "from cprl_functions.defined_functions import create_pk, add_seats, get_recent_file\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_row(row, string_column):\n",
    "    # Check conditions using an if-else statement\n",
    "    if re.search(r'[Hh]ouse|[Rr]epresentative', str(row[string_column])):\n",
    "        return \"House\"\n",
    "    elif re.search(r'[Ss]enate', str(row[string_column])):\n",
    "        return \"Senate\"\n",
    "    else:\n",
    "        return 'Unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ballotpedia poll\n",
    "\n",
    "this will be commented out until need for a repull, use the loaded file in the \"JSON File Load\" section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitial Pull\n",
    "\n",
    "# #initializing webscraping info\n",
    "# soup_url = r'https://ballotpedia.org/State_Legislative_Districts'\n",
    "# all_districts = []\n",
    "# response = requests.get(soup_url, verify = False)\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# state_districts = soup.find_all(\"a\", href = True)\n",
    "# h_refs = []\n",
    "# for url in state_districts:\n",
    "#     if 'state legislative districts' in str(url):\n",
    "#         # print(url)\n",
    "#         base = \"https://ballotpedia.org/\"\n",
    "#         full_url = base + str(url.text).replace(' ',\"_\")\n",
    "#         h_refs.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Webscrape\n",
    "\n",
    "\n",
    "# Fetches all of the districts (commented out until needed to repull)\n",
    "# for ref in h_refs:\n",
    "#     url = ref\n",
    "    \n",
    "#     page = requests.get(url)\n",
    "    \n",
    "#     os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\txt files for troubleshooting')\n",
    "\n",
    "#     # Write the page's text content to a file\n",
    "#     # with open('output_soup_strainer.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "#     #     f.write(page.text)\n",
    "#     # print(page.content)\n",
    "#     table_strainer = SoupStrainer('table', id='officeholder-table')\n",
    "#     page_soup = BeautifulSoup(page.content, 'html.parser', parse_only=table_strainer)\n",
    "\n",
    "#     # print(page_soup.content)\n",
    "#     # print(type(page_soup))\n",
    "#     districts = page_soup.find_all(\"a\")\n",
    "#     total_districts = []\n",
    "#     # print(page_soup.prettify())\n",
    "#     for d in districts:\n",
    "#         total_districts.append(d.text)\n",
    "#         # print(d.text)\n",
    "#     all_districts.extend(total_districts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON File Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data to JSON file\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\json save data')\n",
    "# with open(f\"all_districts_{str(date.today()).replace('-', '_')}.json\", \"w\") as f:\n",
    "#     json.dump(all_districts, f)\n",
    "#     save_file_name = f.name\n",
    "#     print(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_districts_2024_11_22.json\n"
     ]
    }
   ],
   "source": [
    "#loading districts webscraping data\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\json save data')\n",
    "json_files = glob.glob('all_districts_*.json')\n",
    "\n",
    "max_mtime = 0\n",
    "for dirname,subdirs,files in os.walk(\".\"):\n",
    "    for fname in files:\n",
    "        full_path = os.path.join(dirname, fname)\n",
    "        mtime = os.stat(full_path).st_mtime\n",
    "        if mtime > max_mtime:\n",
    "            max_mtime = mtime\n",
    "            max_dir = dirname\n",
    "            max_file = fname\n",
    "save_file_name = max_file\n",
    "print(save_file_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(f'{save_file_name}', \"r\") as f:\n",
    "    all_districts = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Curate df for Seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull together intitials for values\n",
    "state_intitals = []\n",
    "for i,j in enumerate(all_districts):\n",
    "    state_match = re.findall(state_pat, str(j))[0]\n",
    "    state = state_match.strip()\n",
    "    state_ab = state_ref.get(state)\n",
    "    state_intitals.append(state_ab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and clean districts data\n",
    "districts_w_intials = pd.DataFrame({'state_abbreviation': state_intitals,'district_string': all_districts})\n",
    "districts_w_intials = districts_w_intials[~districts_w_intials['district_string'].str.contains(r'[Hh]istorical|9[AB]{1}', regex=True)]\n",
    "thi_state_districts = districts_w_intials[districts_w_intials['state_abbreviation'].isin(thi_states)]\n",
    "\n",
    "thi_state_districts.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "thi_state_districts['chamber'] = thi_state_districts.apply(\n",
    "    filter_row, args=('district_string',), axis=1\n",
    ")\n",
    "\n",
    "thi_state_districts[\"district\"] = thi_state_districts[\"district_string\"].str.extractall(r\"(\\d+)\").unstack().fillna('').apply(' '.join, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary_key, district_code, state_abbreviation, district_string, chamber, district, state_code, chamber_code\n"
     ]
    }
   ],
   "source": [
    "#create pk for leg seats from ballot pedia\n",
    "\n",
    "leg_keys, leg_keys_dupes = create_pk(thi_state_districts, 'district', 'chamber')\n",
    "\n",
    "# leg_lookup = pd.concat([leg_keys_wseats,leg_keys_dupes_wseats])\n",
    "leg_lookup = pd.concat([leg_keys,leg_keys_dupes]).reset_index(drop = True)\n",
    "print(*leg_keys_dupes, sep = ', ')\n",
    "\n",
    "#uncomment for help troubleshooting\n",
    "#  os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data')\n",
    "# leg_lookup.to_csv('leg_lookup.csv')\n",
    "\n",
    "\n",
    "\n",
    "#get states with multi_seat legislature\n",
    "multi_seats = leg_lookup[leg_lookup['primary_key'].str.startswith(('430','571'))]\n",
    "multi_seats = list(set(multi_seats['primary_key'].to_list()))\n",
    "\n",
    "#assign seats\n",
    "leg_lookup['seat'] = np.nan\n",
    "for m in multi_seats:\n",
    "    n = [1]\n",
    "    \n",
    "    #grab all of the pks that match m\n",
    "    leg_lookup_m = leg_lookup[leg_lookup['primary_key'] == m]\n",
    "    \n",
    "    #create dict to change values\n",
    "    new_values = {index: i for i, (index, row) in enumerate(leg_lookup_m.iterrows(), start=1)}\n",
    "    leg_lookup.update(pd.DataFrame({'seat': new_values}).astype(str))\n",
    "\n",
    "    \n",
    "    # for row_i,seat in new_values.items():\n",
    "    #     leg_lookup.loc[row_i, 'seat'] = str(seat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_pk', 'primary_key', 'district_code', 'state_abbreviation',\n",
       "       'district_string', 'chamber', 'district', 'state_code', 'chamber_code',\n",
       "       'seat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "#create full_pk for leg_lookup\n",
    "\n",
    "leg_lookup = leg_lookup.copy()\n",
    "# leg_lookup[leg_lookup['seat'].isnull(), 'full_pk'] = leg_lookup['primary_key'] + '00'\n",
    "\n",
    "leg_lookup.loc[leg_lookup['seat'].notna(), 'full_pk'] = leg_lookup['primary_key'] + \"0\" + leg_lookup['seat']\n",
    "leg_lookup.loc[leg_lookup['seat'].isnull(), 'full_pk'] = leg_lookup.loc[leg_lookup['seat'].isnull(), 'primary_key'] + '00'\n",
    "\n",
    "\n",
    "\n",
    "# Move the full_pk column to the first position\n",
    "column_to_move = leg_lookup.pop('full_pk')\n",
    "leg_lookup.insert(0, 'full_pk', column_to_move)\n",
    "\n",
    "leg_lookup.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing actual ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in current year file\n",
    "path = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\all_legs_files\\2025\"\n",
    "all_leg_data = get_recent_file(r'*.xlsx', path)\n",
    "all_leg_df = pd.read_excel(all_leg_data)\n",
    "\n",
    "\n",
    "all_leg_df.columns = [x.lower() for x in all_leg_df.columns]\n",
    "# all_leg_df = all_leg_df.iloc[:,2:].reset_index(drop = True)\n",
    "\n",
    "\n",
    "all_leg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matching files\n",
      "**/*\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# only for if you have all records\n",
    "#getting and creating key for all leg files\n",
    "# dir = r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\all_legs_files'\n",
    "# all_leg_data = get_recent_file('*.xlsx', dir)\n",
    "\n",
    "# all_leg_data = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\all_legs_files\\all_leg_records.xlsx\"\n",
    "\n",
    "\n",
    "# all_leg_df = pd.read_excel(all_leg_data)\n",
    "# all_leg_df.columns = [x.lower() for x in all_leg_df.columns]\n",
    "# all_leg_df = all_leg_df.iloc[:,2:].reset_index(drop = True)\n",
    "\n",
    "# all_leg_df = all_leg_df[all_leg_df['recorded_year']==2025].reset_index(drop=True)\n",
    "# all_leg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#extract district from district string and replace \n",
    "# all_leg_df[\"district\"] = all_leg_df[\"district\"].str.extractall(r\"(\\d+)\")[0].unstack().fillna('').apply(' '.join, 1)\n",
    "# all_leg_df.drop(['District'], axis = 1)\n",
    "\n",
    "# all_leg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEPRECATED all_legs already has pk\n",
    "\n",
    "#bring in leg files\n",
    "# all_leg_wkey, all_leg_dupes_wkey = create_pk(all_leg_df, 'district', 'chamber')\n",
    "# all_leg_wkey, all_leg_dupes_wkey = add_seats(all_leg_wkey, all_leg_dupes_wkey, 'First Name', 'Last Name', keep_names = True)\n",
    "\n",
    "#pull back in all people into one file\n",
    "# all_leg_lookup = pd.concat([all_leg_wkey, all_leg_dupes_wkey]).reset_index(drop = True)\n",
    "# all_leg_lookup.drop(['full_pk'], axis = 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something wrong\n",
      "nannannan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_pk</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>district_code</th>\n",
       "      <th>state abbreviation</th>\n",
       "      <th>chamber</th>\n",
       "      <th>title</th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>party</th>\n",
       "      <th>district</th>\n",
       "      <th>date assumed office</th>\n",
       "      <th>name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>leader</th>\n",
       "      <th>state_code</th>\n",
       "      <th>chamber_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006300</td>\n",
       "      <td>100063</td>\n",
       "      <td>63.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>House</td>\n",
       "      <td>Alabama Representative</td>\n",
       "      <td>Cynthia</td>\n",
       "      <td>Almond</td>\n",
       "      <td>Republican</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>AL Rep. Cynthia Almond (R-AL-063)</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006600</td>\n",
       "      <td>100066</td>\n",
       "      <td>66.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>House</td>\n",
       "      <td>Alabama Representative</td>\n",
       "      <td>Alan</td>\n",
       "      <td>Baker</td>\n",
       "      <td>Republican</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>AL Rep. Alan Baker (R-AL-066)</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004900</td>\n",
       "      <td>100049</td>\n",
       "      <td>49.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>House</td>\n",
       "      <td>Alabama Representative</td>\n",
       "      <td>Russell</td>\n",
       "      <td>Bedsole</td>\n",
       "      <td>Republican</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>AL Rep. Russell Bedsole (R-AL-049)</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008000</td>\n",
       "      <td>100080</td>\n",
       "      <td>80.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>House</td>\n",
       "      <td>Alabama Representative</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Blackshear</td>\n",
       "      <td>Republican</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>AL Rep. Chris Blackshear (R-AL-080)</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006100</td>\n",
       "      <td>100061</td>\n",
       "      <td>61.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>House</td>\n",
       "      <td>Alabama Representative</td>\n",
       "      <td>Ronald</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>Republican</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>AL Rep. Ronald \"Ron\" Bolton (R-AL-061)</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>57101501</td>\n",
       "      <td>571015</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WV</td>\n",
       "      <td>Senate</td>\n",
       "      <td>West Virginia Senator</td>\n",
       "      <td>Darren</td>\n",
       "      <td>Thorne</td>\n",
       "      <td>Republican</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>WV Sen. Darren Thorne (R-WV-015)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>57100102</td>\n",
       "      <td>571001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WV</td>\n",
       "      <td>Senate</td>\n",
       "      <td>West Virginia Senator</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Weld</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>WV Sen. Ryan Weld (R-WV-001)</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>57101502</td>\n",
       "      <td>571015</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WV</td>\n",
       "      <td>Senate</td>\n",
       "      <td>West Virginia Senator</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Willis</td>\n",
       "      <td>Republican</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>WV Sen. Thomas \"Tom\" Willis (R-WV-015)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>57100502</td>\n",
       "      <td>571005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WV</td>\n",
       "      <td>Senate</td>\n",
       "      <td>West Virginia Senator</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Woelfel</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>WV Sen. Michael \"Mike\" Woelfel (D-WV-005)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>57101002</td>\n",
       "      <td>571010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>WV</td>\n",
       "      <td>Senate</td>\n",
       "      <td>West Virginia Senator</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Woodrum</td>\n",
       "      <td>Republican</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>WV Sen. Jack Woodrum (R-WV-010)</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_pk primary_key  district_code state abbreviation chamber  \\\n",
       "0     10006300      100063           63.0                 AL   House   \n",
       "1     10006600      100066           66.0                 AL   House   \n",
       "2     10004900      100049           49.0                 AL   House   \n",
       "3     10008000      100080           80.0                 AL   House   \n",
       "4     10006100      100061           61.0                 AL   House   \n",
       "...        ...         ...            ...                ...     ...   \n",
       "1980  57101501      571015           15.0                 WV  Senate   \n",
       "1981  57100102      571001            1.0                 WV  Senate   \n",
       "1982  57101502      571015           15.0                 WV  Senate   \n",
       "1983  57100502      571005            5.0                 WV  Senate   \n",
       "1984  57101002      571010           10.0                 WV  Senate   \n",
       "\n",
       "                       title first name   last name       party  district  \\\n",
       "0     Alabama Representative    Cynthia      Almond  Republican      63.0   \n",
       "1     Alabama Representative       Alan       Baker  Republican      66.0   \n",
       "2     Alabama Representative    Russell     Bedsole  Republican      49.0   \n",
       "3     Alabama Representative      Chris  Blackshear  Republican      80.0   \n",
       "4     Alabama Representative     Ronald      Bolton  Republican      61.0   \n",
       "...                      ...        ...         ...         ...       ...   \n",
       "1980   West Virginia Senator     Darren      Thorne  Republican      15.0   \n",
       "1981   West Virginia Senator       Ryan        Weld  Republican       1.0   \n",
       "1982   West Virginia Senator     Thomas      Willis  Republican      15.0   \n",
       "1983   West Virginia Senator    Michael     Woelfel    Democrat       5.0   \n",
       "1984   West Virginia Senator       Jack     Woodrum  Republican      10.0   \n",
       "\n",
       "      date assumed office                                       name  tenure  \\\n",
       "0                    2021          AL Rep. Cynthia Almond (R-AL-063)       4   \n",
       "1                    2006              AL Rep. Alan Baker (R-AL-066)      19   \n",
       "2                    2020         AL Rep. Russell Bedsole (R-AL-049)       5   \n",
       "3                    2016        AL Rep. Chris Blackshear (R-AL-080)       9   \n",
       "4                    2022     AL Rep. Ronald \"Ron\" Bolton (R-AL-061)       3   \n",
       "...                   ...                                        ...     ...   \n",
       "1980                 2025           WV Sen. Darren Thorne (R-WV-015)       0   \n",
       "1981                 2016               WV Sen. Ryan Weld (R-WV-001)       9   \n",
       "1982                 2024     WV Sen. Thomas \"Tom\" Willis (R-WV-015)       1   \n",
       "1983                 2024  WV Sen. Michael \"Mike\" Woelfel (D-WV-005)       1   \n",
       "1984                 2020            WV Sen. Jack Woodrum (R-WV-010)       5   \n",
       "\n",
       "     leader  state_code  chamber_code  \n",
       "0       NaN        10.0           0.0  \n",
       "1       NaN        10.0           0.0  \n",
       "2       NaN        10.0           0.0  \n",
       "3       NaN        10.0           0.0  \n",
       "4       NaN        10.0           0.0  \n",
       "...     ...         ...           ...  \n",
       "1980    NaN        57.0           1.0  \n",
       "1981    NaN        57.0           1.0  \n",
       "1982    NaN        57.0           1.0  \n",
       "1983    NaN        57.0           1.0  \n",
       "1984    NaN        57.0           1.0  \n",
       "\n",
       "[1985 rows x 16 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make dictionary to show full pks available at each primary key\n",
    "leg_lookbook = leg_lookup.groupby(['primary_key'])['full_pk'].apply(list).reset_index()\n",
    "leg_dict = dict(zip(leg_lookbook['primary_key'], leg_lookbook['full_pk']))\n",
    "\n",
    "#go through legislator data and apply\n",
    "all_leg_df['full_pk'] = np.nan\n",
    "for i,j in enumerate(all_leg_df['primary_key']):\n",
    "    # print(type(j))\n",
    "    j_alt = str(j)\n",
    "    # continue\n",
    "    value = leg_dict.get(j_alt)\n",
    "    # print(type(value))\n",
    "    if value is None:\n",
    "        print('something wrong')\n",
    "        print(j)\n",
    "        # print(all_leg_df[i,['first name','last name', 'tenure']])\n",
    "        # print(all_leg_lookup.iloc[i,:])\n",
    "        continue\n",
    "        # trouble.append(j)\n",
    "    elif len(value) == 1:\n",
    "        full_pk = j_alt + \"00\"\n",
    "    elif len(value) > 1:\n",
    "        names = sorted(all_leg_df[all_leg_df['primary_key']==j]['last name'].to_list())\n",
    "        row_name = all_leg_df.loc[i,'last name']\n",
    "        for ni, name in enumerate(names):\n",
    "            if name == row_name:\n",
    "                # print(True)\n",
    "                if ni == 0:\n",
    "                    seat = 1\n",
    "                    break\n",
    "                elif ni == 1:\n",
    "                    seat = 2\n",
    "                    break\n",
    "        full_pk = j_alt + \"0\" + str(seat)\n",
    "    all_leg_df.loc[i,['full_pk']] = full_pk\n",
    "\n",
    "\n",
    "#this is the final full_pk for the year\n",
    "\n",
    "# Move the full_pk column to the first position\n",
    "column_to_move = all_leg_df.pop('full_pk')\n",
    "all_leg_df.insert(0, 'full_pk', column_to_move)\n",
    "all_leg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export Final Data\n",
    "from datetime import date\n",
    "file_name = f'leg_lookup_{str(date.today()).replace('-','_')}.csv'\n",
    "file_name_ex = f'leg_lookup_{str(date.today()).replace('-','_')}.xlsx'\n",
    "all_leg_df.to_csv(fr'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors\\legislator lookup\\{file_name}', index = False)\n",
    "all_leg_df.to_excel(fr'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors\\legislator lookup\\{file_name_ex}', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW END (2/3/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#uncomment for help troubleshooting\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data')\n",
    "# all_leg_lookup.to_csv('all_leg_lookup.csv')\n",
    "\n",
    "#grab cols from legislators data\n",
    "all_leg_lookup_for_merge = all_leg_lookup.loc[:,['primary_key', 'first name', 'last name']]\n",
    "#grab cols from seats\n",
    "leg_lookup_for_merge = leg_lookup.loc[:,['primary_key','state_abbreviation']] \n",
    "\n",
    "#merge data together\n",
    "merge_1 = pd.merge(leg_lookup_for_merge, all_leg_lookup_for_merge, how='left', left_on='primary_key', right_on='primary_key')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ND', 'WV']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#gets multiseat districts\n",
    "merge_1_dupes = merge_1[merge_1.duplicated(subset='primary_key',keep=False)]\n",
    "merge_1_dupes = merge_1_dupes.drop_duplicates()\n",
    "print(list(set(merge_1_dupes['state_abbreviation'].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#gets only non multiseat districts and addes seats\n",
    "merge_1_nodupes = merge_1[~merge_1.duplicated(subset='primary_key',keep=False)]\n",
    "merge_wseats = add_seats(df = merge_1_nodupes, keep_names = True) #this will go to the end \n",
    "\n",
    "\n",
    "# pull in from seats and truncated for lookup ease and cleaner look\n",
    "leg_keys_dupes_for_merge = leg_keys_dupes.loc[:,['primary_key','state_abbreviation']] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merges the absolute positions with the values found from legislator files\n",
    "merge_2 = pd.merge(leg_keys_dupes_for_merge, merge_1_dupes, how='left', left_on='primary_key', right_on='primary_key', suffixes=('', '_y'))\n",
    "merge_2.drop(merge_2.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "merge_2 = merge_2.drop_duplicates()\n",
    "# print(*merge_2.columns, sep=', ')\n",
    "\n",
    "#add seats to last merge\n",
    "merge_2 = add_seats('First Name', 'Last Name', df_duplicates = merge_2, keep_names = True)\n",
    "\n",
    "#pull data back together\n",
    "to_combine = [merge_wseats, merge_2]\n",
    "full_ref = pd.concat(to_combine).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull all data back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_pk</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>state_abbreviation</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10100100</td>\n",
       "      <td>101001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Melson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10100200</td>\n",
       "      <td>101002</td>\n",
       "      <td>AL</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Butler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10100300</td>\n",
       "      <td>101003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>Orr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10100400</td>\n",
       "      <td>101004</td>\n",
       "      <td>AL</td>\n",
       "      <td>Garlan</td>\n",
       "      <td>Gudger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10100500</td>\n",
       "      <td>101005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Greg</td>\n",
       "      <td>Reed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>57101500</td>\n",
       "      <td>571015</td>\n",
       "      <td>WV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>57101601</td>\n",
       "      <td>571016</td>\n",
       "      <td>WV</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Barrett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>57101602</td>\n",
       "      <td>571016</td>\n",
       "      <td>WV</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Rucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>57101701</td>\n",
       "      <td>571017</td>\n",
       "      <td>WV</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>57101702</td>\n",
       "      <td>571017</td>\n",
       "      <td>WV</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Takubo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_pk primary_key state_abbreviation first_name last_name\n",
       "0     10100100      101001                 AL        Tim    Melson\n",
       "1     10100200      101002                 AL        Tom    Butler\n",
       "2     10100300      101003                 AL     Arthur       Orr\n",
       "3     10100400      101004                 AL     Garlan    Gudger\n",
       "4     10100500      101005                 AL       Greg      Reed\n",
       "...        ...         ...                ...        ...       ...\n",
       "1986  57101500      571015                 WV        NaN       NaN\n",
       "1987  57101601      571016                 WV      Jason   Barrett\n",
       "1988  57101602      571016                 WV   Patricia    Rucker\n",
       "1989  57101701      571017                 WV       Eric    Nelson\n",
       "1990  57101702      571017                 WV        Tom    Takubo\n",
       "\n",
       "[1991 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "leg_keys_wseats, leg_keys_dupes_wseats = add_seats(df = leg_keys, df_duplicates = leg_keys_dupes, keep_names = True)\n",
    "ref_back = pd.concat([leg_keys_wseats, leg_keys_dupes_wseats])\n",
    "ref_back.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "#reference for checking vacancies\n",
    "\n",
    "#from final merge also should be the final lookup##\n",
    "leg_lookup_df = full_ref.loc[:,['full_pk', 'primary_key','state_abbreviation','first name', 'last name']]\n",
    "leg_lookup_df = leg_lookup_df.rename(columns={\"first name\": \"first_name\", \"last name\": \"last_name\"})\n",
    "\n",
    "\n",
    "#from intial data\n",
    "ref_back = ref_back.loc[:,['full_pk', 'state_abbreviation']]\n",
    "# full_ref = full_ref.drop(['state_abbreviation_x', 'state_abbreviation_y'], axis = 1)\n",
    "\n",
    "\n",
    "# test = pd.merge(ref_back, full_ref, how='left', left_on='full_pk', right_on='full_pk')\n",
    "# print(*leg_lookup_df.columns, sep=', ')\n",
    "\n",
    "leg_lookup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Key file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export Final Data\n",
    "from datetime import date\n",
    "file_name = f'leg_lookup_{str(date.today()).replace('-','_')}.csv'\n",
    "leg_lookup_df.to_csv(fr'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors\\legislator lookup\\{file_name}', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seat info\n",
    "pulls in data without taking out data for unfilled seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seat info\n",
    "#copy data from ballotpedia\n",
    "leg_seats_info = leg_lookup_for_merge.copy()\n",
    "\n",
    "#add seats\n",
    "leg_seats_info_unique, leg_seats_info_dupes = add_seats(df = leg_keys, df_duplicates = leg_keys_dupes)\n",
    "leg_seats_info = pd.concat([leg_seats_info_unique, leg_seats_info_dupes])\n",
    "leg_seats_info.to_csv('all_seats')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#export seat keys\n",
    "from datetime import date\n",
    "ex_file_name = f'leg_seats_info_{str(date.today()).replace('-','_')}.xlsx'\n",
    "csv_file_name= f'leg_seats_info_{str(date.today()).replace('-','_')}.csv'\n",
    "leg_seats_info.to_excel(fr'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors\\{ex_file_name}', index = False)\n",
    "leg_seats_info.to_csv(fr'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors\\{csv_file_name}', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i,j in enumerate(leg_seats_info['full_pk']):\n",
    "#     j_pk = re.findall(r'^\\d{6}', str(j))[0]\n",
    "#     seat_num = re.findall(r'\\d{2}$', str(j))[0]\n",
    "#     # print(f'seat num is {seat_num}')\n",
    "#     # print(f'type is {type(seat_num)}')\n",
    "    \n",
    "#     if seat_num == '00':\n",
    "#         # print('its a single seat')\n",
    "#         seat_num_v = np.nan\n",
    "#     else:\n",
    "#         seat_num_v = 'Seat ' + seat_num\n",
    "\n",
    "    \n",
    "#     state_match = re.findall(r'^\\d{2}', str(j_pk))\n",
    "#     state = state_coding_r.get(int(state_match[0]))\n",
    "#     chamber = int(re.findall(r'(?<=^\\d{2})\\d{1}(?=\\d{3})', str(j_pk))[0])\n",
    "    \n",
    "#     if chamber == 0:\n",
    "#         chamber_v = 'House'\n",
    "#     else:\n",
    "#         chamber_v = 'Senate'\n",
    "    \n",
    "#     district = int(re.findall(r'(?<=^\\d{3})\\d{3}$', str(j_pk))[0].lstrip('0'))\n",
    "#     district_v = f'District {district}'\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if str(seat_num_v) != 'nan':\n",
    "#         leg_seats_info.loc[i,'seat_num'] = seat_num_v\n",
    "        \n",
    "\n",
    "\n",
    "#     # print('################')\n",
    "#     # print(f'state is {state}')\n",
    "#     # print(f'chamber is {chamber_v}')\n",
    "#     # print(f'district is {district_v}')\n",
    "#     # print(seat_num_v)\n",
    "    \n",
    "\n",
    "#     leg_seats_info.loc[i,'state'] = state\n",
    "#     leg_seats_info.loc[i,'chamber'] = chamber_v\n",
    "#     leg_seats_info.loc[i,'district'] = district_v\n",
    "\n",
    "# leg_lookup_for_merge\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%splitting up district numbers from rest of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pk(df,column):\n",
    "    lengths = []\n",
    "    df.loc[:,'state_code'] = np.nan\n",
    "    df.loc[:,'chamber_code'] = np.nan\n",
    "    df.loc[:,'district'] = np.nan\n",
    "    df.loc[:,'primary_key'] = np.nan\n",
    "    for i,j in enumerate(df[f'{column}']):\n",
    "        # print(str(j))\n",
    "        # print(row)\n",
    "        district_raw = re.split(r'\\s(?=District)', str(j))\n",
    "        match = re.findall(r'\\s\\d+', str(district_raw))[0]\n",
    "        match = match.strip()\n",
    "        if len(match) == 2:\n",
    "            district_code = '0' + str(match)\n",
    "        elif len(match) == 1:\n",
    "            district_code = '00'+str(match)\n",
    "        else:\n",
    "            district_code = str(match)\n",
    "        district_len = len(match)\n",
    "        lengths.append(district_len)\n",
    "        ext_state = df.loc[i,'state_abbreviation']\n",
    "        state_code = state_coding.get(ext_state)\n",
    "        if 'house' in str(j).lower():\n",
    "            chamber_code = '0'\n",
    "        elif 'senate' in str(j).lower():\n",
    "            chamber_code = '1'\n",
    "        else:\n",
    "            print(f'unknown chamber: {str(j)}')\n",
    "            break\n",
    "        \n",
    "        # display_markdown(f'#### {ext_state} - {chamber_code} - {district_raw}', raw=True)\n",
    "        key_code = f'{state_code}{chamber_code}{district_code}'\n",
    "        \n",
    "        \n",
    "        df.loc[i,'state_code'] = state_code\n",
    "        df.loc[i,'chamber_code'] = chamber_code\n",
    "        df.loc[i,'district'] = match\n",
    "        df.loc[i,'primary_key'] = key_code\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch original\n",
    "\n",
    "lengths = []\n",
    "thi_state_districts['state_code'] = np.nan\n",
    "thi_state_districts['chamber_code'] = np.nan\n",
    "thi_state_districts['district'] = np.nan\n",
    "thi_state_districts['primary_key'] = np.nan\n",
    "for i,j in enumerate(thi_state_districts['district_string']):\n",
    "    # print(str(j))\n",
    "    # print(row)\n",
    "    district_raw = re.split(r'\\s(?=District)', str(j))\n",
    "    match = re.findall(r'\\s\\d+', str(district_raw))[0]\n",
    "    match = match.strip()\n",
    "    if len(match) == 2:\n",
    "        district_code = '0' + str(match)\n",
    "    elif len(match) == 1:\n",
    "        district_code = '00'+str(match)\n",
    "    else:\n",
    "        district_code = str(match)\n",
    "    district_len = len(match)\n",
    "    lengths.append(district_len)\n",
    "    ext_state = thi_state_districts.loc[i,'state_abbreviation']\n",
    "    state_code = state_coding.get(ext_state)\n",
    "    if 'house' in str(j).lower():\n",
    "        chamber_code = '0'\n",
    "    elif 'senate' in str(j).lower():\n",
    "        chamber_code = '1'\n",
    "    else:\n",
    "        print(f'unknown chamber: {str(j)}')\n",
    "        break\n",
    "    \n",
    "    # display_markdown(f'#### {ext_state} - {chamber_code} - {district_raw}', raw=True)\n",
    "    key_code = f'{state_code}{chamber_code}{district_code}'\n",
    "    \n",
    "    \n",
    "    thi_state_districts.loc[i,'state_code'] = state_code\n",
    "    thi_state_districts.loc[i,'chamber_code'] = chamber_code\n",
    "    thi_state_districts.loc[i,'district'] = match\n",
    "    thi_state_districts.loc[i,'primary_key'] = key_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "# %% takes duplicates of primary keys and assigns a seat num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eat num of 00 means there is only one seat (no multi-member districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thi_state_districts['count'] = thi_state_districts['primary_key'].map(thi_state_districts['primary_key'].value_counts())\n",
    "thi_state_districts['seat_num'] = thi_state_districts.groupby('primary_key').cumcount() + 1\n",
    "thi_state_districts.loc[thi_state_districts['count'] == 1, 'seat_num'] = 0\n",
    "thi_state_districts = thi_state_districts.drop(columns='count')\n",
    "thi_state_districts['seat_num'] = thi_state_districts['seat_num'].apply(lambda x: f'{x:02d}')\n",
    "thi_state_districts['final_primary_key'] = thi_state_districts['primary_key'] + thi_state_districts['seat_num']\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = thi_state_districts[thi_state_districts.duplicated('primary_key')]\n",
    "\n",
    "    # print(str(j))\n",
    "    # print(district_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(max(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # print(line.split('District')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*all_districts, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x) for x in thi_state_districts]\n",
    "\n",
    "    # states.append(str(state_match))\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sorted(list(set(states)))\n",
    "print(len(states))\n",
    "print(*states, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(states):\n",
    "    code = str(i+1)\n",
    "    if len(code) == 1:\n",
    "        code = \"0\"+code\n",
    "    df = pd.DataFrame({'state': [j], 'code':[code]})\n",
    "    print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    break\n",
    "    print(page.status_code)\n",
    "    print(page.content[:500])  # Preview the content\n",
    "    \n",
    "    # df_list = pd.read_html(page_soup.prettify())\n",
    "    # print(len(df_list))\n",
    "    # print(type(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # print(df)\n",
    "\n",
    "    # dis_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # ditricts_tags = dis_soup.find_all(\"td\")\n",
    "    # for d in ditricts_tags:\n",
    "    #     print(d)\n",
    "    \n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
