{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, re, xlrd  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "from datetime import date\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "from openpyxl import Workbook\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "from cprl_functions.state_capture import thi_states,state_ref, state_coding, state_pat, state_abv_pat\n",
    "from cprl_functions.text_printing import bordered\n",
    "from cprl_functions.defined_functions import create_pk, add_seats, get_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bordered(text):\n",
    "    \n",
    "    if isinstance(text, int) or isinstance(text, str):\n",
    "        text = str(text)\n",
    "    try:\n",
    "        lines = text.splitlines()\n",
    "        width = max(len(s) for s in lines)\n",
    "        res = ['┌' + '─' * width + '┐']\n",
    "        for s in lines:\n",
    "            res.append('│' + (s + ' ' * width)[:width] + '│')\n",
    "        res.append('└' + '─' * width + '┘')\n",
    "        return '\\n'.join(res)\n",
    "    except:\n",
    "        lines = [text]\n",
    "        width = len(str(lines[0]))\n",
    "        res = ['┌' + '─' * width + '┐']\n",
    "        for s in lines:\n",
    "            res.append('│' + (s + ' ' * width)[:width] + '│')\n",
    "        res.append('└' + '─' * width + '┘')\n",
    "        return '\\n'.join(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_majority_party(list, x) :\n",
    "    rep = [x for x in list if \"Republican\" in str(x)]\n",
    "    dem = [x for x in list if \"Democrat\" in str(x)]\n",
    "\n",
    "    rep_count = len(rep)\n",
    "    dem_count = len(dem)\n",
    "\n",
    "    if rep_count > dem_count:\n",
    "        maj_party = \"Republican\"\n",
    "    elif dem_count > rep_count:\n",
    "        maj_party = \"Democrat\"\n",
    "    else:\n",
    "        print('somehow they are equal')\n",
    "\n",
    "    if maj_party == x:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "Gather data and clean for legislator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#gather all legislator files from done folder\n",
    "#committee data should be updated before pulling this\n",
    "\n",
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\done')\n",
    "legislator_files = glob.glob('*.xlsx') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiles legislator files into one file\n",
    "#goes through each sheet and retrieves sheet as dataframe\n",
    "dfs = {}\n",
    "for i,file in enumerate(legislator_files):\n",
    "    #print('working on file:' + str(file))\n",
    "    # file = legislator_files[0]\n",
    "    # xls = pd.ExcelFile(file)\n",
    "    sheets_dict = pd.read_excel(file, engine=\"openpyxl\", sheet_name=None)\n",
    "    sheet_names = list(sheets_dict.keys())\n",
    "    for s in sheet_names:\n",
    "        df = pd.read_excel(file, engine=\"openpyxl\", sheet_name=s)\n",
    "        \n",
    "        \n",
    "        filename =  f'{s}'\n",
    "        dfs[filename] = df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this may not even be used\n",
    "#trims files to not include committee data\n",
    "compiling = []\n",
    "for k,v in dfs.items():\n",
    "    #print(*v.columns, sep = \" | \")\n",
    "    df = v.iloc[:, :9]\n",
    "    compiling.append(df)\n",
    "    #print(k,\" is in\")\n",
    "\n",
    "#pull togther all newly trimmed df's\n",
    "all_legs_files = pd.concat(compiling)\n",
    "all_legs_files.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024')\n",
    "# all_legs_files.to_csv(f'all_legs_files_{str(date.today()).replace('-','_')}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling in Legislator reference file\n",
    "leg_lookup = r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors\\leg_lookup_df.csv'\n",
    "leg_lookup_ref = pd.read_csv(leg_lookup)\n",
    "\n",
    "leg_lookup_dict = (leg_lookup_ref.loc[:,['full_pk', 'Last Name']]).set_index('full_pk')['Last Name'].to_dict() \n",
    "# ms_legs_lookup = (ms_legs.loc[:,['full_pk', 'Last Name']]).set_index('full_pk')['Last Name'].to_dict()\n",
    "\n",
    "ms_legs = leg_lookup_ref[~leg_lookup_ref['full_pk'].astype(str).str.endswith('00')]\n",
    "\n",
    "ms_legs_lookup = (ms_legs.loc[:,['full_pk', 'Last Name']]).set_index('full_pk')['Last Name'].to_dict()\n",
    "\n",
    "# for k,v in ms_legs_lookup.items():\n",
    "#     print(f'{k} - type: {type(k)}')\n",
    "#     print(f'{v} - type: {type(v)}')\n",
    "\n",
    "# leg_lookup_ref_noo = leg_lookup_ref[~leg_lookup_ref['full_pk'].astype(str).str.endswith('00')]\n",
    "# leg_lookup_ref_noo = (leg_lookup_ref_noo.loc[:,['full_pk', 'Last Name']]).set_index('full_pk')['Last Name'].to_dict()\n",
    "# leg_lookup_ref_noo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keepnames didnt work\n",
      "full_pk,primary_key,State Abbreviation,Chamber,full title,First Name,Last Name,Party,district,tenure,leader,seat,state_code,chamber_code,district_code\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_df,duplicates = create_pk(all_legs_files,'district', 'Chamber')\n",
    "duplicates['full_pk'] = np.nan\n",
    "for i,j in enumerate(duplicates['Last Name']):\n",
    "    full_pk = get_key(j, ms_legs_lookup)\n",
    "    duplicates.loc[i,['full_pk']] = int(full_pk)\n",
    "    # print(full_pk)\n",
    "\n",
    "duplicates = duplicates.loc[:,['full_pk', 'primary_key', 'First Name', 'Last Name']]\n",
    "\n",
    "non_dupes = add_seats(df = cleaned_df)\n",
    "non_dupes = non_dupes.loc[:,['full_pk', 'primary_key', 'First Name', 'Last Name']]\n",
    "leg_files_fpk = pd.concat([non_dupes, duplicates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cleaned_df.loc[:,['full_pk']] = np.nan\n",
    "# for i,j in enumerate(cleaned_df['Last Name']):\n",
    "#     # print(j)\n",
    "#     test_fpk = int(str(cleaned_df.loc[i,'primary_key'])+'00')\n",
    "#     # print(test_fpk)\n",
    "#     # print(type(test_fpk))\n",
    "#     # break\n",
    "#     results = leg_lookup_dict.get(test_fpk)\n",
    "#     if str(results) == 'None':\n",
    "#         print(results)\n",
    "    \n",
    "\n",
    "    # full_pk = get_key(j, leg_lookup_ref_noo)\n",
    "    # print(full_pk)\n",
    "    # duplicates.loc[i,['full_pk']] = int(full_pk)\n",
    "    # print(full_pk)\n",
    "\n",
    "# cleaned_df.loc['full_pk', 'primary_key', 'First Name', 'Last Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing manually edited leadership positions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issues with the district match\n",
      "primary_key                                NaN\n",
      "State Abbreviation                          WV\n",
      "Chamber                                  House\n",
      "full title            Lt. Governor Craig Blair\n",
      "First Name                               Craig\n",
      "Last Name                                Blair\n",
      "Party                               Republican\n",
      "district                                   NaN\n",
      "tenure                                       3\n",
      "leader                                        \n",
      "state_code                                 NaN\n",
      "chamber_code                               NaN\n",
      "district_code                              NaN\n"
     ]
    }
   ],
   "source": [
    "leadership_positions_file = r\"C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\all_legs_files_w_rankings.csv\"\n",
    "leaders_lookup = pd.read_csv(leadership_positions_file)\n",
    "\n",
    "#create primary key for leadership file\n",
    "infl_rankings, rankings_dupes = create_pk(leaders_lookup, 'district', 'Chamber')\n",
    "\n",
    "# for i,j in enumerate(infl_rankings['primary_key']):\n",
    "#     print(type(j))\n",
    "#     print(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keepnames didnt work\n",
      "full_pk,primary_key,State Abbreviation,Chamber,full title,First Name,Last Name,Party,district,tenure,leader,state_code,chamber_code,district_code\n",
      "Index(['full_pk', 'primary_key', 'State Abbreviation', 'Chamber', 'full title',\n",
      "       'First Name', 'Last Name', 'Party', 'district', 'tenure', 'leader',\n",
      "       'state_code', 'chamber_code', 'district_code'],\n",
      "      dtype='object')\n",
      "Index(['primary_key', 'State Abbreviation', 'Chamber', 'full title',\n",
      "       'First Name', 'Last Name', 'Party', 'district', 'tenure', 'leader',\n",
      "       'state_code', 'chamber_code', 'district_code', 'full_pk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "infl_rankings = infl_rankings.dropna(axis = 0, subset='district')\n",
    "infl_rankings.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#fill in dupes seats and full pk\n",
    "rankings_dupes['full_pk'] = np.nan\n",
    "for i,j in enumerate(duplicates['Last Name']):\n",
    "    full_pk = get_key(j, ms_legs_lookup)\n",
    "\n",
    "\n",
    "    rankings_dupes.loc[i,['full_pk']] = int(full_pk)\n",
    "    # print(full_pk)\n",
    "\n",
    "infl_non_dupes = add_seats(df = infl_rankings)\n",
    "print(infl_non_dupes.columns)\n",
    "print(rankings_dupes.columns)\n",
    "infl_non_dupes = infl_non_dupes.loc[:,['full_pk', 'primary_key', 'First Name', 'Last Name', 'leader']]\n",
    "rankings_dupes = rankings_dupes.loc[:,['full_pk', 'primary_key', 'First Name', 'Last Name','leader']]\n",
    "# print(infl_non_dupes.columns)\n",
    "# print(rankings_dupes.columns)\n",
    "leadership_files = pd.concat([infl_non_dupes, rankings_dupes])\n",
    "leadership_files.reset_index(inplace=True, drop=True)\n",
    "# leaders_lookup = leaders_lookup.loc[:, ['helper', \"leader\"]]\n",
    "\n",
    "leadership_dict = (leadership_files.loc[:,['full_pk', 'leader']]).set_index('full_pk')['leader'].to_dict()\n",
    "\n",
    "# for k,v in leadership_dict.items():\n",
    "#     print(k,v)\n",
    "# ms_legs_lookup = (ms_legs.loc[:,['full_pk', 'Last Name']]).set_index('full_pk')['Last Name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check for leaks (commented out otherwise)\n",
    "\n",
    "# infl_rankings.loc[:,['full_pk']] = np.nan\n",
    "# for i,j in enumerate(cleaned_df['Last Name']):\n",
    "#     # print(j)\n",
    "#     test_fpk = int(str(cleaned_df.loc[i,'primary_key'])+'00')\n",
    "#     # print(test_fpk)\n",
    "#     # print(type(test_fpk))\n",
    "#     # break\n",
    "#     results = leg_lookup_dict.get(test_fpk)\n",
    "#     if str(results) == 'None':\n",
    "#         print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# leaders_lookup['helper'] = leaders_lookup['State Abbreviation'].astype(str)+ \"-\"+ leaders_lookup['Chamber'].astype(str)+ \"-\"+leaders_lookup['district'].astype(str)\n",
    "\n",
    "# leaders_lookup.loc[leaders_lookup['helper'].str.contains(r'^ND-House'), 'helper'] = leaders_lookup['State Abbreviation'].astype(str)+ \"-\"+ leaders_lookup['Chamber'].astype(str)+ \"-\"+leaders_lookup['district'].astype(str)+\"-\"+leaders_lookup['Last Name'].astype(str)\n",
    "\n",
    "\n",
    "# leaders_lookup = leaders_lookup.loc[:, ['helper', \"leader\"]]\n",
    "# leaders_lookup.dropna(subset='leader', inplace=True)\n",
    "# leaders_lookup.reset_index(inplace=True, drop=True)\n",
    "# leaders_dict = leaders_lookup.to_dict()\n",
    "\n",
    "\n",
    "#print(k,v,\"\\n\") for k,v in leaders_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence Score calculation\n",
    "Pulls in committee data, leadership values, and tenure to calculate tenure score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pulling in data from legislator files, pulls in \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "influence_scores = []\n",
    "for k,v in dfs.items():\n",
    "    # display_markdown(f' # {k}', raw = True)\n",
    "    # v = dfs.get('AL_house')\n",
    "    df = v\n",
    "    #Conneticut is all in one file since there committies are all joint\n",
    "    #This splits them up and puts them into a list, otherwise single files get put into a list of one\n",
    "    if re.search(r'^CT', str(k)):\n",
    "        house = df[df['Chamber'] == \"House\"]\n",
    "        house.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        \n",
    "        senate = df[df['Chamber'] == \"Senate\"]\n",
    "        senate.reset_index(inplace=True, drop=True)\n",
    "        # #print(house.to_string())\n",
    "        # #print(senate.to_string())\n",
    "        dfs_temp = [house, senate]\n",
    "    \n",
    "    else:\n",
    "        dfs_temp = [df]\n",
    "\n",
    "    \n",
    "    \n",
    "    for d in dfs_temp:\n",
    "        #Putting helper column in the front\n",
    "        # d['helper'] = d['State Abbreviation'].astype(str)+ \"-\"+ d['Chamber'].astype(str)+ \"-\"+d['district'].astype(str)\n",
    "        # d.loc[d['helper'].str.contains(r'^ND-House'), 'helper'] = d['State Abbreviation'].astype(str)+ \"-\"+ d['Chamber'].astype(str)+ \"-\"+d['district'].astype(str)+\"-\"+d['Last Name'].astype(str)\n",
    "        # # d.loc[d['state'].isna() | (d['state'] == \"\") | (d['district'].isna()), 'helper'] = None\n",
    "        \n",
    "        cleaned_df,duplicates = create_pk(d,'district', 'Chamber',  drop_extra_codes = True)\n",
    "        cleaned_df.reset_index(inplace= True, drop = True)\n",
    "        duplicates.reset_index(inplace= True, drop = True)\n",
    "\n",
    "        duplicates['full_pk'] = np.nan\n",
    "        for i,j in enumerate(duplicates['Last Name']):\n",
    "            full_pk = get_key(j, ms_legs_lookup)\n",
    "            duplicates.loc[i,['full_pk']] = int(full_pk)\n",
    "            # print(full_pk)\n",
    "\n",
    "        # print(duplicates.to_string())\n",
    "        # print(cleaned_df.to_string())\n",
    "\n",
    "        # duplicates = duplicates.loc[:,['full_pk', 'primary_key', 'First Name', 'Last Name']]\n",
    "\n",
    "\n",
    "        non_dupes = add_seats(df = cleaned_df)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # non_dupes = non_dupes.loc[:,['full_pk', 'primary_key', 'First Name', 'Last Name']]\n",
    "        first_column = non_dupes.pop('full_pk')\n",
    "        non_dupes.insert(0, 'full_pk', first_column)\n",
    "\n",
    "        first_column = duplicates.pop('full_pk')\n",
    "        duplicates.insert(0, 'full_pk', first_column)\n",
    "\n",
    "        # print('########################')\n",
    "        # print(*non_dupes.columns, sep=\" , \")\n",
    "        # print(*duplicates.columns, sep=\" , \")\n",
    "        # print('########################')\n",
    "\n",
    "\n",
    "        d = pd.concat([non_dupes, duplicates])\n",
    "        d.reset_index(inplace=True, drop=True)\n",
    "        # first_column = d.pop('full_pk')\n",
    "        # d.insert(0, 'full_pk', first_column)\n",
    "        # print(duplicates.head(2).to_string())\n",
    "        # print(cleaned_df.head(2).to_string())\n",
    "        \n",
    "\n",
    "        \n",
    "        #getting all columns except for committee columns\n",
    "        col_list = d.columns.to_list()\n",
    "        for ic,col in enumerate(col_list):\n",
    "            if re.search(r'^leader', str(col)):\n",
    "                index_start = ic+1\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # d_coms = d.iloc[:, f'-{index_start}'index_start:]\n",
    "        # #print(d.shape[1])\n",
    "\n",
    "        d_coms = d.iloc[:, [0] + list(range(index_start, (d.shape[1]-1)))]\n",
    "        # #print(d_2.columns)\n",
    "\n",
    "\n",
    "        #getting list of committee memberships, list would include a collection of \"none, Member, Vice Chair, Chair, or even Minority Chair\"\n",
    "        comm_dict = {}\n",
    "        for i,dc in enumerate(d_coms['full_pk']):\n",
    "            \n",
    "            coms_list = d_coms.iloc[i,1:].to_list()\n",
    "            comm_dict[dc] = coms_list\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # #getting majority party and splitting up by dems and repubs\n",
    "        party_list_uc = d['Party'].to_list()   \n",
    "        d['influence_score'] = np.nan\n",
    "        for i,hv in enumerate(d['full_pk']):\n",
    "            #variable declaration\n",
    "            score = 1\n",
    "            first_tier = False\n",
    "            second_tier = False\n",
    "            other_tier = False\n",
    "            in_maj_party = False\n",
    "            is_chair = False\n",
    "            is_vice = False\n",
    "            member = False\n",
    "            minority_mem = False\n",
    "            \n",
    "            \n",
    "            #retrieving values\n",
    "            value = leadership_dict.get(hv)\n",
    "            d.loc[i,'leaders'] = value\n",
    "            if re.search(r'\\[\\d\\]', str(value)):\n",
    "                #print('found a top leader')\n",
    "                if re.search(r'\\[1\\]', str(value)):\n",
    "                    first_tier = True\n",
    "                elif re.search(r'\\[2\\]',str(value)):\n",
    "                    second_tier = True                \n",
    "            else:\n",
    "                other_tier = True\n",
    "\n",
    "            #get the majority party\n",
    "            if is_majority_party(party_list_uc, str(d['Party'].iloc[i])):\n",
    "                in_maj_party = True\n",
    "\n",
    "            #get comms list\n",
    "            leg_comms = comm_dict.get(hv)\n",
    "            # #print(\"****Legislator's Comms\")\n",
    "            for leg in leg_comms:\n",
    "                \n",
    "                if isinstance(leg, float):\n",
    "                    continue\n",
    "                elif re.search(r'^[Cc]hair', str(leg)):\n",
    "                    is_chair = True\n",
    "                elif re.search(r'[Vv]ice-?\\s?[Cc]hair', str(leg)):\n",
    "                    is_vice = True\n",
    "                elif re.search(r'[Mm]ember', str(leg)):\n",
    "                    member = True\n",
    "                elif re.search(r'[Mm]inority', str(leg)):\n",
    "                    minority_mem = True\n",
    "                # else:\n",
    "                #     print(\"something else\")\n",
    "\n",
    "    \n",
    "            #scoring\n",
    "            if in_maj_party == True:\n",
    "                #print('in majority party')\n",
    "                if first_tier == True:\n",
    "                    score = 20\n",
    "                    #print(\"speaker\")\n",
    "                elif second_tier == True:\n",
    "                    score = 15\n",
    "                    #print(\"other majority leaders\")\n",
    "\n",
    "                elif is_chair == True:\n",
    "                    score = 15\n",
    "                    #print('chair of a committee')\n",
    "                elif is_vice == True:\n",
    "                    score = 10\n",
    "                    #print('vice chair of a committe')\n",
    "                elif other_tier == True:\n",
    "                    score = 10\n",
    "                    #print('other majority leadership')\n",
    "                elif member == True:\n",
    "                    score = 5   \n",
    "            elif in_maj_party == False:\n",
    "                #print('not in majority party')\n",
    "                if first_tier == True:\n",
    "                    score = 15\n",
    "                    #print('minority leader')\n",
    "                elif is_chair == True:\n",
    "                    score = 15\n",
    "                    #print('chair of a committee')\n",
    "\n",
    "                elif second_tier == True:\n",
    "                    score = 10\n",
    "                elif is_vice == True:\n",
    "                    score = 10\n",
    "                    #print('vice chair of a committe')\n",
    "\n",
    "                elif minority_mem == True:\n",
    "                    score = 5\n",
    "                    #print('is minority ranking mem in committee')\n",
    "                elif member == True:\n",
    "                    score = 5\n",
    "                    #print('is a committee member')\n",
    "                elif other_tier == True:\n",
    "                    score = 5\n",
    "                    #print('other minority leadership')\n",
    "\n",
    "\n",
    "            #pull out tenure modifier\n",
    "            tenure = d['tenure'].iloc[i]\n",
    "            if tenure > 10:\n",
    "                score += 3\n",
    "            elif tenure > 6:\n",
    "                score += 2\n",
    "            elif tenure > 2:\n",
    "                score += 1\n",
    "\n",
    "\n",
    "            #make sure 20 is max score\n",
    "            if score > 20:\n",
    "                score = 20\n",
    "\n",
    "            if score == 1:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            #assign score to influence score column\n",
    "            d.loc[i,'influence_score'] = score\n",
    "        \n",
    "        #df creation and appending to list of dfs\n",
    "        final_df = d.loc[:,['full_pk', 'First Name', 'Last Name', 'influence_score']]\n",
    "        influence_scores.append(final_df)\n",
    "\n",
    "\n",
    "#pull together all dfs and export\n",
    "leg_infl_df = pd.concat(influence_scores)\n",
    "leg_infl_df.reset_index(drop = True, inplace= True)\n",
    "# os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\build files')\n",
    "# leg_infl_df.to_csv(\"leg_infl_df.csv\", index=False)\n",
    "        \n",
    "leg_infl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defunct\n",
    "Chunk below is vistigial of using rankings list from ncls website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below is an older chunk that looked through the raw legislator files, cell above contains the same information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leader_dfs = []\n",
    "# for i,j in enumerate(leader_rankings_df['position']):\n",
    "#     if re.search(r'[Ss]peaker', str(j)):\n",
    "#         continue\n",
    "#     elif re.search(r'[Mm]ajority|[Mm]inority', str(j)):\n",
    "#         # #print(j)\n",
    "#         continue\n",
    "#     else:\n",
    "#         # #print('***not found***')\n",
    "#         # #print(j)\n",
    "#         # #print(\"**************\")\n",
    "#         # #print(leader_rankings_df.iloc[i,:].to_string())\n",
    "#         df2 = pd.DataFrame(columns=['state', 'position', 'chamber'])\n",
    "#         df2 = df2._append(leader_rankings_df.iloc[i], ignore_index=True)\n",
    "#         # #print(type(df))\n",
    "#         leader_dfs.append(df2)\n",
    "#         # #print('\\n')\n",
    "\n",
    "# outliers = pd.concat(leader_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking_file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\leader_rankings.csv\"\n",
    "# rankings = pd.read_csv(ranking_file)\n",
    "\n",
    "\n",
    "# file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\leadership_ranking.xlsx\"\n",
    "# leader_rankings_df = pd.read_excel(file)\n",
    "# #print(*leader_rankings_df.columns)\n",
    "# leader_rankings_df['state'] = leader_rankings_df['state'].fillna(method=\"ffill\")\n",
    "\n",
    "# n = len(leader_rankings_df)\n",
    "# break_point = False\n",
    "\n",
    "# for i,j in enumerate(leader_rankings_df['state']):\n",
    "#     if \"Wyoming\" in str(j) and \"Alabama\" in leader_rankings_df['state'].iloc[i+1]:\n",
    "#         index_stop = i + 1\n",
    "#         break_point = True\n",
    "\n",
    "\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "#     if break_point == True:\n",
    "#         house_list = ['House']*index_stop\n",
    "#         senate_list = ['Senate']*(n-index_stop)\n",
    "#         full_list = house_list + senate_list\n",
    "#         leader_rankings_df['chamber'] = full_list\n",
    "#         leader_rankings_df.dropna(inplace=True)\n",
    "#         break\n",
    "\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data')\n",
    "# leader_rankings_df.to_csv('leader_rankings.csv', index_label= False, index=False)\n",
    "\n",
    "# #print(leader_rankings_df[leader_rankings_df['state'].str.contains('Connecticut')].to_string())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
