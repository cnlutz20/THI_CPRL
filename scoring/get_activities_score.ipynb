{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, datetime, re, xlrd  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "from openpyxl import Workbook\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bordered(text):\n",
    "    \n",
    "    if isinstance(text, int):\n",
    "        text = str(text)\n",
    "    try:\n",
    "        lines = text.splitlines()\n",
    "        width = max(len(s) for s in lines)\n",
    "        res = ['┌' + '─' * width + '┐']\n",
    "        for s in lines:\n",
    "            res.append('│' + (s + ' ' * width)[:width] + '│')\n",
    "        res.append('└' + '─' * width + '┘')\n",
    "        return '\\n'.join(res)\n",
    "    except:\n",
    "        lines = [text]\n",
    "        width = len(str(lines[0]))\n",
    "        res = ['┌' + '─' * width + '┐']\n",
    "        for s in lines:\n",
    "            res.append('│' + (s + ' ' * width)[:width] + '│')\n",
    "        res.append('└' + '─' * width + '┘')\n",
    "        return '\\n'.join(res)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering leg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\done')\n",
    "legislator_files = glob.glob('*.xlsx') \n",
    "\n",
    "for i,file in enumerate(legislator_files):\n",
    "    if '_legislators' not in str(file).lower():\n",
    "        print(\"deleting: \" + str(legislator_files[i]))\n",
    "        del legislator_files[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:AL_legislators.xlsx\n",
      "working on file:CT_legislators.xlsx\n",
      "working on file:IL_legislators.xlsx\n",
      "working on file:IN_Legislators.xlsx\n",
      "working on file:KS_legislators.xlsx\n",
      "working on file:MO_legislators.xlsx\n",
      "working on file:NC_legislators.xlsx\n",
      "working on file:ND_legislators.xlsx\n",
      "working on file:NM_legislators.xlsx\n",
      "working on file:OH_legislators.xlsx\n",
      "working on file:OK_legislators.xlsx\n",
      "working on file:VA_legislators.xlsx\n",
      "working on file:WV_legislators.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#compiles legislator files into one file\n",
    "dfs = []\n",
    "for i,file in enumerate(legislator_files):\n",
    "    print('working on file:' + str(file))\n",
    "    # file = legislator_files[0]\n",
    "    # xls = pd.ExcelFile(file)\n",
    "    sheets_dict = pd.read_excel(file, engine=\"openpyxl\", sheet_name=None)\n",
    "    sheet_names = list(sheets_dict.keys())\n",
    "    for s in sheet_names:\n",
    "        df = pd.read_excel(file, engine=\"openpyxl\", sheet_name=s)\n",
    "        df = df.iloc[:,:9]\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legs = pd.concat(dfs)\n",
    "# print(all_legs.columns)\n",
    "\n",
    "all_legs['helper'] = all_legs['State Abbreviation'].astype(str)+ \"-\"+ all_legs['Chamber'].astype(str)+ \"-\"+all_legs['district'].astype(str)\n",
    "all_legs.reset_index(inplace = True, drop = True)\n",
    "# duplicates = all_legs.index.duplicated()\n",
    "# all_legs[duplicates])\n",
    "\n",
    "all_legs.loc[all_legs['helper'].str.contains(r'^ND-House'), 'helper'] = all_legs['State Abbreviation'].astype(str)+ \"-\"+ all_legs['Chamber'].astype(str)+ \"-\"+all_legs['district'].astype(str)+\"-\"+all_legs['Last Name'].astype(str)\n",
    "first_column = all_legs.pop('helper')\n",
    "all_legs.insert(0,'helper', first_column) \n",
    "\n",
    "\n",
    "# export\n",
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\build files')\n",
    "all_legs.to_csv('list_of_legislators_11_15_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE_LEG_ED_Dinner_2023.xlsx', 'ECLS_2024.xlsx', 'ElevateNC_C4_M3.xlsx', 'ElevateNC_C4_M4.xlsx', 'HKF_C10_S1.xlsx', 'HKF_Regional_Visit_(FAU).xlsx', 'HSPF_C4_M1.xlsx', 'HSPF_C4_M2.xlsx', 'HSPF_C4_M3.xlsx', 'MO_SLR_2023.xlsx', 'NCCCS_M4.xlsx', 'NC_EC_Roundtable_2024.xlsx', 'NC_HLR_2024.xlsx', 'ND_Literacy_taskforce_2024.xlsx', 'ND_SLR_2023.xlsx', 'ND_SLR_2024.xlsx', 'ND_TRR_M1.xlsx', 'ND_TRR_m2.xlsx', 'ND_TRR_m3.xlsx', 'OH_SLR_2023.xlsx', 'OH_SLR_2024.xlsx', 'OK_SLR_2023.xlsx', 'OK_SLR_2024.xlsx', 'SC_Leg_Ed_Dinner_2023.xlsx', 'The_Path_Forward_2024.xlsx', 'WV_SLR_2023.xlsx', 'WV_SLR_2024.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# import files\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data')\n",
    "events = glob.glob(\"*.xlsx\")\n",
    "print(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex list set up\n",
    "state_list = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \n",
    "    \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \n",
    "    \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \n",
    "    \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \n",
    "    \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \n",
    "    \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \n",
    "    \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \n",
    "    \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n",
    "    \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\", \"District of Columbia\"\n",
    "]\n",
    "state_abbreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"\n",
    "]\n",
    "#editing for finding state intitals at beginning of string only\n",
    "state_abbreviations_reg = []\n",
    "for abv in state_abbreviations:\n",
    "    for_regex = f'^{abv}'\n",
    "    state_abbreviations_reg.append(for_regex)\n",
    "#compiling regex patterns for looking for states\n",
    "state_pat = re.compile(\"|\".join(state_list))\n",
    "state_abv_pat = re.compile(\"|\".join(state_abbreviations_reg))\n",
    "# print(state_abv_pat)\n",
    "state_ref = dict(zip(state_list, state_abbreviations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in State info\n",
    "\n",
    "looks for state names in the title, org, and state fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "vals_changed = 0\n",
    "for event in events:\n",
    "    df = pd.read_excel(event)\n",
    "    # print('######################')\n",
    "    # print(bordered(event))\n",
    "    \n",
    "    # print(*df.columns)\n",
    "    event_name = str(event).split('.')[0].strip().replace('_', ' ')\n",
    "    df = df.iloc[:,:8]\n",
    "    df.loc[:,'event name'] = event_name\n",
    "    \n",
    "    break_all = False\n",
    "    # #print(df)\n",
    "    # continue\n",
    "    for i,state in enumerate(df['state']):\n",
    "       \n",
    "        # #print('----------------------------')\n",
    "        # if isinstance(state, float):\n",
    "        # if re.search(r'[Rr]epresentative|[Ss]enator|[Ll]egislator',str(df['title'].iloc[i])) or re.search(r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse', str(df['org'].iloc[i])):\n",
    "    \n",
    "    \n",
    "        # display_markdown(f'### title', raw=True)\n",
    "        # print(df.loc[i,'title'])\n",
    "        # display_markdown(f'### org', raw=True)\n",
    "        # print(df.loc[i,'org'])\n",
    "    \n",
    "    \n",
    "    \n",
    "        # continue\n",
    "        #print(\"^^^^^^^^^^^\")\n",
    "        #print(\"found a match\")\n",
    "        # #print(df.loc[i,['first_name', 'last_name']])\n",
    "        \n",
    "        testing_string = str(df['title'].iloc[i]) + \" \" + str(df['org'].iloc[i])\n",
    "        # #print(testing_string)\n",
    "        testing_string = testing_string.lstrip('nan').lstrip().strip()\n",
    "        # #print(re.match(r'[Rr]epresentative|[Ss]enator|[Ll]egislator|[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse',str(testing_string)))\n",
    "        # continue\n",
    "        # #print('###########')\n",
    "        # #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "        # #print('\\n')\n",
    "        state_match_uc = re.findall(state_pat, str(df['org'].iloc[i]))\n",
    "        state_match = [x for x in state_match_uc if len(x) > 0]\n",
    "        \n",
    "        # First match test\n",
    "        if len(state_match) == 0:\n",
    "            #print('no regular state match')\n",
    "            #print(state_match_uc)\n",
    "            state_abv_match_uc = re.findall(state_abv_pat, str(df['org'].iloc[i]))\n",
    "            state_abv_match = [x for x in state_abv_match_uc if len(x) > 0]\n",
    "            # Second match test\n",
    "            if len(state_abv_match) == 0:\n",
    "                #print('no state abbreviation match')\n",
    "                #print(state_abv_match_uc)\n",
    "                state_abv_event_match_uc = re.findall(state_abv_pat, str(df['event name'].iloc[i]))\n",
    "                state_abv_event_match = [x for x in state_abv_event_match_uc if len(x) > 0]\n",
    "                # Third match test\n",
    "                if len(state_abv_event_match) == 0:\n",
    "                    #print('no state abv event match')\n",
    "                    #print(state_abv_event_match_uc)\n",
    "                    break\n",
    "                elif len(state_abv_event_match) > 1:\n",
    "                    #print('more than one match?')\n",
    "                    break_all = True\n",
    "                    break\n",
    "                else:\n",
    "                    #print(\"abv in event match\")\n",
    "                    state_val = str(state_abv_event_match[0])\n",
    "                    # df.loc[i,'state'] = None\n",
    "                    df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                    df.loc[i,'state'] = state_val\n",
    "                    #print(state_val)\n",
    "                    vals_changed += 1\n",
    "            elif len(state_abv_match) > 1:\n",
    "                #print('more than one match?')\n",
    "                #print(state_abv_match)\n",
    "                #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "                break_all = True\n",
    "                break\n",
    "            else:\n",
    "                #print(\"regular abreviation match\")\n",
    "                \n",
    "                state_val = str(state_abv_match[0])\n",
    "                # df.loc[i,'state'] = None\n",
    "                df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                df.loc[i,'state'] = state_val\n",
    "                #print(state_val)\n",
    "                vals_changed += 1\n",
    "\n",
    "            # #print('###########')\n",
    "            # #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "            # #print('\\n')\n",
    "            # break\n",
    "        elif len(state_match) > 1:\n",
    "            #print(\"more than one match?\")\n",
    "            break_all = True\n",
    "            break\n",
    "        else:\n",
    "            #print(\"normal state match\")\n",
    "            state_val_dirty = str(state_match[0])\n",
    "            state_val = state_ref.get(state_val_dirty)\n",
    "            df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "            # df.loc[i,'state'] = None\n",
    "            df.loc[i,'state'] = state_val\n",
    "            #print(state_val)\n",
    "            vals_changed += 1\n",
    "        # else:\n",
    "        #     # #print('#########################')\n",
    "        #     # #print('NOT A REP OR SEN')\n",
    "        #     # #print(df.loc[i,['first_name','last_name','title', 'org']])\n",
    "        #     continue\n",
    "            # #print(df.loc[i, list(df.columns[3:5]) + [df.columns[-1]]])\n",
    "            # #print('\\n')\n",
    "    if break_all == True:\n",
    "        break\n",
    "    dfs.append(df)\n",
    "event_data = pd.concat(dfs)\n",
    "event_data.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#looks for state names and replaces them with state initials\n",
    "for i,j in enumerate(event_data['state']):\n",
    "    \n",
    "    if isinstance(j, float):\n",
    "        continue\n",
    "    elif re.search(r'[A-Z]{2}', str(j)):\n",
    "        continue\n",
    "    else:\n",
    "        val = state_ref.get(str(j))\n",
    "        event_data.loc[i,'state'] = str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# event_data.to_csv(\"event_data_export_11_7_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refining data\n",
    "\n",
    "This section refines the data done into only legislators and then split by whether districts are found or not\n",
    "\n",
    "Later on hopefully we wont need to split up by no districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern set up\n",
    "title_pattern = r'[Rr]epresentative|[Ss]enator|[Ll]egislator'\n",
    "org_pattern = r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|(?<!School )(?:House District|District)|[Ss]tate [Hh]ouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#filter for state legislators\n",
    "filtered_df = event_data[event_data['title'].astype(str).apply(lambda x: bool(re.search(title_pattern, x))) |\n",
    "                 event_data['org'].astype(str).apply(lambda x: bool(re.search(org_pattern, x)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_28616\\4117469650.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  no_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True) |\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_28616\\4117469650.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#filter out where can't find district number\n",
    "no_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_28616\\2864911978.py:7: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) |\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_28616\\2864911978.py:8: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Data export\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# no_districts.to_csv('no_districts.csv', index=False)\n",
    "\n",
    "\n",
    "#regine values with districts\n",
    "w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True))]\n",
    "\n",
    "w_districts.reset_index(inplace=True, drop=True)\n",
    "w_districts['chamber'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a,b in zip(w_districts.title, w_districts.org):\n",
    "    # print('#######################')\n",
    "    # print('***********')\n",
    "    # print(a)\n",
    "    # print('***********')\n",
    "    # print(b)\n",
    "    # continue\n",
    "    has_a = False\n",
    "    has_b = False\n",
    "    if 'district' in str(a).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(a)):\n",
    "        match_a = re.findall(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(a))\n",
    "        match_a = [x for x in match_a if len(x) > 0]\n",
    "        if len(match_a) == 0:\n",
    "            print('no results for title')\n",
    "            print(a)\n",
    "            \n",
    "        else:\n",
    "            has_a = True\n",
    "            match = match_a[0]\n",
    "            # print(\"a match: \" + match)\n",
    "            # print('################')\n",
    "            # print(match_a)\n",
    "        # print(str(dis))\n",
    "    \n",
    "    if 'district' in str(b).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(b)):\n",
    "        match_b = re.findall(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(b))\n",
    "        match_b = [x for x in match_b if len(x) > 0]\n",
    "        if len(match_b) == 0:\n",
    "            print('no results for org')\n",
    "            print(b)\n",
    "        \n",
    "        else:\n",
    "            has_b = True\n",
    "            match = match_b[0]\n",
    "            # print(\"b match: \" + match)\n",
    "            # print('################')\n",
    "            # print(match_b)\n",
    "    # else:\n",
    "    #     print('no results')\n",
    "    #     print(a)\n",
    "    #     print(b)\n",
    "\n",
    "\n",
    "    if has_b == True or has_a == True:\n",
    "        match_final = re.findall(r'\\d+[A-Za-z]?', str(match))\n",
    "        # print(\"final match: \" + str(match_final[0]))\n",
    "        # print(\"putting it on row: \" + str(i))\n",
    "        w_districts.loc[i, 'district'] = str(match_final[0]).strip().lstrip('0')\n",
    "\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix for no districts\n",
    "The chunk below brings in a manually edited file that incorporates districts from match where available\n",
    "missing info mostly comes from states where we have not pulled legislator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\archive\\no_districts_attendance_patch.xlsx\"\n",
    "districts_patch = pd.read_excel(patch_file)\n",
    "\n",
    "patched_df = pd.concat([w_districts,districts_patch])\n",
    "patched_df.reset_index(inplace=True, drop=True)\n",
    "i = 0\n",
    "for a,b in zip(patched_df.title, patched_df.org):\n",
    "    if re.search(r'[Hh]ouse|[Ss]enate', str(b)):\n",
    "        if re.search(r'[Hh]ouse', str(b)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enate', str(b)):\n",
    "            chamber = \"Senate\"\n",
    "    elif re.search(r'[Rr]epresentative|[Ss]enator|[Dd]elegate', str(a)):\n",
    "        if re.search(r'[Rr]epresentative|[Dd]elegate', str(a)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enator', str(a)):\n",
    "            chamber = \"Senate\"\n",
    "\n",
    "    try:\n",
    "        patched_df.loc[i,'chamber'] = str(chamber)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compiling events\n",
    "\n",
    "takes all of the events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#creating helper column\n",
    "patched_df['helper'] = patched_df['state'].astype(str)+ \"-\"+ patched_df['chamber'].astype(str)+ \"-\"+patched_df['district'].astype(str)\n",
    "patched_df.loc[patched_df['helper'].str.contains(r'^CT-Senate', regex=True), 'helper'] = patched_df['state'].astype(str)+ \"-\"+ patched_df['chamber'].astype(str)+ \"-S\"+patched_df['district'].astype(str)\n",
    "patched_df.loc[patched_df['helper'].str.contains(r'^ND-House'), 'helper'] = patched_df['state'].astype(str)+ \"-\"+ patched_df['chamber'].astype(str)+ \"-\"+patched_df['district'].astype(str)+\"-\"+patched_df['last_name'].astype(str)\n",
    "patched_df.loc[patched_df['state'].isna() | (patched_df['state'] == \"\") | (patched_df['district'].isna()), 'helper'] = None\n",
    "patch_minus_nan = patched_df[~(patched_df['helper'].isna())]\n",
    "# patched_df.loc[patched_df['helper'].str.contains(r'^ND-House'), 'helper'] = patched_df['state'].astype(str)+ \"-\"+ patched_df['chamber'].astype(str)+ \"-\"+patched_df['district'].astype(str)+\"-\"+patched_df['last_name'].astype(str)\n",
    "\n",
    "# print(patch_minus_nan.columns)\n",
    "thi_states_df = patch_minus_nan.loc[:,['helper','first_name', 'last_name', 'honorific', 'title', 'org', 'district',\n",
    "       'role', 'state', 'event name']]\n",
    "\n",
    "grouped_df = thi_states_df.groupby('helper').agg({\n",
    "    'first_name': 'first',\n",
    "    'last_name': 'first',\n",
    "    'honorific': 'first',\n",
    "    'title': 'first',\n",
    "    'org': 'first',\n",
    "    'district': 'first',\n",
    "    'state': 'first',\n",
    "    'event name': lambda x: '|'.join(\n",
    "        f\"{sc} ({ac})\" if not pd.isna(ac) else f\"{sc}\"\n",
    "        for sc, ac in zip(thi_states_df.loc[x.index, 'event name'], thi_states_df.loc[x.index, 'role'])),\n",
    "\n",
    "}).reset_index()\n",
    "# grouped_df.reset_index()\n",
    "grouped_df.rename(columns={'event name': 'events'}, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Cell below calculates the activities score from the attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_df.loc[:, 'activities_score'] = 0\n",
    "for i,j in enumerate(grouped_df['events']):\n",
    "    \n",
    "    \n",
    "    # split up events\n",
    "    event_split = str(j).split('|')\n",
    "    events = \";\".join(event_split)\n",
    "    # if len(event_split) < 2:\n",
    "    #     continue\n",
    "\n",
    "\n",
    "    # print(grouped_df.loc[i,['first_name','last_name' ]])\n",
    "    fname = grouped_df.at[i,'first_name']\n",
    "    lname = grouped_df.at[i,'last_name']\n",
    "\n",
    "\n",
    "    names = [fname, lname]\n",
    "    name = \" \".join(names)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # display_markdown(f' ## {name}', raw=True)\n",
    "    # print(bordered(events))\n",
    "\n",
    "\n",
    "    scores = []\n",
    "    for event in event_split:\n",
    "\n",
    "        # display_markdown(f' ## {event}', raw=True)\n",
    "        # #print(name)\n",
    "        score = 0\n",
    "        speaker = False\n",
    "        is_hkf = False\n",
    "        dev_program = False\n",
    "        in_state = False\n",
    "        out_state = False\n",
    "        is_slr = False\n",
    "        dinner_or_lunch = False\n",
    "        # non_slr = False\n",
    "        speaker = False\n",
    "        # #print('#################')\n",
    "        # #print(*grouped_df.loc[i,['helper','first_name', 'last_name', 'events']], sep=\" \\ \")\n",
    "        \n",
    "        \n",
    "        # #print(bordered(event))\n",
    "        if re.search(r'\\(.+\\)', str(event)):\n",
    "            match = re.findall(r'\\(.+\\)', str(event))\n",
    "            match_refine = [x for x in match if len(x) != 0]\n",
    "            #print(\"match refine results\", match_refine)\n",
    "            if len(match_refine) != 0:\n",
    "                for m in match_refine:\n",
    "                    if re.search('speaker|presenter', str(m).lower()):\n",
    "                        print('found a speaker')\n",
    "                        speaker = True\n",
    "                    elif 'HKF' in str(m):\n",
    "                        #print('THERE IS HKF IN THE RESULTS')\n",
    "                        is_hkf = True\n",
    "                \n",
    "        \n",
    "        \n",
    "        if re.search(r'[Dd]inner|[Ll]unch', str(event)):\n",
    "            dinner_or_lunch = True\n",
    "\n",
    "\n",
    "        state = str(grouped_df.loc[i,'helper']).split('-')[0].strip()\n",
    "        \n",
    "        # #print(re.match('ECLS', str(event)))\n",
    "        \n",
    "        if 'ECLS' not in str(event) or \"HKF\" not in str(event):\n",
    "            #print(\"no ecls or hKF\")\n",
    "            try:\n",
    "                event_state = re.findall(state_abv_pat, str(event))[0].strip()\n",
    "                if event_state == state:\n",
    "                #print(\"states match\")\n",
    "                    in_state = True\n",
    "                else:\n",
    "                    out_state = True\n",
    "            except:\n",
    "                \n",
    "                print(str(event))\n",
    "                print('no state match')\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            out_state = True\n",
    "            \n",
    "            \n",
    "\n",
    "        if 'HSPF' in str(event) or 'Elevate' in str(event):\n",
    "            dev_program = True\n",
    "\n",
    "        if re.search(r'SLR|HLR',str(event)):\n",
    "            is_slr = True\n",
    "\n",
    "        if re.search(r'\\s[Mm]\\d', str(event)):\n",
    "            non_slr = True\n",
    "        \n",
    "        variables = [\n",
    "        speaker,\n",
    "        is_hkf,\n",
    "        dev_program,\n",
    "        in_state,\n",
    "        out_state,\n",
    "        is_slr,\n",
    "        dinner_or_lunch\n",
    "        ]\n",
    "        # #print('quick look at logic')\n",
    "        # for var_name, var_value in zip(['speaker', 'is_hfk', 'dev_program', 'in_state', 'out_state', 'is_slr', 'dinner_or_lunch', 'non_slr', 'out_of_state'], variables):\n",
    "        #     #print(bordered(f\"{var_name}: {var_value}\"))\n",
    "        \n",
    "\n",
    "        #Event data\n",
    "        if is_slr == True:\n",
    "            score += 15\n",
    "            # print(f'adding 15 for {name} due to being an slr')\n",
    "        # else:\n",
    "        #     score += 10\n",
    "        #     #print(f'adding 10 for {name}')\n",
    "\n",
    "        elif dev_program == True:\n",
    "            score += 15\n",
    "            # print(f'adding 15 for {name} due to being in an dev program')\n",
    "        elif dinner_or_lunch == True:\n",
    "            score += 5\n",
    "            # print(f'adding 5 for {name} due to being a lunch or dinner')\n",
    "        else:\n",
    "            score += 10\n",
    "            # print(\"adding 10 for full day event with no other attributes\")\n",
    "\n",
    "        \n",
    "        #check for speaker\n",
    "        if speaker == True:\n",
    "            if in_state == True:\n",
    "                score += 0\n",
    "                #if in state no additional points\n",
    "                # print(f'adding 0 for {name} for being in state speaker')\n",
    "            elif out_state == True:\n",
    "                #if out of state add 5 more points for speakers\n",
    "                # print(f'adding 5 for {name} due ot being a speaker at an out of state event')\n",
    "                score += 5\n",
    "        \n",
    "        # check for hkf\n",
    "        if is_hkf == True:\n",
    "            score += 20\n",
    "            print(f'adding 20 for {name} due to being hkf')\n",
    "\n",
    "\n",
    "        \n",
    "        # print(bordered(score))\n",
    "        scores.append(score)\n",
    "\n",
    "    # display_markdown(f' ### {name}', raw=True)\n",
    "    # print(scores)\n",
    "    total = sum(scores)\n",
    "    # print(\"total: \",total)\n",
    "    \n",
    "    \n",
    "    grouped_df.loc[i, 'activities_score'] = total\n",
    "\n",
    "\n",
    "            \n",
    "print(grouped_df.to_string())\n",
    "\n",
    "    # continue\n",
    "\n",
    "        # print(\"%%%%%%%%%%%%%%%\")\n",
    "        # print(*match_refine, sep=' - ')\n",
    "        # print('%%%%%%%%%%%%%%%')\n",
    "\n",
    "    # continue\n",
    "\n",
    "    # speaker = False\n",
    "    # for event in event_split:\n",
    "    #     if re.search(r'\\(.+\\)', str(event)):\n",
    "    #         match = re.findall(r'\\(.+\\)', str(event))\n",
    "    #         match = match[0]\n",
    "    #         if 'speaker' in str(match).lower():\n",
    "    #             speaker = True\n",
    "            \n",
    "    # if len(event_split) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_scores = grouped_df.loc[:,['helper','first_name','last_name','activities_score', 'events']]\n",
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\build files')\n",
    "relationship_scores.to_csv('relationship_scores.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
