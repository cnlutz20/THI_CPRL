{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clutz\\hunt_env\\Scripts\\python.exe\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#importing modules\n",
    "import os, sys, json, datetime, re, xlrd  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "from openpyxl import Workbook\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "from setuptools import find_packages\n",
    "print(find_packages())\n",
    "\n",
    "\n",
    "from cprl_functions.state_capture import thi_states,state_ref, state_coding, state_pat, state_abv_pat\n",
    "from cprl_functions.text_printing import bordered\n",
    "from cprl_functions.defined_functions import create_pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering leg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AL\\\\AL_legislators_info_2024_12_11.xlsx', 'CT\\\\CT_legislators_info_2024_12_11.xlsx', 'IL\\\\IL_legislators_info_2024_12_11.xlsx', 'IN\\\\IN_legislators_info_2024_12_11.xlsx', 'KS\\\\KS_legislators_info_2024_12_11.xlsx', 'MO\\\\MO_legislators_info_2024_12_11.xlsx', 'NC\\\\NC_legislators_info_2024_12_11.xlsx', 'ND\\\\ND_legislators_info_2024_12_11.xlsx', 'NM\\\\NM_legislators_info_2024_12_11.xlsx', 'OH\\\\OH_legislators_info_2024_12_11.xlsx', 'OK\\\\OK_legislators_info_2024_12_11.xlsx', 'VA\\\\VA_legislators_info_2024_12_11.xlsx', 'WV\\\\WV_legislators_info_2024_12_11.xlsx']\n"
     ]
    }
   ],
   "source": [
    "#gather all legislator files from done folder\n",
    "#committee data should be updated before pulling this\n",
    "\n",
    "# os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\done')\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\2025')\n",
    "legislator_files = glob.glob('**/*_info*.xlsx')\n",
    "leg_files = [f for f in legislator_files if not f.endswith('_old.xlsx')]\n",
    "leg_files = [f for f in leg_files if re.search(r'12_11', str(f))]\n",
    "\n",
    "print(leg_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #gathering legislator files from one drive \n",
    "# os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\done')\n",
    "# legislator_files = glob.glob('*.xlsx') \n",
    "\n",
    "# for i,file in enumerate(legislator_files):\n",
    "#     if '_legislators' not in str(file).lower():\n",
    "#         print(\"deleting: \" + str(legislator_files[i]))\n",
    "#         del legislator_files[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#compiles legislator files into one file\n",
    "dfs = []\n",
    "for i,file in enumerate(legislator_files):\n",
    "    # print('working on file:' + str(file))\n",
    "    sheets_dict = pd.read_excel(file, engine=\"openpyxl\", sheet_name=None)\n",
    "    sheet_names = list(sheets_dict.keys())\n",
    "    for s in sheet_names:\n",
    "        df = pd.read_excel(file, engine=\"openpyxl\", sheet_name=s)\n",
    "        df = df.iloc[:,:9]\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "all_legs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all attendance data files\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data')\n",
    "events = glob.glob(\"*.xlsx\")\n",
    "print(*events, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Field Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in State info\n",
    "\n",
    "looks for state names in the title, org, and state fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE_LEG_ED_Dinner_2023.xlsx', 'ECLS_2024.xlsx', 'ElevateNC_C4_M3.xlsx', 'ElevateNC_C4_M4.xlsx', 'HBCU_Caucus_2024.xlsx', 'HKF_C10_S1.xlsx', 'HKF_Regional_Visit_FAU.xlsx', 'HSPF_C4_M1.xlsx', 'HSPF_C4_M2.xlsx', 'HSPF_C4_M3.xlsx', 'MO_SLR_2023.xlsx', 'NCCCS_M4.xlsx', 'NC_EC_Roundtable_2024.xlsx', 'NC_HLR_2024.xlsx', 'ND_Literacy_taskforce_2024.xlsx', 'ND_SLR_2023.xlsx', 'ND_SLR_2024.xlsx', 'ND_TRR_M1.xlsx', 'ND_TRR_m2.xlsx', 'ND_TRR_m3.xlsx', 'OH_SLR_2023.xlsx', 'OH_SLR_2024.xlsx', 'OK_SLR_2023.xlsx', 'OK_SLR_2024.xlsx', 'SC_Leg_Ed_Dinner_2023.xlsx', 'The_Path_Forward_2024.xlsx', 'WV_SLR_2023.xlsx', 'WV_SLR_2024.xlsx']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_state = \"North Carolina\"\n",
    "re.findall(state_pat, test_state)\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>honorific</th>\n",
       "      <th>title</th>\n",
       "      <th>org</th>\n",
       "      <th>district</th>\n",
       "      <th>role</th>\n",
       "      <th>state</th>\n",
       "      <th>event name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kyra</td>\n",
       "      <td>Hoffner</td>\n",
       "      <td>Senator</td>\n",
       "      <td>District 014 Senator</td>\n",
       "      <td>Deleware Senate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russell</td>\n",
       "      <td>Huxtable</td>\n",
       "      <td>Senator</td>\n",
       "      <td>District 006 Senator</td>\n",
       "      <td>Deleware Senate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura</td>\n",
       "      <td>Sturgeon</td>\n",
       "      <td>Senator</td>\n",
       "      <td>District 004 Senator</td>\n",
       "      <td>Deleware Senate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>Hilovsky</td>\n",
       "      <td>Representative</td>\n",
       "      <td>District 004 Representative</td>\n",
       "      <td>Deleware House of Representatives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie</td>\n",
       "      <td>Phillips</td>\n",
       "      <td>Representative</td>\n",
       "      <td>District 018 Representative</td>\n",
       "      <td>Deleware House of Representatives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Hank</td>\n",
       "      <td>Hager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Counsel</td>\n",
       "      <td>West Virginia State Senate Education Committee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>Kelley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistant Superintendent of District &amp; School ...</td>\n",
       "      <td>West Virginia Department of Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>JB</td>\n",
       "      <td>McCuskey</td>\n",
       "      <td>Auditor</td>\n",
       "      <td>West Virginia State Auditor</td>\n",
       "      <td>West Virginia State Auditor's Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Mike</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deputy Secretary of State</td>\n",
       "      <td>West Virginia Secretary of State's Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Mac</td>\n",
       "      <td>Warner</td>\n",
       "      <td>Secretary</td>\n",
       "      <td>West Virginia Secretary of State</td>\n",
       "      <td>West Virginia Secretary of State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1422 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_name last_name       honorific  \\\n",
       "0          Kyra   Hoffner         Senator   \n",
       "1       Russell  Huxtable         Senator   \n",
       "2         Laura  Sturgeon         Senator   \n",
       "3          Jeff  Hilovsky  Representative   \n",
       "4        Sophie  Phillips  Representative   \n",
       "...         ...       ...             ...   \n",
       "1417       Hank     Hager             NaN   \n",
       "1418       Jeff    Kelley             NaN   \n",
       "1419         JB  McCuskey         Auditor   \n",
       "1420       Mike     Queen             NaN   \n",
       "1421        Mac    Warner       Secretary   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                  District 014 Senator   \n",
       "1                                  District 006 Senator   \n",
       "2                                  District 004 Senator   \n",
       "3                           District 004 Representative   \n",
       "4                           District 018 Representative   \n",
       "...                                                 ...   \n",
       "1417                                      Chief Counsel   \n",
       "1418  Assistant Superintendent of District & School ...   \n",
       "1419                        West Virginia State Auditor   \n",
       "1420                          Deputy Secretary of State   \n",
       "1421                   West Virginia Secretary of State   \n",
       "\n",
       "                                                 org district            role  \\\n",
       "0                                    Deleware Senate      NaN             NaN   \n",
       "1                                    Deleware Senate      NaN             NaN   \n",
       "2                                    Deleware Senate      NaN             NaN   \n",
       "3                  Deleware House of Representatives      NaN             NaN   \n",
       "4                  Deleware House of Representatives      NaN             NaN   \n",
       "...                                              ...      ...             ...   \n",
       "1417  West Virginia State Senate Education Committee      NaN  Invited Guests   \n",
       "1418           West Virginia Department of Education      NaN  Invited Guests   \n",
       "1419            West Virginia State Auditor's Office      NaN  Invited Guests   \n",
       "1420       West Virginia Secretary of State's Office      NaN  Invited Guests   \n",
       "1421                West Virginia Secretary of State      NaN  Invited Guests   \n",
       "\n",
       "     state             event name  \n",
       "0       DE  DE LEG ED Dinner 2023  \n",
       "1       DE  DE LEG ED Dinner 2023  \n",
       "2       DE  DE LEG ED Dinner 2023  \n",
       "3       DE  DE LEG ED Dinner 2023  \n",
       "4       DE  DE LEG ED Dinner 2023  \n",
       "...    ...                    ...  \n",
       "1417    WV            WV SLR 2024  \n",
       "1418    WV            WV SLR 2024  \n",
       "1419    WV            WV SLR 2024  \n",
       "1420    WV            WV SLR 2024  \n",
       "1421    WV            WV SLR 2024  \n",
       "\n",
       "[1422 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "vals_changed = 0\n",
    "for event in events:\n",
    "    df = pd.read_excel(event)\n",
    "    # print('######################')\n",
    "    # print(bordered(event))\n",
    "    \n",
    "    # print(*df.columns)\n",
    "    event_name = str(event).split('.')[0].strip().replace('_', ' ')\n",
    "    df = df.iloc[:,:8]\n",
    "    df.loc[:,'event name'] = event_name\n",
    "    \n",
    "    break_all = False\n",
    "    # #print(df)\n",
    "    # continue\n",
    "    # display_markdown(f'## {event_name}', raw=True)\n",
    "    for i,state in enumerate(df['state']):\n",
    "        \n",
    "        # if \"HKF\" in str(df['event name'].iloc[i]): \n",
    "        #     print('###############################')\n",
    "        #     print(f'first name: {str(df.loc[i,'first_name'])}')\n",
    "        #     print(f'last name: {str(df.loc[i,'last_name'])}')\n",
    "        #     print(f'role: {str(df.loc[i,'role'])}')\n",
    "        #     print(f'org: {str(df.loc[i,'org'])}')\n",
    "        #     print(f'title: {str(df.loc[i,'title'])}')\n",
    "        \n",
    "        \n",
    "        #     hkf_match = re.findall(state_pat, str(df['org'].iloc[i]))\n",
    "        #     print(hkf_match)\n",
    "        #     if len(hkf_match) == 0:\n",
    "                \n",
    "        #     else:\n",
    "        #         print(hkf_match[0])\n",
    "        #         continue\n",
    "\n",
    "        \n",
    "        testing_string = str(df['title'].iloc[i]) + \" \" + str(df['org'].iloc[i])\n",
    "        # #print(testing_string)\n",
    "        testing_string = testing_string.lstrip('nan').lstrip().strip()\n",
    "        # #print(re.match(r'[Rr]epresentative|[Ss]enator|[Ll]egislator|[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse',str(testing_string)))\n",
    "        # continue\n",
    "        # #print('###########')\n",
    "        # #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "        # #print('\\n')\n",
    "\n",
    "        # if 'HFK' in str(df.loc[i,'role']):\n",
    "        # try:\n",
    "        state_match_uc = re.findall(state_pat, str(df.loc[i,'org']))\n",
    "        state_match = [x for x in state_match_uc if len(x) > 0]\n",
    "\n",
    "\n",
    "\n",
    "        # if 'hkf' in str(df.loc[i,'role']).lower():\n",
    "        #     print('HKF')\n",
    "        #     print(f'first name: {str(df.loc[i,'first_name'])}')\n",
    "        #     print(f'last name: {str(df.loc[i,'last_name'])}')\n",
    "        #     print(f'role: {str(df.loc[i,'role'])}')\n",
    "        #     print(f'org: {str(df.loc[i,'org'])}')\n",
    "        #     print(f'title: {str(df.loc[i,'title'])}')\n",
    "        #     try:\n",
    "        #         print(f'state match: {state_match[0]}')\n",
    "        #         continue\n",
    "        #     except:\n",
    "        #         print('no match found')\n",
    "        # else:\n",
    "        #     continue\n",
    "            \n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "        # First match test\n",
    "        if len(state_match) == 0:\n",
    "            ##print('no regular state match')\n",
    "            ##print(state_match_uc)\n",
    "            state_abv_match_uc = re.findall(state_abv_pat, str(df['org'].iloc[i]))\n",
    "            state_abv_match = [x for x in state_abv_match_uc if len(x) > 0]\n",
    "            # Second match test\n",
    "            if len(state_abv_match) == 0:\n",
    "                ##print('no state abbreviation match')\n",
    "                ##print(state_abv_match_uc)\n",
    "                state_abv_event_match_uc = re.findall(state_abv_pat, str(df['event name'].iloc[i]))\n",
    "                state_abv_event_match = [x for x in state_abv_event_match_uc if len(x) > 0]\n",
    "                # Third match test\n",
    "                if len(state_abv_event_match) == 0:\n",
    "                    #print('no state abv event match')\n",
    "                    #print(state_abv_event_match_uc)\n",
    "                    #print(f'first name: {str(df.loc[i,'first_name'])}')\n",
    "                    #print(f'last name: {str(df.loc[i,'last_name'])}')\n",
    "                    #print(f'role: {str(df.loc[i,'role'])}')\n",
    "                    #print(f'org: {str(df.loc[i,'org'])}')\n",
    "                    #print(f'title: {str(df.loc[i,'title'])}')\n",
    "                    continue\n",
    "                elif len(state_abv_event_match) > 1:\n",
    "                    #print('more than one match?')\n",
    "                    # break_all = True\n",
    "                    break\n",
    "                else:\n",
    "                    ##print(\"abv in event match\")\n",
    "                    state_val = str(state_abv_event_match[0])\n",
    "                    # df.loc[i,'state'] = None\n",
    "                    df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                    df.loc[i,'state'] = state_val\n",
    "                    ##print(state_val)\n",
    "                    vals_changed += 1\n",
    "            elif len(state_abv_match) > 1:\n",
    "                #print('more than one match?')\n",
    "                #print(state_abv_match)\n",
    "                ##print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "                break_all = True\n",
    "                break\n",
    "            else:\n",
    "                #print(\"regular abreviation match\")\n",
    "                \n",
    "                state_val = str(state_abv_match[0])\n",
    "                # df.loc[i,'state'] = None\n",
    "                df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                df.loc[i,'state'] = state_val\n",
    "                ##print(state_val)\n",
    "                vals_changed += 1\n",
    "\n",
    "            # ##print('###########')\n",
    "            # ##print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "            # ##print('\\n')\n",
    "            # break\n",
    "        elif len(state_match) > 1:\n",
    "            #print(\"more than one match?\")\n",
    "            # break_all = True\n",
    "            break\n",
    "        else:\n",
    "            # #print(\"normal state match\")\n",
    "            state_val_dirty = str(state_match[0])\n",
    "            state_val = state_ref.get(state_val_dirty)\n",
    "            # df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "            # df.loc[i,'state'] = None\n",
    "            df.loc[i,'state'] = str(state_val)\n",
    "            #print(state_val)\n",
    "            vals_changed += 1\n",
    "        # else:\n",
    "        #     # ##print('#########################')\n",
    "        #     # ##print('NOT A REP OR SEN')\n",
    "        #     # ##print(df.loc[i,['first_name','last_name','title', 'org']])\n",
    "        #     continue\n",
    "            # ##print(df.loc[i, list(df.columns[3:5]) + [df.columns[-1]]])\n",
    "            # ##print('\\n')\n",
    "    # if break_all == True:\n",
    "        # break\n",
    "    \n",
    "\n",
    "    dfs.append(df)\n",
    "event_data = pd.concat(dfs)\n",
    "event_data.reset_index(inplace=True, drop = True)\n",
    "\n",
    "\n",
    "event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#looks for state names and replaces them with state initials\n",
    "for i,j in enumerate(event_data['state']):\n",
    "    \n",
    "    if isinstance(j, float):\n",
    "        continue\n",
    "    elif re.search(r'[A-Z]{2}', str(j)):\n",
    "        continue\n",
    "    else:\n",
    "        val = state_ref.get(str(j))\n",
    "        event_data.loc[i,'state'] = str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "event_data.to_csv(\"event_data_export_12_11_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Legislator search pattern set up\n",
    "title_pattern = r'[Rr]epresentative|[Ss]enator|[Ll]egislator'\n",
    "org_pattern = r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|(?<!School )(?:House District|District)|[Ss]tate [Hh]ouse'\n",
    "exclude_pattern = r'[Aa]id(e)?|[Aa]ssistant|[Ss]taff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for state legislators\n",
    "filtered_df = event_data[\n",
    "    (\n",
    "        event_data['title'].astype(str).apply(lambda x: bool(re.search(title_pattern, x))) |\n",
    "        event_data['org'].astype(str).apply(lambda x: bool(re.search(org_pattern, x)))\n",
    "    ) &\n",
    "    ~(\n",
    "        event_data['org'].astype(str).apply(lambda x: bool(re.search(exclude_pattern, x)))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#regine values with districts\n",
    "w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True)) &\n",
    "                ~(filtered_df['title'].str.contains(r'[Aa]ssistant|[Aa]id(e)?|[Ss]taff', regex=True, na=False))]\n",
    "\n",
    "#find no districts\n",
    "n_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True)) &\n",
    "                ~(filtered_df['title'].str.contains(r'[Aa]ssistant|[Aa]id(e)?|[Ss]taff', regex=True, na=False))]\n",
    "\n",
    "\n",
    "#clean up\n",
    "w_districts.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for districts in title and org field\n",
    "i = 0\n",
    "for a,b in zip(w_districts.title, w_districts.org):\n",
    "\n",
    "\n",
    "    has_a = False\n",
    "    has_b = False\n",
    "    if 'district' in str(a).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(a)):\n",
    "        match_a = re.findall(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(a))\n",
    "        match_a = [x for x in match_a if len(x) > 0]\n",
    "        if len(match_a) == 0:\n",
    "            print('no results for title')\n",
    "            print(a)\n",
    "            \n",
    "        else:\n",
    "            has_a = True\n",
    "            match = re.sub(r'[A-Za-z]','',str(match_a[0]))\n",
    "\n",
    "    \n",
    "    if 'district' in str(b).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(b)):\n",
    "        match_b = re.findall(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(b))\n",
    "        match_b = [x for x in match_b if len(x) > 0]\n",
    "        if len(match_b) == 0:\n",
    "            print('no results for org')\n",
    "            print(b)\n",
    "        \n",
    "        else:\n",
    "            has_b = True\n",
    "            match = re.sub(r'[A-Za-z]','',str(match_b[0]))\n",
    "\n",
    "\n",
    "    if has_b == True or has_a == True:\n",
    "        match_final = re.findall(r'\\d+[A-Za-z]?', str(match))\n",
    "        # print(\"final match: \" + str(match_final[0]))\n",
    "        # print(\"putting it on row: \" + str(i))\n",
    "        w_districts.loc[i, 'district'] = str(match_final[0]).strip().lstrip('0')\n",
    "\n",
    "    i +=1\n",
    "# w_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data export to create patch file\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# n_districts.to_csv('no_districts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process patch file \n",
    "patch_file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\patch files\\no_districts_patch.csv\"\n",
    "districts_patch = pd.read_csv(patch_file)\n",
    "\n",
    "#pull together all data\n",
    "patched_df = pd.concat([w_districts,districts_patch])\n",
    "patched_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#looks through and assigns chamber column to either house or senate\n",
    "w_districts['chamber'] = \"\"\n",
    "i = 0\n",
    "for a,b in zip(patched_df.title, patched_df.org):\n",
    "    if re.search(r'[Hh]ouse|[Ss]enate', str(b)):\n",
    "        if re.search(r'[Hh]ouse', str(b)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enate', str(b)):\n",
    "            chamber = \"Senate\"\n",
    "    elif re.search(r'[Rr]epresentative|[Ss]enator|[Dd]elegate', str(a)):\n",
    "        if re.search(r'[Rr]epresentative|[Dd]elegate', str(a)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enator', str(a)):\n",
    "            chamber = \"Senate\"\n",
    "\n",
    "    try:\n",
    "        patched_df.loc[i,'chamber'] = str(chamber)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "#find only thi states\n",
    "patched_df = patched_df[patched_df['state'].isin(thi_states)]\n",
    "patched_df = patched_df[~patched_df['district'].isna()]\n",
    "patched_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#name edits\n",
    "patched_df['first_name'] = patched_df['first_name'].str.strip().str.title()\n",
    "patched_df['last_name'] = patched_df['last_name'].str.strip().str.title().str.replace(\"' \", \"'\")\n",
    "# condition = patched_df['last_name'].str.contains(r'(?!\\w+)\\s(?<!\\w)', regex = True)\n",
    "# patched_df.loc[condition, 'last_name'] = (patched_df['last_name'].str.split(r'\\s*,\\s*(?=[A-Z])').str[0])\n",
    "# Identify rows where 'last_name' has two words separated by whitespace\n",
    "\n",
    "# patched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df,duplicates = create_pk(patched_df,'district', 'chamber')\n",
    "\n",
    "# clean_dfs = [cleaned_df,duplicates]\n",
    "# clean_df = pd.concat(clean_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(duplicates.columns)\n",
    "#grouping data together and getting list of events per legislator\n",
    "grouped_df = duplicates.groupby(['primary_key','last_name']).agg({\n",
    "    'state': 'first',\n",
    "    'first_name': 'first',\n",
    "    'event name': lambda x: '|'.join(\n",
    "        list(set(f\"{sc} ({ac})\" if not pd.isna(ac) else f\"{sc}\"\n",
    "        for sc, ac in zip(duplicates.loc[x.index, 'event name'], duplicates.loc[x.index, 'role']))))\n",
    "\n",
    "}).reset_index()\n",
    "# grouped_df.reset_index()\n",
    "grouped_df.rename(columns={'event name': 'events'}, inplace=True)\n",
    "# state_coding\n",
    "# grouped_df\n",
    "# print(cleaned_df.columns)\n",
    "\n",
    "\n",
    "#clean up grouped data\n",
    "non_dupe_df = cleaned_df.loc[:,['primary_key', 'first_name','last_name', 'state','event name']]\n",
    "non_dupe_df.rename(columns={'event name': 'events'}, inplace=True)\n",
    "\n",
    "#pull event data back together\n",
    "merged_dfs = [grouped_df, non_dupe_df]\n",
    "leg_events_df = pd.concat(merged_dfs)\n",
    "# print(leg_events_df.columns)\n",
    "\n",
    "\n",
    "#find dupes\n",
    "leg_events_df_dupes = leg_events_df[leg_events_df.duplicated(subset='primary_key', keep = False)]\n",
    "leg_events_df_dupes.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "#find none dupes and add seat\n",
    "leg_events_df_nodupes = leg_events_df[~leg_events_df.duplicated(subset='primary_key', keep = False)]\n",
    "leg_events_df_nodupes['seat'] = '00'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# print(f\"checking for {trunc_name}\")\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#look for the key, get results, and split up the names into a list\u001b[39;00m\n\u001b[0;32m     29\u001b[0m results \u001b[38;5;241m=\u001b[39m loop_dict\u001b[38;5;241m.\u001b[39mget(j)\n\u001b[1;32m---> 30\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#get length of names\u001b[39;00m\n\u001b[0;32m     33\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(names)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "#pull in key lookup\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors')\n",
    "\n",
    "leg_lookup_file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\all_legs_files\\all_legs_files_2024_12_11.csv\"\n",
    "leg_lookup_ref = pd.read_csv(leg_lookup_file)\n",
    "\n",
    "#groupby data to get primary key and last names associated with it\n",
    "loop_group = leg_lookup_ref.groupby(['primary_key']).agg({\n",
    "    'Last Name': lambda x: '|'.join(\n",
    "        list(set(f\"{sc}\" if not pd.isna(sc) else \"not found\"\n",
    "        for sc in leg_lookup_ref.loc[x.index, 'Last Name'])))\n",
    "}).reset_index()\n",
    "\n",
    "#set up dict for lookup\n",
    "loop_dict = loop_group.set_index('primary_key')['Last Name'].to_dict()\n",
    "\n",
    "#create seat for dupes\n",
    "leg_events_df_dupes['seat'] = np.nan\n",
    "for i,j in enumerate(leg_events_df_dupes['primary_key']):\n",
    "    #ensure j is an integer\n",
    "    j = int(j)\n",
    "    \n",
    "    #get name we are looking for\n",
    "    name_to_check = leg_events_df_dupes.loc[i,'last_name']\n",
    "    trunc_name = str(name_to_check)[:3]\n",
    "    # print(f\"checking for {trunc_name}\")\n",
    "    \n",
    "    #look for the key, get results, and split up the names into a list\n",
    "    results = loop_dict.get(j)\n",
    "    names = results.split('|')\n",
    "    \n",
    "    #get length of names\n",
    "    n = len(names)-1\n",
    "    \n",
    "    #go through and check if the name matches either of the one in the list and return the seat\n",
    "    for ik,name in enumerate(names):\n",
    "        # print(f\"going through {ik}\")\n",
    "        # print(type(name))\n",
    "        # print(type(trunc_name))\n",
    "        if re.search(f'^{trunc_name.strip()}', str(name)):\n",
    "            # print('found it')\n",
    "            seat = ik + 1\n",
    "            leg_events_df_dupes.loc[i,'seat'] = f'0{seat}'\n",
    "            break\n",
    "        #stops if we are on the last iteration and still no seat\n",
    "        elif ik == n:\n",
    "            print(f\"couldn't find one for '{trunc_name}' aka '{name_to_check}' in {names} with length for it being {len(trunc_name)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(leg_events_df_nodupes.columns)\n",
    "# print(leg_events_df_dupes.columns)\n",
    "\n",
    "#pull all event data back together\n",
    "events_dfs = [leg_events_df_dupes, leg_events_df_nodupes]\n",
    "events_df = pd.concat(events_dfs)\n",
    "events_df.dropna(subset=['seat'], inplace=True)\n",
    "events_df.reset_index(inplace=True, drop=True)\n",
    "# events_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having issues where just applying the last part of the create pk function just assigns people with same last name different seats. Might need to run create_pk without athe seat numbers first, group the (but keeping the last name for differences) and then assign seat numbers based on that. Can create a mid point look up value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Cell below calculates the activities score from the attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Score for loop\n",
    "\n",
    "\n",
    "# print(events_df.columns)\n",
    "#For loop description: goes through events column and gathers information for activities scoring\n",
    "events_df.loc[:, 'activities_score'] = 0\n",
    "for i,j in enumerate(events_df['events']):\n",
    "    \n",
    "    \n",
    "    # split up events\n",
    "    event_split = str(j).split('|')\n",
    "    events = \";\".join(event_split)\n",
    "    # if len(event_split) < 2:\n",
    "    #     continue\n",
    "\n",
    "\n",
    "    #compile name for print statements\n",
    "\n",
    "    # fname = grouped_df.at[i,'first_name']\n",
    "    lname = events_df.at[i,'last_name']\n",
    "\n",
    "    # names = [fname, lname]\n",
    "    # name = \" \".join(names)\n",
    "    \n",
    "    \n",
    "    # display_markdown(f' ## {name}', raw=True)\n",
    "    # print(bordered(events))\n",
    "\n",
    "    #For loop description: go through each event and score \n",
    "    scores = []\n",
    "    for event in event_split:\n",
    "\n",
    "        #intializing boolean values for scoring    \n",
    "        score = 0\n",
    "        speaker = False\n",
    "        is_hkf = False\n",
    "        dev_program = False\n",
    "        in_state = False\n",
    "        out_state = False\n",
    "        is_slr = False\n",
    "        dinner_or_lunch = False\n",
    "        # non_slr = False\n",
    "        speaker = False\n",
    "        # #print('#################')\n",
    "        # #print(*grouped_df.loc[i,['helper','first_name', 'last_name', 'events']], sep=\" \\ \")\n",
    "        \n",
    "        \n",
    "        # #print(bordered(event))\n",
    "\n",
    "        #Look through for roles in events\n",
    "        if re.search(r'\\(.+\\)', str(event)):\n",
    "            match = re.findall(r'\\(.+\\)', str(event))\n",
    "            match_refine = [x for x in match if len(x) != 0]\n",
    "            #print(\"match refine results\", match_refine)\n",
    "            if len(match_refine) != 0:\n",
    "                for m in match_refine:\n",
    "                    if re.search('speaker|presenter', str(m).lower()):\n",
    "                        # print('found a speaker')\n",
    "                        speaker = True\n",
    "                    elif 'HKF' in str(m):\n",
    "                        #print('THERE IS HKF IN THE RESULTS')\n",
    "                        is_hkf = True\n",
    "                \n",
    "        \n",
    "        #is it just a short engagment such as a dinner or lunch?\n",
    "        if re.search(r'[Dd]inner|[Ll]unch', str(event)):\n",
    "            dinner_or_lunch = True\n",
    "\n",
    "        #get state\n",
    "        state = events_df.loc[i,'state']\n",
    "        \n",
    "        #looking for whether events where in state or out of state\n",
    "        if 'ECLS' not in str(event) or \"HKF\" not in str(event):\n",
    "            #print(\"no ecls or hKF\")\n",
    "            try:\n",
    "                event_state = re.findall(state_abv_pat, str(event))[0].strip()\n",
    "                if event_state == state:\n",
    "                #print(\"states match\")\n",
    "                    in_state = True\n",
    "                else:\n",
    "                    out_state = True\n",
    "            except:\n",
    "                out_state = True\n",
    "                # print(str(event))\n",
    "                # print('no state match')\n",
    "        else:\n",
    "            out_state = True\n",
    "            \n",
    "            \n",
    "        #lower dev program?\n",
    "        if 'HSPF' in str(event) or 'Elevate' in str(event):\n",
    "            dev_program = True\n",
    "\n",
    "        #State Legislator event?\n",
    "        if re.search(r'SLR|HLR',str(event)):\n",
    "            is_slr = True\n",
    "\n",
    "\n",
    "        # if re.search(r'\\s[Mm]\\d', str(event)):\n",
    "        #     non_slr = True\n",
    "        \n",
    "        variables = [\n",
    "        speaker,\n",
    "        is_hkf,\n",
    "        dev_program,\n",
    "        in_state,\n",
    "        out_state,\n",
    "        is_slr,\n",
    "        dinner_or_lunch\n",
    "        ]\n",
    "\n",
    "        #Trouble shooting print statement to make sure logic is working\n",
    "        # #print('quick look at logic')\n",
    "        # for var_name, var_value in zip(['speaker', 'is_hfk', 'dev_program', 'in_state', 'out_state', 'is_slr', 'dinner_or_lunch', 'non_slr', 'out_of_state'], variables):\n",
    "        #     #print(bordered(f\"{var_name}: {var_value}\"))\n",
    "        \n",
    "\n",
    "        #Event data scoring \n",
    "        if is_slr == True:\n",
    "            score += 15\n",
    "            # print(f'adding 15 for {name} due to being an slr')\n",
    "        # else:\n",
    "        #     score += 10\n",
    "        #     #print(f'adding 10 for {name}')\n",
    "\n",
    "        elif dev_program == True:\n",
    "            score += 15\n",
    "            # print(f'adding 15 for {name} due to being in an dev program')\n",
    "        elif dinner_or_lunch == True:\n",
    "            score += 5\n",
    "            # print(f'adding 5 for {name} due to being a lunch or dinner')\n",
    "        else:\n",
    "            score += 10\n",
    "            # print(\"adding 10 for full day event with no other attributes\")\n",
    "\n",
    "        \n",
    "        #check for speaker\n",
    "        if speaker == True:\n",
    "            if in_state == True:\n",
    "                score += 0\n",
    "                #if in state no additional points\n",
    "                # print(f'adding 0 for {name} for being in state speaker')\n",
    "            elif out_state == True:\n",
    "                #if out of state add 5 more points for speakers\n",
    "                # print(f'adding 5 for {name} due ot being a speaker at an out of state event')\n",
    "                score += 5\n",
    "        \n",
    "        # check for hkf\n",
    "        if is_hkf == True:\n",
    "            score += 20\n",
    "            # print(f'adding 20 for {lname} due to being hkf')\n",
    "\n",
    "\n",
    "        \n",
    "        # print(bordered(score))\n",
    "        scores.append(score)\n",
    "\n",
    "    # display_markdown(f' ### {name}', raw=True)\n",
    "    # print(scores)\n",
    "    total = sum(scores)\n",
    "    # print(\"total: \",total)\n",
    "    \n",
    "    \n",
    "    events_df.loc[i, 'activities_score'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_pk , primary_key , first_name , last_name , activities_score , events\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "#export activity scores df\n",
    "activity_scores = events_df.loc[:,['primary_key','seat','first_name','last_name','activities_score', 'events']]\n",
    "\n",
    "#make full_pk and convert to int\n",
    "activity_scores['full_pk'] = activity_scores['primary_key'].astype(str) + activity_scores['seat'].astype(str)\n",
    "activity_scores['full_pk'] = activity_scores['full_pk'].astype(int)\n",
    "\n",
    "#put full_pk to front\n",
    "activity_scores = activity_scores.drop('seat', axis=1)\n",
    "first_column = activity_scores.pop('full_pk')\n",
    "activity_scores.insert(0, 'full_pk', first_column)\n",
    "print(*activity_scores.columns, sep = ' , ')\n",
    "activity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\build files')\n",
    "\n",
    "\n",
    "activity_scores.to_csv(f'activity_scores{str(date.today()).replace('-','_')}.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "# activity_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
