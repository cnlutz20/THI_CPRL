{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clutz\\hunt_env\\Scripts\\python.exe\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#importing modules\n",
    "import os, sys, json, datetime, re, xlrd  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "from openpyxl import Workbook\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "from setuptools import find_packages\n",
    "print(find_packages())\n",
    "\n",
    "\n",
    "from cprl_functions.state_capture import thi_states,state_ref, state_coding, state_pat, state_abv_pat\n",
    "from cprl_functions.text_printing import bordered\n",
    "from cprl_functions.defined_functions import create_pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering leg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering legislator files from one drive \n",
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\done')\n",
    "legislator_files = glob.glob('*.xlsx') \n",
    "\n",
    "for i,file in enumerate(legislator_files):\n",
    "    if '_legislators' not in str(file).lower():\n",
    "        print(\"deleting: \" + str(legislator_files[i]))\n",
    "        del legislator_files[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#compiles legislator files into one file\n",
    "dfs = []\n",
    "for i,file in enumerate(legislator_files):\n",
    "    # print('working on file:' + str(file))\n",
    "    sheets_dict = pd.read_excel(file, engine=\"openpyxl\", sheet_name=None)\n",
    "    sheet_names = list(sheets_dict.keys())\n",
    "    for s in sheet_names:\n",
    "        df = pd.read_excel(file, engine=\"openpyxl\", sheet_name=s)\n",
    "        df = df.iloc[:,:9]\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "all_legs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE_LEG_ED_Dinner_2023.xlsx\n",
      "ECLS_2024.xlsx\n",
      "ElevateNC_C4_M3.xlsx\n",
      "ElevateNC_C4_M4.xlsx\n",
      "HKF_C10_S1.xlsx\n",
      "HKF_Regional_Visit_FAU.xlsx\n",
      "HSPF_C4_M1.xlsx\n",
      "HSPF_C4_M2.xlsx\n",
      "HSPF_C4_M3.xlsx\n",
      "MO_SLR_2023.xlsx\n",
      "NCCCS_M4.xlsx\n",
      "NC_EC_Roundtable_2024.xlsx\n",
      "NC_HLR_2024.xlsx\n",
      "ND_Literacy_taskforce_2024.xlsx\n",
      "ND_SLR_2023.xlsx\n",
      "ND_SLR_2024.xlsx\n",
      "ND_TRR_M1.xlsx\n",
      "ND_TRR_m2.xlsx\n",
      "ND_TRR_m3.xlsx\n",
      "OH_SLR_2023.xlsx\n",
      "OH_SLR_2024.xlsx\n",
      "OK_SLR_2023.xlsx\n",
      "OK_SLR_2024.xlsx\n",
      "SC_Leg_Ed_Dinner_2023.xlsx\n",
      "The_Path_Forward_2024.xlsx\n",
      "WV_SLR_2023.xlsx\n",
      "WV_SLR_2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "# import all attendance data files\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data')\n",
    "events = glob.glob(\"*.xlsx\")\n",
    "print(*events, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Field Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in State info\n",
    "\n",
    "looks for state names in the title, org, and state fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE_LEG_ED_Dinner_2023.xlsx', 'ECLS_2024.xlsx', 'ElevateNC_C4_M3.xlsx', 'ElevateNC_C4_M4.xlsx', 'HKF_C10_S1.xlsx', 'HKF_Regional_Visit_FAU.xlsx', 'HSPF_C4_M1.xlsx', 'HSPF_C4_M2.xlsx', 'HSPF_C4_M3.xlsx', 'MO_SLR_2023.xlsx', 'NCCCS_M4.xlsx', 'NC_EC_Roundtable_2024.xlsx', 'NC_HLR_2024.xlsx', 'ND_Literacy_taskforce_2024.xlsx', 'ND_SLR_2023.xlsx', 'ND_SLR_2024.xlsx', 'ND_TRR_M1.xlsx', 'ND_TRR_m2.xlsx', 'ND_TRR_m3.xlsx', 'OH_SLR_2023.xlsx', 'OH_SLR_2024.xlsx', 'OK_SLR_2023.xlsx', 'OK_SLR_2024.xlsx', 'SC_Leg_Ed_Dinner_2023.xlsx', 'The_Path_Forward_2024.xlsx', 'WV_SLR_2023.xlsx', 'WV_SLR_2024.xlsx']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_state = \"North Carolina\"\n",
    "re.findall(state_pat, test_state)\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>honorific</th>\n",
       "      <th>title</th>\n",
       "      <th>org</th>\n",
       "      <th>district</th>\n",
       "      <th>role</th>\n",
       "      <th>state</th>\n",
       "      <th>event name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kyra</td>\n",
       "      <td>Hoffner</td>\n",
       "      <td>Senator</td>\n",
       "      <td>District 014 Senator</td>\n",
       "      <td>Deleware Senate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russell</td>\n",
       "      <td>Huxtable</td>\n",
       "      <td>Senator</td>\n",
       "      <td>District 006 Senator</td>\n",
       "      <td>Deleware Senate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura</td>\n",
       "      <td>Sturgeon</td>\n",
       "      <td>Senator</td>\n",
       "      <td>District 004 Senator</td>\n",
       "      <td>Deleware Senate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>Hilovsky</td>\n",
       "      <td>Representative</td>\n",
       "      <td>District 004 Representative</td>\n",
       "      <td>Deleware House of Representatives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie</td>\n",
       "      <td>Phillips</td>\n",
       "      <td>Representative</td>\n",
       "      <td>District 018 Representative</td>\n",
       "      <td>Deleware House of Representatives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE LEG ED Dinner 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>Hank</td>\n",
       "      <td>Hager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Counsel</td>\n",
       "      <td>West Virginia State Senate Education Committee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>Kelley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistant Superintendent of District &amp; School ...</td>\n",
       "      <td>West Virginia Department of Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>JB</td>\n",
       "      <td>McCuskey</td>\n",
       "      <td>Auditor</td>\n",
       "      <td>West Virginia State Auditor</td>\n",
       "      <td>West Virginia State Auditor's Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Mike</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deputy Secretary of State</td>\n",
       "      <td>West Virginia Secretary of State's Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>Mac</td>\n",
       "      <td>Warner</td>\n",
       "      <td>Secretary</td>\n",
       "      <td>West Virginia Secretary of State</td>\n",
       "      <td>West Virginia Secretary of State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invited Guests</td>\n",
       "      <td>WV</td>\n",
       "      <td>WV SLR 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1355 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_name last_name       honorific  \\\n",
       "0          Kyra   Hoffner         Senator   \n",
       "1       Russell  Huxtable         Senator   \n",
       "2         Laura  Sturgeon         Senator   \n",
       "3          Jeff  Hilovsky  Representative   \n",
       "4        Sophie  Phillips  Representative   \n",
       "...         ...       ...             ...   \n",
       "1350       Hank     Hager             NaN   \n",
       "1351       Jeff    Kelley             NaN   \n",
       "1352         JB  McCuskey         Auditor   \n",
       "1353       Mike     Queen             NaN   \n",
       "1354        Mac    Warner       Secretary   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                  District 014 Senator   \n",
       "1                                  District 006 Senator   \n",
       "2                                  District 004 Senator   \n",
       "3                           District 004 Representative   \n",
       "4                           District 018 Representative   \n",
       "...                                                 ...   \n",
       "1350                                      Chief Counsel   \n",
       "1351  Assistant Superintendent of District & School ...   \n",
       "1352                        West Virginia State Auditor   \n",
       "1353                          Deputy Secretary of State   \n",
       "1354                   West Virginia Secretary of State   \n",
       "\n",
       "                                                 org  district  \\\n",
       "0                                    Deleware Senate       NaN   \n",
       "1                                    Deleware Senate       NaN   \n",
       "2                                    Deleware Senate       NaN   \n",
       "3                  Deleware House of Representatives       NaN   \n",
       "4                  Deleware House of Representatives       NaN   \n",
       "...                                              ...       ...   \n",
       "1350  West Virginia State Senate Education Committee       NaN   \n",
       "1351           West Virginia Department of Education       NaN   \n",
       "1352            West Virginia State Auditor's Office       NaN   \n",
       "1353       West Virginia Secretary of State's Office       NaN   \n",
       "1354                West Virginia Secretary of State       NaN   \n",
       "\n",
       "                role state             event name  \n",
       "0                NaN    DE  DE LEG ED Dinner 2023  \n",
       "1                NaN    DE  DE LEG ED Dinner 2023  \n",
       "2                NaN    DE  DE LEG ED Dinner 2023  \n",
       "3                NaN    DE  DE LEG ED Dinner 2023  \n",
       "4                NaN    DE  DE LEG ED Dinner 2023  \n",
       "...              ...   ...                    ...  \n",
       "1350  Invited Guests    WV            WV SLR 2024  \n",
       "1351  Invited Guests    WV            WV SLR 2024  \n",
       "1352  Invited Guests    WV            WV SLR 2024  \n",
       "1353  Invited Guests    WV            WV SLR 2024  \n",
       "1354  Invited Guests    WV            WV SLR 2024  \n",
       "\n",
       "[1355 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "vals_changed = 0\n",
    "for event in events:\n",
    "    df = pd.read_excel(event)\n",
    "    # print('######################')\n",
    "    # print(bordered(event))\n",
    "    \n",
    "    # print(*df.columns)\n",
    "    event_name = str(event).split('.')[0].strip().replace('_', ' ')\n",
    "    df = df.iloc[:,:8]\n",
    "    df.loc[:,'event name'] = event_name\n",
    "    \n",
    "    break_all = False\n",
    "    # #print(df)\n",
    "    # continue\n",
    "    # display_markdown(f'## {event_name}', raw=True)\n",
    "    for i,state in enumerate(df['state']):\n",
    "        \n",
    "        # if \"HKF\" in str(df['event name'].iloc[i]): \n",
    "        #     print('###############################')\n",
    "        #     print(f'first name: {str(df.loc[i,'first_name'])}')\n",
    "        #     print(f'last name: {str(df.loc[i,'last_name'])}')\n",
    "        #     print(f'role: {str(df.loc[i,'role'])}')\n",
    "        #     print(f'org: {str(df.loc[i,'org'])}')\n",
    "        #     print(f'title: {str(df.loc[i,'title'])}')\n",
    "        \n",
    "        \n",
    "        #     hkf_match = re.findall(state_pat, str(df['org'].iloc[i]))\n",
    "        #     print(hkf_match)\n",
    "        #     if len(hkf_match) == 0:\n",
    "                \n",
    "        #     else:\n",
    "        #         print(hkf_match[0])\n",
    "        #         continue\n",
    "\n",
    "        \n",
    "        testing_string = str(df['title'].iloc[i]) + \" \" + str(df['org'].iloc[i])\n",
    "        # #print(testing_string)\n",
    "        testing_string = testing_string.lstrip('nan').lstrip().strip()\n",
    "        # #print(re.match(r'[Rr]epresentative|[Ss]enator|[Ll]egislator|[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse',str(testing_string)))\n",
    "        # continue\n",
    "        # #print('###########')\n",
    "        # #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "        # #print('\\n')\n",
    "\n",
    "        # if 'HFK' in str(df.loc[i,'role']):\n",
    "        # try:\n",
    "        state_match_uc = re.findall(state_pat, str(df.loc[i,'org']))\n",
    "        state_match = [x for x in state_match_uc if len(x) > 0]\n",
    "\n",
    "\n",
    "\n",
    "        # if 'hkf' in str(df.loc[i,'role']).lower():\n",
    "        #     print('HKF')\n",
    "        #     print(f'first name: {str(df.loc[i,'first_name'])}')\n",
    "        #     print(f'last name: {str(df.loc[i,'last_name'])}')\n",
    "        #     print(f'role: {str(df.loc[i,'role'])}')\n",
    "        #     print(f'org: {str(df.loc[i,'org'])}')\n",
    "        #     print(f'title: {str(df.loc[i,'title'])}')\n",
    "        #     try:\n",
    "        #         print(f'state match: {state_match[0]}')\n",
    "        #         continue\n",
    "        #     except:\n",
    "        #         print('no match found')\n",
    "        # else:\n",
    "        #     continue\n",
    "            \n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "        # First match test\n",
    "        if len(state_match) == 0:\n",
    "            ##print('no regular state match')\n",
    "            ##print(state_match_uc)\n",
    "            state_abv_match_uc = re.findall(state_abv_pat, str(df['org'].iloc[i]))\n",
    "            state_abv_match = [x for x in state_abv_match_uc if len(x) > 0]\n",
    "            # Second match test\n",
    "            if len(state_abv_match) == 0:\n",
    "                ##print('no state abbreviation match')\n",
    "                ##print(state_abv_match_uc)\n",
    "                state_abv_event_match_uc = re.findall(state_abv_pat, str(df['event name'].iloc[i]))\n",
    "                state_abv_event_match = [x for x in state_abv_event_match_uc if len(x) > 0]\n",
    "                # Third match test\n",
    "                if len(state_abv_event_match) == 0:\n",
    "                    #print('no state abv event match')\n",
    "                    #print(state_abv_event_match_uc)\n",
    "                    #print(f'first name: {str(df.loc[i,'first_name'])}')\n",
    "                    #print(f'last name: {str(df.loc[i,'last_name'])}')\n",
    "                    #print(f'role: {str(df.loc[i,'role'])}')\n",
    "                    #print(f'org: {str(df.loc[i,'org'])}')\n",
    "                    #print(f'title: {str(df.loc[i,'title'])}')\n",
    "                    continue\n",
    "                elif len(state_abv_event_match) > 1:\n",
    "                    #print('more than one match?')\n",
    "                    # break_all = True\n",
    "                    break\n",
    "                else:\n",
    "                    ##print(\"abv in event match\")\n",
    "                    state_val = str(state_abv_event_match[0])\n",
    "                    # df.loc[i,'state'] = None\n",
    "                    df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                    df.loc[i,'state'] = state_val\n",
    "                    ##print(state_val)\n",
    "                    vals_changed += 1\n",
    "            elif len(state_abv_match) > 1:\n",
    "                #print('more than one match?')\n",
    "                #print(state_abv_match)\n",
    "                ##print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "                break_all = True\n",
    "                break\n",
    "            else:\n",
    "                #print(\"regular abreviation match\")\n",
    "                \n",
    "                state_val = str(state_abv_match[0])\n",
    "                # df.loc[i,'state'] = None\n",
    "                df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                df.loc[i,'state'] = state_val\n",
    "                ##print(state_val)\n",
    "                vals_changed += 1\n",
    "\n",
    "            # ##print('###########')\n",
    "            # ##print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "            # ##print('\\n')\n",
    "            # break\n",
    "        elif len(state_match) > 1:\n",
    "            #print(\"more than one match?\")\n",
    "            # break_all = True\n",
    "            break\n",
    "        else:\n",
    "            # #print(\"normal state match\")\n",
    "            state_val_dirty = str(state_match[0])\n",
    "            state_val = state_ref.get(state_val_dirty)\n",
    "            # df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "            # df.loc[i,'state'] = None\n",
    "            df.loc[i,'state'] = str(state_val)\n",
    "            #print(state_val)\n",
    "            vals_changed += 1\n",
    "        # else:\n",
    "        #     # ##print('#########################')\n",
    "        #     # ##print('NOT A REP OR SEN')\n",
    "        #     # ##print(df.loc[i,['first_name','last_name','title', 'org']])\n",
    "        #     continue\n",
    "            # ##print(df.loc[i, list(df.columns[3:5]) + [df.columns[-1]]])\n",
    "            # ##print('\\n')\n",
    "    # if break_all == True:\n",
    "        # break\n",
    "    \n",
    "\n",
    "    dfs.append(df)\n",
    "event_data = pd.concat(dfs)\n",
    "event_data.reset_index(inplace=True, drop = True)\n",
    "\n",
    "\n",
    "event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#looks for state names and replaces them with state initials\n",
    "for i,j in enumerate(event_data['state']):\n",
    "    \n",
    "    if isinstance(j, float):\n",
    "        continue\n",
    "    elif re.search(r'[A-Z]{2}', str(j)):\n",
    "        continue\n",
    "    else:\n",
    "        val = state_ref.get(str(j))\n",
    "        event_data.loc[i,'state'] = str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# event_data.to_csv(\"event_data_export_11_7_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Legislator search pattern set up\n",
    "title_pattern = r'[Rr]epresentative|[Ss]enator|[Ll]egislator'\n",
    "org_pattern = r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|(?<!School )(?:House District|District)|[Ss]tate [Hh]ouse'\n",
    "exclude_pattern = r'[Aa]id(e)?|[Aa]ssistant|[Ss]taff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for state legislators\n",
    "filtered_df = event_data[\n",
    "    (\n",
    "        event_data['title'].astype(str).apply(lambda x: bool(re.search(title_pattern, x))) |\n",
    "        event_data['org'].astype(str).apply(lambda x: bool(re.search(org_pattern, x)))\n",
    "    ) &\n",
    "    ~(\n",
    "        event_data['org'].astype(str).apply(lambda x: bool(re.search(exclude_pattern, x)))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_25444\\765334227.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) |\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_25444\\765334227.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True)) &\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_25444\\765334227.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  ~(filtered_df['title'].str.contains(r'[Aa]ssistant|[Aa]id(e)?|[Ss]taff', regex=True, na=False))]\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_25444\\765334227.py:7: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  n_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) |\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_25444\\765334227.py:8: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True)) &\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_25444\\765334227.py:9: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  ~(filtered_df['title'].str.contains(r'[Aa]ssistant|[Aa]id(e)?|[Ss]taff', regex=True, na=False))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#regine values with districts\n",
    "w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True)) &\n",
    "                ~(filtered_df['title'].str.contains(r'[Aa]ssistant|[Aa]id(e)?|[Ss]taff', regex=True, na=False))]\n",
    "\n",
    "#find no districts\n",
    "n_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd](-|\\s)?\\d{2,3}[A-Za-z]?', regex=True)) &\n",
    "                ~(filtered_df['title'].str.contains(r'[Aa]ssistant|[Aa]id(e)?|[Ss]taff', regex=True, na=False))]\n",
    "\n",
    "\n",
    "#clean up\n",
    "w_districts.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for districts in title and org field\n",
    "i = 0\n",
    "for a,b in zip(w_districts.title, w_districts.org):\n",
    "\n",
    "\n",
    "    has_a = False\n",
    "    has_b = False\n",
    "    if 'district' in str(a).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(a)):\n",
    "        match_a = re.findall(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(a))\n",
    "        match_a = [x for x in match_a if len(x) > 0]\n",
    "        if len(match_a) == 0:\n",
    "            print('no results for title')\n",
    "            print(a)\n",
    "            \n",
    "        else:\n",
    "            has_a = True\n",
    "            match = re.sub(r'[A-Za-z]','',str(match_a[0]))\n",
    "\n",
    "    \n",
    "    if 'district' in str(b).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(b)):\n",
    "        match_b = re.findall(r'[Dd]istrict\\s?\\d{1,3}[A-Za-z]?|[Dd]-?\\s?\\d{1,3}[A-Za-z]?', str(b))\n",
    "        match_b = [x for x in match_b if len(x) > 0]\n",
    "        if len(match_b) == 0:\n",
    "            print('no results for org')\n",
    "            print(b)\n",
    "        \n",
    "        else:\n",
    "            has_b = True\n",
    "            match = re.sub(r'[A-Za-z]','',str(match_b[0]))\n",
    "\n",
    "\n",
    "    if has_b == True or has_a == True:\n",
    "        match_final = re.findall(r'\\d+[A-Za-z]?', str(match))\n",
    "        # print(\"final match: \" + str(match_final[0]))\n",
    "        # print(\"putting it on row: \" + str(i))\n",
    "        w_districts.loc[i, 'district'] = str(match_final[0]).strip().lstrip('0')\n",
    "\n",
    "    i +=1\n",
    "# w_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data export to create patch file\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# n_districts.to_csv('no_districts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process patch file \n",
    "patch_file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\patch files\\no_districts_patch.csv\"\n",
    "districts_patch = pd.read_csv(patch_file)\n",
    "\n",
    "#pull together all data\n",
    "patched_df = pd.concat([w_districts,districts_patch])\n",
    "patched_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#looks through and assigns chamber column to either house or senate\n",
    "w_districts['chamber'] = \"\"\n",
    "i = 0\n",
    "for a,b in zip(patched_df.title, patched_df.org):\n",
    "    if re.search(r'[Hh]ouse|[Ss]enate', str(b)):\n",
    "        if re.search(r'[Hh]ouse', str(b)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enate', str(b)):\n",
    "            chamber = \"Senate\"\n",
    "    elif re.search(r'[Rr]epresentative|[Ss]enator|[Dd]elegate', str(a)):\n",
    "        if re.search(r'[Rr]epresentative|[Dd]elegate', str(a)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enator', str(a)):\n",
    "            chamber = \"Senate\"\n",
    "\n",
    "    try:\n",
    "        patched_df.loc[i,'chamber'] = str(chamber)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "#find only thi states\n",
    "patched_df = patched_df[patched_df['state'].isin(thi_states)]\n",
    "patched_df = patched_df[~patched_df['district'].isna()]\n",
    "patched_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#name edits\n",
    "patched_df['first_name'] = patched_df['first_name'].str.strip().str.title()\n",
    "patched_df['last_name'] = patched_df['last_name'].str.strip().str.title().str.replace(\"' \", \"'\")\n",
    "# condition = patched_df['last_name'].str.contains(r'(?!\\w+)\\s(?<!\\w)', regex = True)\n",
    "# patched_df.loc[condition, 'last_name'] = (patched_df['last_name'].str.split(r'\\s*,\\s*(?=[A-Z])').str[0])\n",
    "# Identify rows where 'last_name' has two words separated by whitespace\n",
    "\n",
    "# patched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df,duplicates = create_pk(patched_df,'district', 'chamber')\n",
    "\n",
    "# clean_dfs = [cleaned_df,duplicates]\n",
    "# clean_df = pd.concat(clean_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(duplicates.columns)\n",
    "#grouping data together and getting list of events per legislator\n",
    "grouped_df = duplicates.groupby(['primary_key','last_name']).agg({\n",
    "    'state': 'first',\n",
    "    'first_name': 'first',\n",
    "    'event name': lambda x: '|'.join(\n",
    "        list(set(f\"{sc} ({ac})\" if not pd.isna(ac) else f\"{sc}\"\n",
    "        for sc, ac in zip(duplicates.loc[x.index, 'event name'], duplicates.loc[x.index, 'role']))))\n",
    "\n",
    "}).reset_index()\n",
    "# grouped_df.reset_index()\n",
    "grouped_df.rename(columns={'event name': 'events'}, inplace=True)\n",
    "# state_coding\n",
    "# grouped_df\n",
    "# print(cleaned_df.columns)\n",
    "\n",
    "\n",
    "#clean up grouped data\n",
    "non_dupe_df = cleaned_df.loc[:,['primary_key', 'first_name','last_name', 'state','event name']]\n",
    "non_dupe_df.rename(columns={'event name': 'events'}, inplace=True)\n",
    "\n",
    "#pull event data back together\n",
    "merged_dfs = [grouped_df, non_dupe_df]\n",
    "leg_events_df = pd.concat(merged_dfs)\n",
    "# print(leg_events_df.columns)\n",
    "\n",
    "\n",
    "#find dupes\n",
    "leg_events_df_dupes = leg_events_df[leg_events_df.duplicated(subset='primary_key', keep = False)]\n",
    "leg_events_df_dupes.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "#find none dupes and add seat\n",
    "leg_events_df_nodupes = leg_events_df[~leg_events_df.duplicated(subset='primary_key', keep = False)]\n",
    "leg_events_df_nodupes['seat'] = '00'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find one for 'Van' aka 'Van Oosting' in ['Elkin'] with length for it being 3\n",
      "couldn't find one for 'Zin' aka 'Zinnecker' in ['Bird'] with length for it being 3\n"
     ]
    }
   ],
   "source": [
    "#pull in key lookup\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\connectors')\n",
    "leg_lookup_ref = pd.read_csv('leg_lookup_df.csv')\n",
    "\n",
    "\n",
    "#groupby data to get primary key and last names associated with it\n",
    "loop_group = leg_lookup_ref.groupby(['primary_key']).agg({\n",
    "    'Last Name': lambda x: '|'.join(\n",
    "        list(set(f\"{sc}\" if not pd.isna(sc) else \"not found\"\n",
    "        for sc in leg_lookup_ref.loc[x.index, 'Last Name'])))\n",
    "}).reset_index()\n",
    "\n",
    "#set up dict for lookup\n",
    "loop_dict = loop_group.set_index('primary_key')['Last Name'].to_dict()\n",
    "\n",
    "#create seat for dupes\n",
    "leg_events_df_dupes['seat'] = np.nan\n",
    "for i,j in enumerate(leg_events_df_dupes['primary_key']):\n",
    "    #ensure j is an integer\n",
    "    j = int(j)\n",
    "    \n",
    "    #get name we are looking for\n",
    "    name_to_check = leg_events_df_dupes.loc[i,'last_name']\n",
    "    trunc_name = str(name_to_check)[:3]\n",
    "    # print(f\"checking for {trunc_name}\")\n",
    "    \n",
    "    #look for the key, get results, and split up the names into a list\n",
    "    results = loop_dict.get(j)\n",
    "    names = results.split('|')\n",
    "    \n",
    "    #get length of names\n",
    "    n = len(names)-1\n",
    "    \n",
    "    #go through and check if the name matches either of the one in the list and return the seat\n",
    "    for ik,name in enumerate(names):\n",
    "        # print(f\"going through {ik}\")\n",
    "        # print(type(name))\n",
    "        # print(type(trunc_name))\n",
    "        if re.search(f'^{trunc_name.strip()}', str(name)):\n",
    "            # print('found it')\n",
    "            seat = ik + 1\n",
    "            leg_events_df_dupes.loc[i,'seat'] = f'0{seat}'\n",
    "            break\n",
    "        #stops if we are on the last iteration and still no seat\n",
    "        elif ik == n:\n",
    "            print(f\"couldn't find one for '{trunc_name}' aka '{name_to_check}' in {names} with length for it being {len(trunc_name)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(leg_events_df_nodupes.columns)\n",
    "# print(leg_events_df_dupes.columns)\n",
    "\n",
    "#pull all event data back together\n",
    "events_dfs = [leg_events_df_dupes, leg_events_df_nodupes]\n",
    "events_df = pd.concat(events_dfs)\n",
    "events_df.dropna(subset=['seat'], inplace=True)\n",
    "events_df.reset_index(inplace=True, drop=True)\n",
    "# events_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having issues where just applying the last part of the create pk function just assigns people with same last name different seats. Might need to run create_pk without athe seat numbers first, group the (but keeping the last name for differences) and then assign seat numbers based on that. Can create a mid point look up value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Cell below calculates the activities score from the attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Score for loop\n",
    "\n",
    "\n",
    "# print(events_df.columns)\n",
    "#For loop description: goes through events column and gathers information for activities scoring\n",
    "events_df.loc[:, 'activities_score'] = 0\n",
    "for i,j in enumerate(events_df['events']):\n",
    "    \n",
    "    \n",
    "    # split up events\n",
    "    event_split = str(j).split('|')\n",
    "    events = \";\".join(event_split)\n",
    "    # if len(event_split) < 2:\n",
    "    #     continue\n",
    "\n",
    "\n",
    "    #compile name for print statements\n",
    "\n",
    "    # fname = grouped_df.at[i,'first_name']\n",
    "    lname = events_df.at[i,'last_name']\n",
    "\n",
    "    # names = [fname, lname]\n",
    "    # name = \" \".join(names)\n",
    "    \n",
    "    \n",
    "    # display_markdown(f' ## {name}', raw=True)\n",
    "    # print(bordered(events))\n",
    "\n",
    "    #For loop description: go through each event and score \n",
    "    scores = []\n",
    "    for event in event_split:\n",
    "\n",
    "        #intializing boolean values for scoring    \n",
    "        score = 0\n",
    "        speaker = False\n",
    "        is_hkf = False\n",
    "        dev_program = False\n",
    "        in_state = False\n",
    "        out_state = False\n",
    "        is_slr = False\n",
    "        dinner_or_lunch = False\n",
    "        # non_slr = False\n",
    "        speaker = False\n",
    "        # #print('#################')\n",
    "        # #print(*grouped_df.loc[i,['helper','first_name', 'last_name', 'events']], sep=\" \\ \")\n",
    "        \n",
    "        \n",
    "        # #print(bordered(event))\n",
    "\n",
    "        #Look through for roles in events\n",
    "        if re.search(r'\\(.+\\)', str(event)):\n",
    "            match = re.findall(r'\\(.+\\)', str(event))\n",
    "            match_refine = [x for x in match if len(x) != 0]\n",
    "            #print(\"match refine results\", match_refine)\n",
    "            if len(match_refine) != 0:\n",
    "                for m in match_refine:\n",
    "                    if re.search('speaker|presenter', str(m).lower()):\n",
    "                        # print('found a speaker')\n",
    "                        speaker = True\n",
    "                    elif 'HKF' in str(m):\n",
    "                        #print('THERE IS HKF IN THE RESULTS')\n",
    "                        is_hkf = True\n",
    "                \n",
    "        \n",
    "        #is it just a short engagment such as a dinner or lunch?\n",
    "        if re.search(r'[Dd]inner|[Ll]unch', str(event)):\n",
    "            dinner_or_lunch = True\n",
    "\n",
    "        #get state\n",
    "        state = events_df.loc[i,'state']\n",
    "        \n",
    "        #looking for whether events where in state or out of state\n",
    "        if 'ECLS' not in str(event) or \"HKF\" not in str(event):\n",
    "            #print(\"no ecls or hKF\")\n",
    "            try:\n",
    "                event_state = re.findall(state_abv_pat, str(event))[0].strip()\n",
    "                if event_state == state:\n",
    "                #print(\"states match\")\n",
    "                    in_state = True\n",
    "                else:\n",
    "                    out_state = True\n",
    "            except:\n",
    "                out_state = True\n",
    "                # print(str(event))\n",
    "                # print('no state match')\n",
    "        else:\n",
    "            out_state = True\n",
    "            \n",
    "            \n",
    "        #lower dev program?\n",
    "        if 'HSPF' in str(event) or 'Elevate' in str(event):\n",
    "            dev_program = True\n",
    "\n",
    "        #State Legislator event?\n",
    "        if re.search(r'SLR|HLR',str(event)):\n",
    "            is_slr = True\n",
    "\n",
    "\n",
    "        # if re.search(r'\\s[Mm]\\d', str(event)):\n",
    "        #     non_slr = True\n",
    "        \n",
    "        variables = [\n",
    "        speaker,\n",
    "        is_hkf,\n",
    "        dev_program,\n",
    "        in_state,\n",
    "        out_state,\n",
    "        is_slr,\n",
    "        dinner_or_lunch\n",
    "        ]\n",
    "\n",
    "        #Trouble shooting print statement to make sure logic is working\n",
    "        # #print('quick look at logic')\n",
    "        # for var_name, var_value in zip(['speaker', 'is_hfk', 'dev_program', 'in_state', 'out_state', 'is_slr', 'dinner_or_lunch', 'non_slr', 'out_of_state'], variables):\n",
    "        #     #print(bordered(f\"{var_name}: {var_value}\"))\n",
    "        \n",
    "\n",
    "        #Event data scoring \n",
    "        if is_slr == True:\n",
    "            score += 15\n",
    "            # print(f'adding 15 for {name} due to being an slr')\n",
    "        # else:\n",
    "        #     score += 10\n",
    "        #     #print(f'adding 10 for {name}')\n",
    "\n",
    "        elif dev_program == True:\n",
    "            score += 15\n",
    "            # print(f'adding 15 for {name} due to being in an dev program')\n",
    "        elif dinner_or_lunch == True:\n",
    "            score += 5\n",
    "            # print(f'adding 5 for {name} due to being a lunch or dinner')\n",
    "        else:\n",
    "            score += 10\n",
    "            # print(\"adding 10 for full day event with no other attributes\")\n",
    "\n",
    "        \n",
    "        #check for speaker\n",
    "        if speaker == True:\n",
    "            if in_state == True:\n",
    "                score += 0\n",
    "                #if in state no additional points\n",
    "                # print(f'adding 0 for {name} for being in state speaker')\n",
    "            elif out_state == True:\n",
    "                #if out of state add 5 more points for speakers\n",
    "                # print(f'adding 5 for {name} due ot being a speaker at an out of state event')\n",
    "                score += 5\n",
    "        \n",
    "        # check for hkf\n",
    "        if is_hkf == True:\n",
    "            score += 20\n",
    "            # print(f'adding 20 for {lname} due to being hkf')\n",
    "\n",
    "\n",
    "        \n",
    "        # print(bordered(score))\n",
    "        scores.append(score)\n",
    "\n",
    "    # display_markdown(f' ### {name}', raw=True)\n",
    "    # print(scores)\n",
    "    total = sum(scores)\n",
    "    # print(\"total: \",total)\n",
    "    \n",
    "    \n",
    "    events_df.loc[i, 'activities_score'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_pk , primary_key , first_name , last_name , activities_score , events\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "#export activity scores df\n",
    "activity_scores = events_df.loc[:,['primary_key','seat','first_name','last_name','activities_score', 'events']]\n",
    "\n",
    "#make full_pk and convert to int\n",
    "activity_scores['full_pk'] = activity_scores['primary_key'].astype(str) + activity_scores['seat'].astype(str)\n",
    "activity_scores['full_pk'] = activity_scores['full_pk'].astype(int)\n",
    "\n",
    "#put full_pk to front\n",
    "activity_scores = activity_scores.drop('seat', axis=1)\n",
    "first_column = activity_scores.pop('full_pk')\n",
    "activity_scores.insert(0, 'full_pk', first_column)\n",
    "print(*activity_scores.columns, sep = ' , ')\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(r'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\Legislators Data\\leg_data_update_10_2024\\build files')\n",
    "\n",
    "\n",
    "activity_scores.to_csv(f'activity_scores{str(date.today()).replace('-','_')}.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "# activity_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
