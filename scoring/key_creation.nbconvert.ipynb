{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:52.599274Z",
     "iopub.status.busy": "2025-02-24T21:38:52.599274Z",
     "iopub.status.idle": "2025-02-24T21:38:54.431280Z",
     "shell.execute_reply": "2025-02-24T21:38:54.430273Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, json, re  # Provides OS-dependent functionality, system-specific parameters, JSON handling\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import time\n",
    "import glob\n",
    "import xlsxwriter\n",
    "from tqdm import tqdm\n",
    "from datetime import date #date/time manipulation\n",
    "import lxml\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "from cprl_functions.state_capture import thi_states,state_ref, state_coding, state_coding_r, state_pat, state_abv_pat, state_abbreviations\n",
    "from cprl_functions.text_printing import bordered\n",
    "from cprl_functions.defined_functions import create_pk, add_seats, get_recent_file\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.434282Z",
     "iopub.status.busy": "2025-02-24T21:38:54.434282Z",
     "iopub.status.idle": "2025-02-24T21:38:54.438811Z",
     "shell.execute_reply": "2025-02-24T21:38:54.438302Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_row(row, string_column):\n",
    "    # Check conditions using an if-else statement\n",
    "    if re.search(r'[Hh]ouse|[Rr]epresentative', str(row[string_column])):\n",
    "        return \"House\"\n",
    "    elif re.search(r'[Ss]enate', str(row[string_column])):\n",
    "        return \"Senate\"\n",
    "    else:\n",
    "        return 'Unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ballotpedia info pull\n",
    "\n",
    "this will be commented out until need for a repull, use the loaded file in the \"JSON File Load\" section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.440815Z",
     "iopub.status.busy": "2025-02-24T21:38:54.440815Z",
     "iopub.status.idle": "2025-02-24T21:38:54.447495Z",
     "shell.execute_reply": "2025-02-24T21:38:54.445800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Intitial Pull\n",
    "\n",
    "# #initializing webscraping info\n",
    "# soup_url = r'https://ballotpedia.org/State_Legislative_Districts'\n",
    "# all_districts = []\n",
    "# response = requests.get(soup_url, verify = False)\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# state_districts = soup.find_all(\"a\", href = True)\n",
    "# h_refs = []\n",
    "# for url in state_districts:\n",
    "#     if 'state legislative districts' in str(url):\n",
    "#         # print(url)\n",
    "#         base = \"https://ballotpedia.org/\"\n",
    "#         full_url = base + str(url.text).replace(' ',\"_\")\n",
    "#         h_refs.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.450754Z",
     "iopub.status.busy": "2025-02-24T21:38:54.450754Z",
     "iopub.status.idle": "2025-02-24T21:38:54.453565Z",
     "shell.execute_reply": "2025-02-24T21:38:54.453565Z"
    }
   },
   "outputs": [],
   "source": [
    "#Main Webscrape\n",
    "\n",
    "\n",
    "# Fetches all of the districts (commented out until needed to repull)\n",
    "# for ref in h_refs:\n",
    "#     url = ref\n",
    "    \n",
    "#     page = requests.get(url)\n",
    "    \n",
    "#     os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\txt files for troubleshooting')\n",
    "\n",
    "#     # Write the page's text content to a file\n",
    "#     # with open('output_soup_strainer.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "#     #     f.write(page.text)\n",
    "#     # print(page.content)\n",
    "#     table_strainer = SoupStrainer('table', id='officeholder-table')\n",
    "#     page_soup = BeautifulSoup(page.content, 'html.parser', parse_only=table_strainer)\n",
    "\n",
    "#     # print(page_soup.content)\n",
    "#     # print(type(page_soup))\n",
    "#     districts = page_soup.find_all(\"a\")\n",
    "#     total_districts = []\n",
    "#     # print(page_soup.prettify())\n",
    "#     for d in districts:\n",
    "#         total_districts.append(d.text)\n",
    "#         # print(d.text)\n",
    "#     all_districts.extend(total_districts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON File Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.456570Z",
     "iopub.status.busy": "2025-02-24T21:38:54.456570Z",
     "iopub.status.idle": "2025-02-24T21:38:54.460339Z",
     "shell.execute_reply": "2025-02-24T21:38:54.459334Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Save data to JSON file\n",
    "# os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\json save data')\n",
    "# with open(f\"all_districts_{str(date.today()).replace('-', '_')}.json\", \"w\") as f:\n",
    "#     json.dump(all_districts, f)\n",
    "#     save_file_name = f.name\n",
    "#     print(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.464491Z",
     "iopub.status.busy": "2025-02-24T21:38:54.464491Z",
     "iopub.status.idle": "2025-02-24T21:38:54.474516Z",
     "shell.execute_reply": "2025-02-24T21:38:54.473998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_districts_2024_11_22.json\n"
     ]
    }
   ],
   "source": [
    "#loading districts webscraping data\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\json save data')\n",
    "json_files = glob.glob('all_districts_*.json')\n",
    "\n",
    "max_mtime = 0\n",
    "for dirname,subdirs,files in os.walk(\".\"):\n",
    "    for fname in files:\n",
    "        full_path = os.path.join(dirname, fname)\n",
    "        mtime = os.stat(full_path).st_mtime\n",
    "        if mtime > max_mtime:\n",
    "            max_mtime = mtime\n",
    "            max_dir = dirname\n",
    "            max_file = fname\n",
    "save_file_name = max_file\n",
    "print(save_file_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(f'{save_file_name}', \"r\") as f:\n",
    "    all_districts = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Curate df for Seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.515572Z",
     "iopub.status.busy": "2025-02-24T21:38:54.514581Z",
     "iopub.status.idle": "2025-02-24T21:38:54.546206Z",
     "shell.execute_reply": "2025-02-24T21:38:54.546206Z"
    }
   },
   "outputs": [],
   "source": [
    "#pull together intitials for values\n",
    "state_intitals = []\n",
    "for i,j in enumerate(all_districts):\n",
    "    state_match = re.findall(state_pat, str(j))[0]\n",
    "    state = state_match.strip()\n",
    "    state_ab = state_ref.get(state)\n",
    "    state_intitals.append(state_ab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.549830Z",
     "iopub.status.busy": "2025-02-24T21:38:54.548820Z",
     "iopub.status.idle": "2025-02-24T21:38:54.601358Z",
     "shell.execute_reply": "2025-02-24T21:38:54.600338Z"
    }
   },
   "outputs": [],
   "source": [
    "#compile and clean districts data\n",
    "districts_w_intials = pd.DataFrame({'state_abbreviation': state_intitals,'district_string': all_districts})\n",
    "districts_w_intials = districts_w_intials[~districts_w_intials['district_string'].str.contains(r'[Hh]istorical|9[AB]{1}', regex=True)]\n",
    "thi_state_districts = districts_w_intials[districts_w_intials['state_abbreviation'].isin(thi_states)]\n",
    "\n",
    "thi_state_districts.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "thi_state_districts['chamber'] = thi_state_districts.apply(\n",
    "    filter_row, args=('district_string',), axis=1\n",
    ")\n",
    "\n",
    "thi_state_districts[\"district\"] = thi_state_districts[\"district_string\"].str.extractall(r\"(\\d+)\").unstack().fillna('').apply(' '.join, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:54.603359Z",
     "iopub.status.busy": "2025-02-24T21:38:54.603359Z",
     "iopub.status.idle": "2025-02-24T21:38:55.338483Z",
     "shell.execute_reply": "2025-02-24T21:38:55.338483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary_key, district_code, state_abbreviation, district_string, chamber, district, state_code, chamber_code\n"
     ]
    }
   ],
   "source": [
    "#create pk for leg seats from ballot pedia\n",
    "\n",
    "leg_keys, leg_keys_dupes = create_pk(thi_state_districts, 'district', 'chamber')\n",
    "\n",
    "# leg_lookup = pd.concat([leg_keys_wseats,leg_keys_dupes_wseats])\n",
    "leg_lookup = pd.concat([leg_keys,leg_keys_dupes]).reset_index(drop = True)\n",
    "print(*leg_keys_dupes, sep = ', ')\n",
    "\n",
    "#uncomment for help troubleshooting\n",
    "#  os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data')\n",
    "# leg_lookup.to_csv('leg_lookup.csv')\n",
    "\n",
    "\n",
    "\n",
    "#get states with multi_seat legislature\n",
    "multi_seats = leg_lookup[leg_lookup['primary_key'].str.startswith(('430','571'))]\n",
    "multi_seats = list(set(multi_seats['primary_key'].to_list()))\n",
    "\n",
    "#assign seats\n",
    "leg_lookup['seat'] = np.nan\n",
    "for m in multi_seats:\n",
    "    n = [1]\n",
    "    \n",
    "    #grab all of the pks that match m\n",
    "    leg_lookup_m = leg_lookup[leg_lookup['primary_key'] == m]\n",
    "    \n",
    "    #create dict to change values\n",
    "    new_values = {index: i for i, (index, row) in enumerate(leg_lookup_m.iterrows(), start=1)}\n",
    "    leg_lookup.update(pd.DataFrame({'seat': new_values}).astype(str))\n",
    "\n",
    "    \n",
    "    # for row_i,seat in new_values.items():\n",
    "    #     leg_lookup.loc[row_i, 'seat'] = str(seat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:55.342492Z",
     "iopub.status.busy": "2025-02-24T21:38:55.341004Z",
     "iopub.status.idle": "2025-02-24T21:38:55.352558Z",
     "shell.execute_reply": "2025-02-24T21:38:55.352558Z"
    }
   },
   "outputs": [],
   "source": [
    "#create full_pk for leg_lookup\n",
    "\n",
    "leg_lookup = leg_lookup.copy()\n",
    "# leg_lookup[leg_lookup['seat'].isnull(), 'full_pk'] = leg_lookup['primary_key'] + '00'\n",
    "\n",
    "leg_lookup.loc[leg_lookup['seat'].notna(), 'full_pk'] = leg_lookup['primary_key'] + \"0\" + leg_lookup['seat']\n",
    "leg_lookup.loc[leg_lookup['seat'].isnull(), 'full_pk'] = leg_lookup.loc[leg_lookup['seat'].isnull(), 'primary_key'] + '00'\n",
    "\n",
    "\n",
    "\n",
    "# Move the full_pk column to the first position\n",
    "column_to_move = leg_lookup.pop('full_pk')\n",
    "leg_lookup.insert(0, 'full_pk', column_to_move)\n",
    "\n",
    "leg_lookup.columns\n",
    "bp_leg_lookup = leg_lookup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing actual ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:55.355562Z",
     "iopub.status.busy": "2025-02-24T21:38:55.354562Z",
     "iopub.status.idle": "2025-02-24T21:38:55.707723Z",
     "shell.execute_reply": "2025-02-24T21:38:55.707723Z"
    }
   },
   "outputs": [],
   "source": [
    "#pull in current year file\n",
    "path = r\"C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\THII\\legislator data\\all_leg_files\\2025\"\n",
    "all_leg_data = get_recent_file(r'*.xlsx', path)\n",
    "all_leg_df = pd.read_excel(all_leg_data)\n",
    "\n",
    "\n",
    "all_leg_df.columns = [x.lower() for x in all_leg_df.columns]\n",
    "# all_leg_df = all_leg_df.iloc[:,2:].reset_index(drop = True)\n",
    "\n",
    "\n",
    "# all_leg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:55.713736Z",
     "iopub.status.busy": "2025-02-24T21:38:55.712735Z",
     "iopub.status.idle": "2025-02-24T21:38:55.716915Z",
     "shell.execute_reply": "2025-02-24T21:38:55.716915Z"
    }
   },
   "outputs": [],
   "source": [
    "# only for if you have all records\n",
    "#getting and creating key for all leg files\n",
    "# dir = r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\all_legs_files'\n",
    "# all_leg_data = get_recent_file('*.xlsx', dir)\n",
    "\n",
    "# all_leg_data = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data\\all_legs_files\\all_leg_records.xlsx\"\n",
    "\n",
    "\n",
    "# all_leg_df = pd.read_excel(all_leg_data)\n",
    "# all_leg_df.columns = [x.lower() for x in all_leg_df.columns]\n",
    "# all_leg_df = all_leg_df.iloc[:,2:].reset_index(drop = True)\n",
    "\n",
    "# all_leg_df = all_leg_df[all_leg_df['recorded_year']==2025].reset_index(drop=True)\n",
    "# all_leg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:55.718931Z",
     "iopub.status.busy": "2025-02-24T21:38:55.718931Z",
     "iopub.status.idle": "2025-02-24T21:38:55.721928Z",
     "shell.execute_reply": "2025-02-24T21:38:55.721928Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#extract district from district string and replace \n",
    "# all_leg_df[\"district\"] = all_leg_df[\"district\"].str.extractall(r\"(\\d+)\")[0].unstack().fillna('').apply(' '.join, 1)\n",
    "# all_leg_df.drop(['District'], axis = 1)\n",
    "\n",
    "# all_leg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:55.723448Z",
     "iopub.status.busy": "2025-02-24T21:38:55.723448Z",
     "iopub.status.idle": "2025-02-24T21:38:55.727896Z",
     "shell.execute_reply": "2025-02-24T21:38:55.726883Z"
    }
   },
   "outputs": [],
   "source": [
    "#DEPRECATED all_legs already has pk\n",
    "\n",
    "#bring in leg files\n",
    "# all_leg_wkey, all_leg_dupes_wkey = create_pk(all_leg_df, 'district', 'chamber')\n",
    "# all_leg_wkey, all_leg_dupes_wkey = add_seats(all_leg_wkey, all_leg_dupes_wkey, 'First Name', 'Last Name', keep_names = True)\n",
    "\n",
    "#pull back in all people into one file\n",
    "# all_leg_lookup = pd.concat([all_leg_wkey, all_leg_dupes_wkey]).reset_index(drop = True)\n",
    "# all_leg_lookup.drop(['full_pk'], axis = 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:55.730899Z",
     "iopub.status.busy": "2025-02-24T21:38:55.730899Z",
     "iopub.status.idle": "2025-02-24T21:38:56.636344Z",
     "shell.execute_reply": "2025-02-24T21:38:56.636344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something wrong\n",
      "nannannan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#make dictionary to show full pks available at each primary key\n",
    "leg_lookbook = bp_leg_lookup.groupby(['primary_key'])['full_pk'].apply(list).reset_index()\n",
    "leg_dict = dict(zip(leg_lookbook['primary_key'], leg_lookbook['full_pk']))\n",
    "\n",
    "#go through legislator data and apply\n",
    "all_leg_df['full_pk'] = np.nan\n",
    "for i,j in enumerate(all_leg_df['primary_key']):\n",
    "    # print(type(j))\n",
    "    j_alt = str(j)\n",
    "    # continue\n",
    "    value = leg_dict.get(j_alt)\n",
    "    # print(type(value))\n",
    "    if value is None:\n",
    "        print('something wrong')\n",
    "        print(j)\n",
    "        # print(all_leg_df[i,['first name','last name', 'tenure']])\n",
    "        # print(all_bp_leg_lookup.iloc[i,:])\n",
    "        continue\n",
    "        # trouble.append(j)\n",
    "    elif len(value) == 1:\n",
    "        full_pk = j_alt + \"00\"\n",
    "    elif len(value) > 1:\n",
    "        names = sorted(all_leg_df[all_leg_df['primary_key']==j]['last name'].to_list())\n",
    "        row_name = all_leg_df.loc[i,'last name']\n",
    "        for ni, name in enumerate(names):\n",
    "            if name == row_name:\n",
    "                # print(True)\n",
    "                if ni == 0:\n",
    "                    seat = 1\n",
    "                    break\n",
    "                elif ni == 1:\n",
    "                    seat = 2\n",
    "                    break\n",
    "        full_pk = j_alt + \"0\" + str(seat)\n",
    "    all_leg_df.loc[i,['full_pk']] = full_pk\n",
    "\n",
    "\n",
    "#this is the final full_pk for the year\n",
    "\n",
    "# Move the full_pk column to the first position\n",
    "column_to_move = all_leg_df.pop('full_pk')\n",
    "all_leg_df.insert(0, 'full_pk', column_to_move)\n",
    "# all_leg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:38:56.639354Z",
     "iopub.status.busy": "2025-02-24T21:38:56.639354Z",
     "iopub.status.idle": "2025-02-24T21:38:57.080940Z",
     "shell.execute_reply": "2025-02-24T21:38:57.080428Z"
    }
   },
   "outputs": [],
   "source": [
    "#export Final Data\n",
    "from datetime import date\n",
    "file_name = f'leg_lookup_{str(date.today()).replace('-','_')}.csv'\n",
    "file_name_ex = f'leg_lookup_{str(date.today()).replace('-','_')}.xlsx'\n",
    "all_leg_df.to_csv(fr'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\THII\\legislator data\\key_creation\\2025\\{file_name}', index = False)\n",
    "all_leg_df.to_excel(fr'C:\\Users\\clutz\\THE HUNT INSTITUTE\\The Hunt Institute Team Site - Documents\\Development (formerly Grants Management)\\!Administrative\\Christian\\THII\\legislator data\\key_creation\\2025\\{file_name_ex}', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
