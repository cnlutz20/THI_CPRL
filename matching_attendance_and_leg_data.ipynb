{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, datetime, re, xlrd  # Provides OS-dependent functionality, system-specific parameters, JSON handling, and date/time manipulation\n",
    "import pandas as pd             # Provides data structures and data analysis tools\n",
    "from openpyxl import Workbook\n",
    "import numpy as np              # Supports large, multi-dimensional arrays and matrices\n",
    "import requests\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering leg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting: archive\\officials_download_quorum_10_4.xlsx\n",
      "deleting: IL\\Il_committee_data_from_quorum.xlsx\n",
      "deleting: IN\\IN_committee_data_from_quorum.xlsx\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\legislator data')\n",
    "legislator_files = glob.glob('**/*.xlsx') \n",
    "\n",
    "for i,file in enumerate(legislator_files):\n",
    "    if '_legislators' not in str(file):\n",
    "        print(\"deleting: \" + str(legislator_files[i]))\n",
    "        del legislator_files[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:AL\\AL_legislators.xlsx\n",
      "working on file:CT\\CT_legislators.xlsx\n",
      "working on file:IL\\IL_legislators.xlsx\n",
      "working on file:IN\\IN_legislators.xlsx\n",
      "working on file:KS\\KS_legislators.xlsx\n",
      "working on file:MO\\MO_legislators.xlsx\n",
      "working on file:NC\\NC_legislators.xlsx\n",
      "working on file:ND\\ND_legislators.xlsx\n",
      "working on file:NM\\NM_legislators.xlsx\n",
      "working on file:OH\\OH_legislators.xlsx\n",
      "working on file:OK\\OK_legislators.xlsx\n",
      "working on file:VA\\VA_legislators.xlsx\n",
      "working on file:WV\\WV_legislators.xlsx\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for i,file in enumerate(legislator_files):\n",
    "    print('working on file:' + str(file))\n",
    "    # file = legislator_files[0]\n",
    "    # xls = pd.ExcelFile(file)\n",
    "    sheets_dict = pd.read_excel(file, engine=\"openpyxl\", sheet_name=None)\n",
    "    sheet_names = list(sheets_dict.keys())\n",
    "    for s in sheet_names:\n",
    "        df = pd.read_excel(file, engine=\"openpyxl\", sheet_name=s)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# all_legs.to_csv('list_of_legislators_11_8_2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering attendance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data')\n",
    "events = glob.glob(\"*.xlsx\")\n",
    "state_list = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \n",
    "    \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \n",
    "    \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \n",
    "    \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \n",
    "    \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \n",
    "    \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \n",
    "    \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \n",
    "    \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n",
    "    \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\", \"District of Columbia\"\n",
    "]\n",
    "state_abbreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a statement\n"
     ]
    }
   ],
   "source": [
    "print(\"a statement\")\n",
    "state_abbreviations_reg = []\n",
    "for abv in state_abbreviations:\n",
    "    for_regex = f'^{abv}'\n",
    "    state_abbreviations_reg.append(for_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pat = re.compile(\"|\".join(state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('^AL|^AK|^AZ|^AR|^CA|^CO|^CT|^DE|^FL|^GA|^HI|^ID|^IL|^IN|^IA|^KS|^KY|^LA|^ME|^MD|^MA|^MI|^MN|^MS|^MO|^MT|^NE|^NV|^NH|^NJ|^NM|^NY|^NC|^ND|^OH|^OK|^OR|^PA|^RI|^SC|^SD|^TN|^TX|^UT|^VT|^VA|^WA|^WV|^WI|^WY)\n"
     ]
    }
   ],
   "source": [
    "state_abv_pat = re.compile(\"|\".join(state_abbreviations_reg))\n",
    "print(state_abv_pat)\n",
    "state_ref = dict(zip(state_list, state_abbreviations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in State info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "vals_changed = 0\n",
    "for event in events:\n",
    "    df = pd.read_excel(event)\n",
    "    # print('######################')\n",
    "    \n",
    "    # print(*df.columns)\n",
    "    event_name = str(event).split('.')[0].strip().replace('_', ' ')\n",
    "    df = df.iloc[:,:8]\n",
    "    df.loc[:,'event name'] = event_name\n",
    "    \n",
    "    break_all = False\n",
    "    # #print(df)\n",
    "    # continue\n",
    "    for i,state in enumerate(df['state']):\n",
    "        #print(i)\n",
    "        # print(type(state))\n",
    "        # #print(str(state))\n",
    "        # #print('----------------------------')\n",
    "        #print(df.loc[i,['first_name', 'last_name', 'title', 'org']])\n",
    "        #print(str(event_name))\n",
    "        # #print(df.loc[i, 'event name'])\n",
    "        # # continue\n",
    "        # #print('----------------------------')\n",
    "        if isinstance(state, float):\n",
    "            if re.search(r'[Rr]epresentative|[Ss]enator|[Ll]egislator',str(df['title'].iloc[i])) or re.search(r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse', str(df['org'].iloc[i])):\n",
    "                # continue\n",
    "                #print(\"^^^^^^^^^^^\")\n",
    "                #print(\"found a match\")\n",
    "                # #print(df.loc[i,['first_name', 'last_name']])\n",
    "                \n",
    "                testing_string = str(df['title'].iloc[i]) + \" \" + str(df['org'].iloc[i])\n",
    "                # #print(testing_string)\n",
    "                testing_string = testing_string.lstrip('nan').lstrip().strip()\n",
    "                # #print(re.match(r'[Rr]epresentative|[Ss]enator|[Ll]egislator|[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse',str(testing_string)))\n",
    "                # continue\n",
    "                # #print('###########')\n",
    "                # #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "                # #print('\\n')\n",
    "                state_match_uc = re.findall(state_pat, str(df['org'].iloc[i]))\n",
    "                state_match = [x for x in state_match_uc if len(x) > 0]\n",
    "                \n",
    "                # First match test\n",
    "                if len(state_match) == 0:\n",
    "                    #print('no regular state match')\n",
    "                    #print(state_match_uc)\n",
    "                    state_abv_match_uc = re.findall(state_abv_pat, str(df['org'].iloc[i]))\n",
    "                    state_abv_match = [x for x in state_abv_match_uc if len(x) > 0]\n",
    "                    # Second match test\n",
    "                    if len(state_abv_match) == 0:\n",
    "                        #print('no state abbreviation match')\n",
    "                        #print(state_abv_match_uc)\n",
    "                        state_abv_event_match_uc = re.findall(state_abv_pat, str(df['event name'].iloc[i]))\n",
    "                        state_abv_event_match = [x for x in state_abv_event_match_uc if len(x) > 0]\n",
    "                        # Third match test\n",
    "                        if len(state_abv_event_match) == 0:\n",
    "                            #print('no state abv event match')\n",
    "                            #print(state_abv_event_match_uc)\n",
    "                            break\n",
    "                        elif len(state_abv_event_match) > 1:\n",
    "                            #print('more than one match?')\n",
    "                            break_all = True\n",
    "                            break\n",
    "                        else:\n",
    "                            #print(\"abv in event match\")\n",
    "                            state_val = str(state_abv_event_match[0])\n",
    "                            # df.loc[i,'state'] = None\n",
    "                            df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                            df.loc[i,'state'] = state_val\n",
    "                            #print(state_val)\n",
    "                            vals_changed += 1\n",
    "                    elif len(state_abv_match) > 1:\n",
    "                        #print('more than one match?')\n",
    "                        #print(state_abv_match)\n",
    "                        #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "                        break_all = True\n",
    "                        break\n",
    "                    else:\n",
    "                        #print(\"regular abreviation match\")\n",
    "                        \n",
    "                        state_val = str(state_abv_match[0])\n",
    "                        # df.loc[i,'state'] = None\n",
    "                        df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                        df.loc[i,'state'] = state_val\n",
    "                        #print(state_val)\n",
    "                        vals_changed += 1\n",
    "\n",
    "                    # #print('###########')\n",
    "                    # #print(df.loc[i, list(df.columns[:5]) + [df.columns[-1]]])\n",
    "                    # #print('\\n')\n",
    "                    # break\n",
    "                elif len(state_match) > 1:\n",
    "                    #print(\"more than one match?\")\n",
    "                    break_all = True\n",
    "                    break\n",
    "                else:\n",
    "                    #print(\"normal state match\")\n",
    "                    state_val_dirty = str(state_match[0])\n",
    "                    state_val = state_ref.get(state_val_dirty)\n",
    "                    df.loc[i,'state'] = str(df.loc[i,'state'])\n",
    "                    # df.loc[i,'state'] = None\n",
    "                    df.loc[i,'state'] = state_val\n",
    "                    #print(state_val)\n",
    "                    vals_changed += 1\n",
    "            else:\n",
    "                # #print('#########################')\n",
    "                # #print('NOT A REP OR SEN')\n",
    "                # #print(df.loc[i,['first_name','last_name','title', 'org']])\n",
    "                continue\n",
    "                # #print(df.loc[i, list(df.columns[3:5]) + [df.columns[-1]]])\n",
    "                # #print('\\n')\n",
    "    if break_all == True:\n",
    "        break\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.concat(dfs)\n",
    "event_data.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(event_data['state']):\n",
    "    \n",
    "    if isinstance(j, float):\n",
    "        continue\n",
    "    elif re.search(r'[A-Z]{2}', str(j)):\n",
    "        continue\n",
    "    else:\n",
    "        val = state_ref.get(str(j))\n",
    "        event_data.loc[i,'state'] = str(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'event_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mclutz\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - THE HUNT INSTITUTE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mattendance data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mexports\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevent_data\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_data_export_11_7_2024.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'event_data' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "# event_data.to_csv(\"event_data_export_11_7_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_pattern = r'[Rr]epresentative|[Ss]enator|[Ll]egislator'\n",
    "org_pattern = r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|(?<!School )(?:House District|District)|[Ss]tate [Hh]ouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_36912\\3899269669.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  no_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True) |\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_36912\\3899269669.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True))]\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_36912\\3899269669.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True) |\n",
      "C:\\Users\\clutz\\AppData\\Local\\Temp\\ipykernel_36912\\3899269669.py:6: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True))]\n"
     ]
    }
   ],
   "source": [
    "filtered_df = event_data[event_data['title'].astype(str).apply(lambda x: bool(re.search(title_pattern, x))) |\n",
    "                 event_data['org'].astype(str).apply(lambda x: bool(re.search(org_pattern, x)))]\n",
    "no_districts = filtered_df[~(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True))]\n",
    "w_districts = filtered_df[(filtered_df['org'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True) | \n",
    "                filtered_df['title'].str.contains(r'[Dd]istrict\\s?\\d{1,3}|[Dd](-|\\s)?\\d{2,3}', regex=True))]\n",
    "\n",
    "w_districts.reset_index(inplace=True, drop=True)\n",
    "w_districts['chamber'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a,b in zip(w_districts.title, w_districts.org):\n",
    "    # print('#######################')\n",
    "    # print('***********')\n",
    "    # print(a)\n",
    "    # print('***********')\n",
    "    # print(b)\n",
    "    # continue\n",
    "    has_a = False\n",
    "    has_b = False\n",
    "    if 'district' in str(a).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}', str(a)):\n",
    "        match_a = re.findall(r'[Dd]istrict\\s?\\d{1,3}|[Dd]-?\\s?\\d{1,3}', str(a))\n",
    "        match_a = [x for x in match_a if len(x) > 0]\n",
    "        if len(match_a) == 0:\n",
    "            print('no results for title')\n",
    "            print(a)\n",
    "            \n",
    "        else:\n",
    "            has_a = True\n",
    "            match = match_a[0]\n",
    "            # print(\"a match: \" + match)\n",
    "            # print('################')\n",
    "            # print(match_a)\n",
    "        # print(str(dis))\n",
    "    \n",
    "    if 'district' in str(b).lower() or re.search(r'[Dd]-?\\s?\\d{1,3}', str(b)):\n",
    "        match_b = re.findall(r'[Dd]istrict\\s?\\d{1,3}|[Dd]-?\\s?\\d{1,3}', str(b))\n",
    "        match_b = [x for x in match_b if len(x) > 0]\n",
    "        if len(match_b) == 0:\n",
    "            print('no results for org')\n",
    "            print(b)\n",
    "        \n",
    "        else:\n",
    "            has_b = True\n",
    "            match = match_b[0]\n",
    "            # print(\"b match: \" + match)\n",
    "            # print('################')\n",
    "            # print(match_b)\n",
    "    # else:\n",
    "    #     print('no results')\n",
    "    #     print(a)\n",
    "    #     print(b)\n",
    "\n",
    "\n",
    "    if has_b == True or has_a == True:\n",
    "        match_final = re.findall(r'\\d+', str(match))\n",
    "        print(\"final match: \" + str(match_final[0]))\n",
    "        print(\"putting it on row: \" + str(i))\n",
    "        w_districts.loc[i, 'district'] = str(match_final[0]).strip().lstrip('0')\n",
    "\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix for no districts\n",
    "The chunk below brings in a manually edited file that incorporates districts from match where available\n",
    "missing info mostly comes from states where we have not pulled legislator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_file = r\"C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\archive\\no_districts_attendance_patch.xlsx\"\n",
    "districts_patch = pd.read_excel(patch_file)\n",
    "\n",
    "patched_df = pd.concat([w_districts,districts_patch])\n",
    "patched_df.reset_index(inplace=True, drop=True)\n",
    "i = 0\n",
    "for a,b in zip(patched_df.title, patched_df.org):\n",
    "    if re.search(r'[Hh]ouse|[Ss]enate', str(b)):\n",
    "        if re.search(r'[Hh]ouse', str(b)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enate', str(b)):\n",
    "            chamber = \"Senate\"\n",
    "    elif re.search(r'[Rr]epresentative|[Ss]enator|[Dd]elegate', str(a)):\n",
    "        if re.search(r'[Rr]epresentative|[Dd]elegate', str(a)):\n",
    "            chamber = \"House\"\n",
    "        elif re.search(r'[Ss]enator', str(a)):\n",
    "            chamber = \"Senate\"\n",
    "\n",
    "    try:\n",
    "        patched_df.loc[i,'chamber'] = str(chamber)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patched_df['helper'] = patched_df['state'].astype(str)+ \"-\"+ patched_df['chamber'].astype(str)+ \"-\"+patched_df['district'].astype(str)\n",
    "patched_df.loc[patched_df['state'].isna() | (patched_df['state'] == \"\") | (patched_df['district'].isna()), 'helper'] = None\n",
    "\n",
    "patch_minus_nan = patched_df[~(patched_df['helper'].isna())]\n",
    "# print(patch_minus_nan.columns)\n",
    "thi_states_df = patch_minus_nan.loc[:,['helper','first_name', 'last_name', 'honorific', 'title', 'org', 'district',\n",
    "       'role', 'state', 'event name']]\n",
    "\n",
    "grouped_df = thi_states_df.groupby('helper').agg({\n",
    "    'first_name': 'first',\n",
    "    'last_name': 'first',\n",
    "    'honorific': 'first',\n",
    "    'title': 'first',\n",
    "    'org': 'first',\n",
    "    'district': 'first',\n",
    "    'state': 'first',\n",
    "    'event name': lambda x: '|'.join(\n",
    "        f\"{sc} ({ac})\" if not pd.isna(ac) else f\"{sc}\"\n",
    "        for sc, ac in zip(thi_states_df.loc[x.index, 'event name'], thi_states_df.loc[x.index, 'role'])),\n",
    "\n",
    "}).reset_index()\n",
    "# grouped_df.reset_index()\n",
    "grouped_df.rename(columns={'event name': 'events'}, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "HKF C10 S1 (HKF)\n",
      "no state match\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "ECLS 2024 (Team Lead, Presenter)\n",
      "no state match\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "25\n",
      "0\n",
      "states match\n",
      "25\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "25\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "25\n",
      "0\n",
      "states match\n",
      "ECLS 2024 (Presenter)\n",
      "no state match\n",
      "25\n",
      "states match\n",
      "25\n",
      "states match\n",
      "HKF C10 S1 (HKF)\n",
      "no state match\n",
      "25\n",
      "0\n",
      "HSPF C4 M2 (Speakers)\n",
      "no state match\n",
      "0\n",
      "HSPF C4 M1 (Speakers)\n",
      "no state match\n",
      "0\n",
      "0\n",
      "states match\n",
      "ElevateNC C4 M3 (Cohort Member)\n",
      "no state match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "0\n",
      "states match\n",
      "ElevateNC C4 M3 (Cohort Member)\n",
      "no state match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "HSPF C4 M1 (Speakers)\n",
      "no state match\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "10\n",
      "ElevateNC C4 M3 (Cohort Member)\n",
      "no state match\n",
      "0\n",
      "states match\n",
      "15\n",
      "HSPF C4 M3 (Speakers)\n",
      "no state match\n",
      "0\n",
      "HSPF C4 M3 (Speakers)\n",
      "no state match\n",
      "0\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "ECLS 2024 (Presenter)\n",
      "no state match\n",
      "25\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "ECLS 2024 (Presenter)\n",
      "no state match\n",
      "25\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "0\n",
      "states match\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "ECLS 2024 (Presenter)\n",
      "no state match\n",
      "25\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "HKF C10 S1 (HKF)\n",
      "no state match\n",
      "0\n",
      "states match\n",
      "states match\n",
      "25\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "25\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "25\n",
      "0\n",
      "states match\n",
      "states match\n",
      "25\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "states match\n",
      "15\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "25\n",
      "HKF C10 S1 (HKF)\n",
      "no state match\n",
      "0\n",
      "states match\n",
      "15\n",
      "states match\n",
      "states match\n",
      "25\n",
      "states match\n",
      "15\n",
      "states match\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(grouped_df['events']):\n",
    "    \n",
    "    score = 0\n",
    "    speaker = False\n",
    "    is_hfk = False\n",
    "    dev_program = False\n",
    "    in_state = False\n",
    "    out_state = False\n",
    "    is_slr = False\n",
    "    dinner_or_lunch = False\n",
    "    non_slr = False\n",
    "\n",
    "    # print('#################')\n",
    "    # print(*grouped_df.loc[i,['helper','first_name', 'last_name', 'events']], sep=\" \\ \")\n",
    "    event_split = str(j).split('|')\n",
    "    # print(len(event_split))\n",
    "    # print('\\n')\n",
    "    speaker = False\n",
    "    for event in event_split:\n",
    "        \n",
    "        match = re.findall(r'\\(.+\\)', str(event))\n",
    "        match_refine = [x for x in match if len(x) != 0]\n",
    "        if len(match_refine) == 0:\n",
    "            continue\n",
    "        \n",
    "        for m in match_refine:\n",
    "            if re.search('speaker|presenter', str(m).lower()):\n",
    "                speaker = True\n",
    "            elif 'HFK' in str(m):\n",
    "                is_hfk = True\n",
    "        \n",
    "        if re.search(r'[Dd]inner|[Ll]unch', str(event)):\n",
    "            dinner_or_lunch = True\n",
    "\n",
    "\n",
    "        state = str(grouped_df.loc[i,'helper']).split('-')[0].strip()\n",
    "        \n",
    "\n",
    "        if 'ECLS' not in str(event) or \"HFK\" not in str(event):\n",
    "\n",
    "            try:\n",
    "                event_state = re.findall(state_abv_pat, str(event))[0].strip()\n",
    "            except:\n",
    "                \n",
    "                print(str(event))\n",
    "                print('no state match')\n",
    "                break\n",
    "\n",
    "            if event_state == state:\n",
    "                print(\"states match\")\n",
    "                in_state = True\n",
    "\n",
    "            else:\n",
    "                out_state = False\n",
    "            \n",
    "        else:\n",
    "            if 'ECLS' in str(event):\n",
    "                out_of_state = True\n",
    "\n",
    "        if 'HSPF' in str(event) or 'Elevate' in str(event):\n",
    "            dev_program = True\n",
    "\n",
    "        if re.search(r'SLR|HLR',str(event)):\n",
    "            is_slr = True\n",
    "\n",
    "        if re.search(r'\\s[Mm]\\d', str(event)):\n",
    "            non_slr = True\n",
    "\n",
    "\n",
    "\n",
    "    if speaker == True:\n",
    "        if in_state == True:\n",
    "            score += 10\n",
    "        elif out_state == True:\n",
    "            score += 15\n",
    "\n",
    "    if is_slr == True:\n",
    "        score += 15\n",
    "\n",
    "    if is_hfk == True:\n",
    "        score += 20\n",
    "\n",
    "    if dev_program == True:\n",
    "        score += 15\n",
    "\n",
    "    if non_slr == True: \n",
    "        score += 10\n",
    "\n",
    "    if dinner_or_lunch == True:\n",
    "        score += 5\n",
    "    \n",
    "    \n",
    "    print(score)\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "    continue\n",
    "\n",
    "        # print(\"%%%%%%%%%%%%%%%\")\n",
    "        # print(*match_refine, sep=' - ')\n",
    "        # print('%%%%%%%%%%%%%%%')\n",
    "\n",
    "    continue\n",
    "\n",
    "    speaker = False\n",
    "    for event in event_split:\n",
    "        if re.search(r'\\(.+\\)', str(event)):\n",
    "            match = re.findall(r'\\(.+\\)', str(event))\n",
    "            match = match[0]\n",
    "            if 'speaker' in str(match).lower():\n",
    "                speaker = True\n",
    "            \n",
    "    # if len(event_split) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make lookup\n",
    "\n",
    "the chunk below cuts down the dataframe to two columns for a look up value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(r'C:\\Users\\clutz\\OneDrive - THE HUNT INSTITUTE\\Documents\\Data\\attendance data\\exports')\n",
    "no_districts.to_csv(\"no_districts_export_11_7_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_legs_event\n",
    "if re.search(r'[Rr]epresentative|[Ss]enator|[Ll]egislator',str(df['title'].iloc[i])) or re.search(r'[Ss]enate|[Hh]ouse of ([Rr]epresentatives)?(Delegates)?|[Dd]istrict|[Ss]tate [Hh]ouse', str(df['org'].iloc[i])):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_legs_event = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
